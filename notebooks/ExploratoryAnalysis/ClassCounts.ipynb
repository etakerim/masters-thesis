{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from vibrodiagnostics import selection, models\n",
    "\n",
    "FEATURES_PATH =  '../../datasets/features_data/'\n",
    "FAULT_CLASSES = {\n",
    "        'A': {\n",
    "            'normal': 'normal',\n",
    "            'imbalance': 'imbalance',\n",
    "            'horizontal-misalignment': 'misalignment',\n",
    "            'vertical-misalignment': 'misalignment',\n",
    "            'underhang-outer_race': 'outer race fault',\n",
    "            'underhang-cage_fault': 'cage fault',\n",
    "            'underhang-ball_fault': 'ball fault'\n",
    "        },\n",
    "        'B': {\n",
    "            'normal': 'normal',\n",
    "            'imbalance': 'imbalance',\n",
    "            'horizontal-misalignment': 'misalignment',\n",
    "            'vertical-misalignment': 'misalignment',\n",
    "            'overhang-cage_fault': 'cage fault',\n",
    "            'overhang-ball_fault': 'ball fault',\n",
    "            'overhang-outer_race': 'outer race fault'\n",
    "        }\n",
    "}\n",
    "\n",
    "\n",
    "MAFAULDA_PATH = '../../datasets/MAFAULDA.zip'\n",
    "FEATURES_PATH =  '../../datasets/features_data/'\n",
    "MAFAULDA_METADATA = os.path.join(FEATURES_PATH, selection.MAFAULDA_METADATA)\n",
    "\n",
    "TD_FEATURES = os.path.join(FEATURES_PATH, selection.TIME_FEATURES_PATH)\n",
    "FD_FEATURES = os.path.join(FEATURES_PATH, selection.FREQ_FEATURES_PATH)\n",
    "TD_FD_FEATURES = os.path.join(FEATURES_PATH, selection.TIME_AND_FREQ_FEATURES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RPM = 2500\n",
    "RPM_RANGE = 500\n",
    "\n",
    "def load_dataset_all(place='A', anomaly=None):\n",
    "    meta = pd.read_csv(MAFAULDA_METADATA, index_col='filename')\n",
    "    files = meta[meta['fault'].isin(tuple(FAULT_CLASSES[place]))]\n",
    "    if anomaly is not None:\n",
    "        return models.fault_labeling(files, FAULT_CLASSES[place], anomaly_severity=anomaly)\n",
    "    else:\n",
    "        return models.fault_labeling(files, FAULT_CLASSES[place])\n",
    "\n",
    "def load_dataset_rpm_limited(place='A', anomaly=None):\n",
    "    meta = pd.read_csv(MAFAULDA_METADATA, index_col='filename')\n",
    "    meta = meta[meta['fault'].isin(tuple(FAULT_CLASSES[place]))]\n",
    "    files = meta[\n",
    "        (meta['rpm'].between(RPM - RPM_RANGE, RPM + RPM_RANGE, inclusive='both'))\n",
    "    ].copy()\n",
    "    if anomaly is not None:\n",
    "        return models.fault_labeling(files, FAULT_CLASSES[place], anomaly_severity=anomaly)\n",
    "    else:\n",
    "        return models.fault_labeling(files, FAULT_CLASSES[place])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_all = load_dataset_all('A')\n",
    "summary = pd.DataFrame()\n",
    "summary['A_rpm_nolimit'] = files_all['fault'].value_counts()\n",
    "summary['A_rpm_nolimit_percent'] = files_all['fault'].value_counts()  / len(files_all) * 100\n",
    "filenames = load_dataset_rpm_limited('A')\n",
    "summary['A_rpm_limit'] = filenames['fault'].value_counts()\n",
    "summary['A_rpm_limit_percent'] = filenames['fault'].value_counts()  / len(filenames) * 100\n",
    "\n",
    "files_all = load_dataset_all('B')\n",
    "summary['B_rpm_nolimit'] = files_all['fault'].value_counts()\n",
    "summary['B_rpm_nolimit_percent'] = files_all['fault'].value_counts()  / len(files_all) * 100\n",
    "filenames = load_dataset_rpm_limited('B')\n",
    "summary['B_rpm_limit'] = filenames['fault'].value_counts()\n",
    "summary['B_rpm_limit_percent'] = filenames['fault'].value_counts()  / len(filenames) * 100\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anomaly, 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_all = load_dataset_all('A', anomaly=0.6)\n",
    "summary = pd.DataFrame()\n",
    "summary['A_rpm_nolimit'] = files_all['anomaly'].value_counts()\n",
    "summary['A_rpm_nolimit_percent'] = files_all['anomaly'].value_counts()  / len(files_all) * 100\n",
    "filenames = load_dataset_rpm_limited('A')\n",
    "summary['A_rpm_limit'] = filenames['anomaly'].value_counts()\n",
    "summary['A_rpm_limit_percent'] = filenames['anomaly'].value_counts()  / len(filenames) * 100\n",
    "\n",
    "files_all = load_dataset_all('B', anomaly=0.6)\n",
    "summary['B_rpm_nolimit'] = files_all['anomaly'].value_counts()\n",
    "summary['B_rpm_nolimit_percent'] = files_all['anomaly'].value_counts()  / len(files_all) * 100\n",
    "filenames = load_dataset_rpm_limited('B')\n",
    "summary['B_rpm_limit'] = filenames['anomaly'].value_counts()\n",
    "summary['B_rpm_limit_percent'] = filenames['anomaly'].value_counts()  / len(filenames) * 100\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anomaly, 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_all = load_dataset_all('A', anomaly=0.9)\n",
    "summary = pd.DataFrame()\n",
    "summary['A_rpm_nolimit'] = files_all['anomaly'].value_counts()\n",
    "summary['A_rpm_nolimit_percent'] = files_all['anomaly'].value_counts()  / len(files_all) * 100\n",
    "filenames = load_dataset_rpm_limited('A')\n",
    "summary['A_rpm_limit'] = filenames['anomaly'].value_counts()\n",
    "summary['A_rpm_limit_percent'] = filenames['anomaly'].value_counts()  / len(filenames) * 100\n",
    "\n",
    "files_all = load_dataset_all('B', anomaly=0.9)\n",
    "summary['B_rpm_nolimit'] = files_all['anomaly'].value_counts()\n",
    "summary['B_rpm_nolimit_percent'] = files_all['anomaly'].value_counts()  / len(files_all) * 100\n",
    "filenames = load_dataset_rpm_limited('B')\n",
    "summary['B_rpm_limit'] = filenames['anomaly'].value_counts()\n",
    "summary['B_rpm_limit_percent'] = filenames['anomaly'].value_counts()  / len(filenames) * 100\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RPM limited counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames.groupby(by='fault')['rpm'].plot.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv(TD_FEATURES)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv(FD_FEATURES)\n",
    "features = models.fault_labeling(features, FAULT_CLASSES['A'])\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = features[features.columns[~features.columns.isin(selection.METADATA_COLUMNS_ALL) | features.columns.isin(('rpm',))]]\n",
    "st = x.corr()['rpm'].abs().sort_values(ascending=False)\n",
    "st.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

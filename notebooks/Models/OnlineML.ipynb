{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online machine learning\n",
    "- Incremental learning experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from zipfile import ZipFile\n",
    "from pprint import pprint\n",
    "from collections import defaultdict\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from feature import mafaulda\n",
    "from feature import selection\n",
    "from feature import discovery\n",
    "from feature import models\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import functools\n",
    "from sklearn import metrics as skmetrics\n",
    "import river\n",
    "from river import (\n",
    "    anomaly,\n",
    "    neighbors,\n",
    "    preprocessing,\n",
    "    evaluate,\n",
    "    stream,\n",
    "    metrics,\n",
    "    feature_selection,\n",
    "    stats\n",
    ")\n",
    "import tsfel\n",
    "\n",
    "\n",
    "PATH_PREFIX = '../../datasets/'\n",
    "FEATURES_PATH =  os.path.join(PATH_PREFIX, 'features_data')\n",
    "\n",
    "DATASET_PATH = os.path.join(PATH_PREFIX, 'MAFAULDA.zip')\n",
    "MAFAULDA_METADATA = os.path.join(FEATURES_PATH, 'mafaulda_metadata.csv')\n",
    "\n",
    "FEATURES_FILENAME = os.path.join(FEATURES_PATH, selection.TSFEL_FEATURES_PATH)\n",
    "# Implement: Mahanalobis distance (EmpiricalCovariance)\n",
    "# Implement Feature selection: F test, MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsfel_features_subset(filename, classes, axis, label=None, severity_sort=False, anomaly_severity=0.5):\n",
    "    features = pd.read_csv(filename)\n",
    "    features = models.fault_labeling(features, classes, anomaly_severity=anomaly_severity, debug=False)\n",
    "\n",
    "    if severity_sort:\n",
    "        groups = [\n",
    "            df.sample(frac=1, random_state=10)\n",
    "            for i, df in (\n",
    "                features.sort_values(by='severity_level')\n",
    "                        .groupby('severity_level')\n",
    "            )\n",
    "        ]\n",
    "        features = pd.concat(groups).reset_index(drop=True)\n",
    "\n",
    "    else:\n",
    "        features = (         # Shuffle\n",
    "            features\n",
    "            .sample(frac=1, random_state=10)\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "\n",
    "    columns = features.columns.str.startswith(tuple(axis))\n",
    "    features.columns[columns]\n",
    "    X = features[features.columns[columns]]\n",
    "    if label is None:\n",
    "        return X\n",
    "    else:\n",
    "        y = features[label].astype('category').cat.codes\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolution of classes in dataset\n",
    "- [ ] Faults over observations (number of seen until observation)\n",
    "- [ ] Fault severity\n",
    "- [ ] Anomaly (classes and percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_label_occurences(y):\n",
    "    observations = []\n",
    "    columns = list(y.astype('category').cat.categories)\n",
    "    empty = dict(zip(columns, len(columns) * [0]))\n",
    "\n",
    "    for row in y.astype('category').cat.codes:\n",
    "        sample = empty.copy()\n",
    "        sample[row] = 1\n",
    "        observations.append(sample)\n",
    "\n",
    "    class_occurences = pd.DataFrame.from_records(observations).cumsum()\n",
    "    class_occurences.plot(grid=True, figsize=(10, 3), xlabel='Observations', ylabel='Label occurences')\n",
    "\n",
    "\n",
    "X, y = tsfel_features_subset(FEATURES_FILENAME, selection.FAULT_CLASSES, ['az'], 'fault')\n",
    "plot_label_occurences(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = tsfel_features_subset(FEATURES_FILENAME, selection.FAULT_CLASSES, ['az'], 'anomaly')\n",
    "plot_label_occurences(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection\n",
    "\n",
    "- [X] Pearson correlation\n",
    "- [ ] Fisher score\n",
    "- [ ] Mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = tsfel_features_subset(FEATURES_FILENAME, selection.FAULT_CLASSES, ['az'], 'fault')\n",
    "selector = feature_selection.SelectKBest(\n",
    "    similarity=stats.PearsonCorr(), k=2\n",
    ")\n",
    "\n",
    "best = []\n",
    "for xs, ys in stream.iter_pandas(X, y):\n",
    "    selector.learn_one(xs, ys)\n",
    "    best.append({k: abs(v) for k, v in selector.leaderboard.items()})\n",
    "\n",
    "# Get only n best featues to plot\n",
    "n_top_names = [(k, abs(v)) for k, v in selector.leaderboard.items()]\n",
    "n_top_names = sorted(n_top_names, key=lambda x: x[1], reverse=True)[:10]\n",
    "n_top_names = set(map(lambda x: x[0], n_top_names))\n",
    "best = [\n",
    "    {k: v for k, v in step.items() if k in n_top_names}\n",
    "    for step in best\n",
    "]\n",
    "\n",
    "feature_set = pd.DataFrame.from_records(best)\n",
    "feature_set.plot(\n",
    "    figsize=(15, 6), grid=True, ylim=(0.4, 0.9),\n",
    "    xlabel='Observation', ylabel='Correlation with fault'\n",
    ")\n",
    "plt.show()\n",
    "feature_set.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_model_setup(n):\n",
    "    engine = neighbors.SWINN(\n",
    "        dist_func=functools.partial(river.utils.math.minkowski_distance, p=2),\n",
    "        seed=10\n",
    "    )\n",
    "    model = (\n",
    "        preprocessing.StandardScaler() |\n",
    "        neighbors.KNNClassifier(n_neighbors=n, engine=engine)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def knn_accuracy_with_delays(X, y, delays):\n",
    "    knn = knn_model_setup(5)\n",
    "\n",
    "    evolution = defaultdict(dict)\n",
    "    for delay in delays:\n",
    "        steps = evaluate.iter_progressive_val_score(\n",
    "            model=knn,\n",
    "            dataset=stream.iter_pandas(X, y),\n",
    "            metric=metrics.Accuracy(),\n",
    "            step=100,\n",
    "            delay=delay\n",
    "        )\n",
    "        for step in steps:\n",
    "            step_num = step['Step']\n",
    "            evolution[step_num]['Observation'] = step_num\n",
    "            evolution[step_num][delay] = step['Accuracy'].get()\n",
    "\n",
    "\n",
    "    evolution = (\n",
    "        pd.DataFrame\n",
    "        .from_records(list(evolution.values()))\n",
    "        .set_index('Observation')\n",
    "    )\n",
    "    evolution.plot(\n",
    "        grid=True, figsize=(15, 4), \n",
    "        marker='.', ylabel='Accuracy', \n",
    "        title='Accuracy with different delays'\n",
    "    )\n",
    "\n",
    "\n",
    "def knn_conf_matrix_plot(X, y):\n",
    "    knn = knn_model_setup(5)\n",
    "    #confmatrix = metrics.ConfusionMatrix()\n",
    "    y_predictions = []\n",
    "\n",
    "    for x, y_true in stream.iter_pandas(X, y):\n",
    "        y_predict = knn.predict_one(x) or 0\n",
    "        knn.learn_one(x, y_true)\n",
    "        y_predictions.append(y_predict)\n",
    "        # confmatrix.update(y_true, y_predict)\n",
    "\n",
    "\n",
    "    cm = skmetrics.confusion_matrix(y, y_predictions)\n",
    "    ax = sb.heatmap(cm, cbar=True, cmap='BuGn', annot=True, fmt='d')\n",
    "    ax.set(xlabel='Prediction', ylabel='Truth')\n",
    "\n",
    "\n",
    "def knn_visualize_classes(X, y):\n",
    "    knn = knn_model_setup(5)\n",
    "\n",
    "    y_predictions = []\n",
    "    for xs, ys in stream.iter_pandas(X, y):\n",
    "        y_predict = int(knn.predict_one(xs) or 0)\n",
    "        knn.learn_one(xs, ys)\n",
    "        y_predictions.append(y_predict)\n",
    "\n",
    "    y_predictions = pd.Series(y_predictions)\n",
    "    mismatch = models.project_classifier_map_plot(X, y, y_predictions)\n",
    "    print(f'Error rate: {100 * (len(mismatch) / len(y)):.2f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN classifier (Faults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = tsfel_features_subset(FEATURES_FILENAME, selection.FAULT_CLASSES, ['az'], 'fault')\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_accuracy_with_delays(X, y, (1, 50, 100, 250))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification report (Faults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate.progressive_val_score(\n",
    "    model=knn_model_setup(5),\n",
    "    dataset=stream.iter_pandas(X, y),\n",
    "    metric=metrics.ClassificationReport()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix (Faults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_conf_matrix_plot(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize clusters of nearest neighbors (Faults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_visualize_classes(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN classifier (Anomaly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = tsfel_features_subset(FEATURES_FILENAME, selection.FAULT_CLASSES, ['az'], 'anomaly')\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_accuracy_with_delays(X, y, (1, 50, 100, 250))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification report (Anomaly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate.progressive_val_score(\n",
    "    model=knn_model_setup(5),\n",
    "    dataset=stream.iter_pandas(X, y),\n",
    "    metric=metrics.ClassificationReport()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix (Anomaly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_conf_matrix_plot(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize clusters of nearest neighbors (Anomaly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_visualize_classes(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### TODO: Hoeffding Tree classifier of faults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: DenStream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = tsfel_features_subset(FEATURES_FILENAME, FAULT_CLASSES, ['az'], 'fault')\n",
    "denstream = (\n",
    "    preprocessing.StandardScaler() |\n",
    "    cluster.DenStream(\n",
    "        decaying_factor=0.01, beta=0.5, mu=2.5, epsilon=0.5, n_samples_init=10\n",
    "    )\n",
    ")\n",
    "steps = evaluate.iter_progressive_val_score(\n",
    "    model=denstream,\n",
    "    dataset=river.stream.iter_pandas(X),\n",
    "    metric=metrics.Silhouette(),\n",
    "    step=200,\n",
    "    delay=10\n",
    ")\n",
    "for step in steps:\n",
    "    print(step)\n",
    "\n",
    "#success = pd.DataFrame.from_records(steps).set_index('Step')\n",
    "#success.plot(grid=True, figsize=(20, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenStream Clusters visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denstream = (\n",
    "    preprocessing.MinMaxScaler() |\n",
    "    cluster.DenStream(\n",
    "        decaying_factor=0.01, beta=0.5, mu=2.5, epsilon=0.5, n_samples_init=10\n",
    "    )\n",
    ")\n",
    "\n",
    "predictions = []\n",
    "for x, y in dataset.iter_pandas(dataset):\n",
    "    y_predict = denstream.predict(x)\n",
    "    denstream.learn_one(x)              # denstream = denstream.learn_one(x)\n",
    "    predictions.append({'y_true': y, 'y_predict': y_predict})\n",
    "\n",
    "\n",
    "pd.DataFrame.from_records(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Half-space trees (Anomaly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HST: Parameter = Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = tsfel_features_subset(FEATURES_FILENAME, selection.FAULT_CLASSES, ['az'], 'anomaly')\n",
    "\n",
    "results = []\n",
    "for tree in (1, 10, 30, 50, 100, 500):\n",
    "    hst = (\n",
    "        preprocessing.MinMaxScaler() |\n",
    "        anomaly.HalfSpaceTrees(n_trees=tree, height=3, window_size=30, seed=10)\n",
    "    )\n",
    "    steps = evaluate.iter_progressive_val_score(\n",
    "        model=hst,\n",
    "        dataset=stream.iter_pandas(X, y),\n",
    "        metric=metrics.ROCAUC(),\n",
    "        step=100\n",
    "    )\n",
    "    evolution = []\n",
    "    for step in steps:\n",
    "        evolution.append({\n",
    "            'Step': step['Step'],\n",
    "            tree: step['ROCAUC'].get()\n",
    "        })\n",
    "\n",
    "    evolution = pd.DataFrame.from_records(evolution).set_index('Step')\n",
    "    results.append(evolution)\n",
    "\n",
    "results = functools.reduce(lambda a, b: pd.merge(a, b, on=['Step'], how='inner'), results)\n",
    "ax = results.plot(grid=True, figsize=(15, 4), title='Half-space Tree AUC (height = 3, window = 30)', xlabel='Observation', ylabel='AUC', marker='.')\n",
    "ax.legend(title='Trees')\n",
    "plt.show()\n",
    "results.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HST: Parameter = Window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = tsfel_features_subset(FEATURES_FILENAME, selection.FAULT_CLASSES, ['az'], 'anomaly')\n",
    "\n",
    "results = []\n",
    "for window in (1, 10, 30, 50, 100, 500):\n",
    "    hst = (\n",
    "        preprocessing.MinMaxScaler() |\n",
    "        anomaly.HalfSpaceTrees(n_trees=10, height=3, window_size=window, seed=10)\n",
    "    )\n",
    "    steps = evaluate.iter_progressive_val_score(\n",
    "        model=hst,\n",
    "        dataset=stream.iter_pandas(X, y),\n",
    "        metric=metrics.ROCAUC(),\n",
    "        step=100\n",
    "    )\n",
    "    evolution = []\n",
    "    for step in steps:\n",
    "        evolution.append({\n",
    "            'Step': step['Step'],\n",
    "            window: step['ROCAUC'].get()\n",
    "        })\n",
    "\n",
    "    evolution = pd.DataFrame.from_records(evolution).set_index('Step')\n",
    "    results.append(evolution)\n",
    "\n",
    "results = functools.reduce(lambda a, b: pd.merge(a, b, on=['Step'], how='inner'), results)\n",
    "ax = results.plot(grid=True, figsize=(15, 4), title='Half-space Tree AUC (trees = 10, height = 3)', xlabel='Observation', ylabel='AUC', marker='.')\n",
    "ax.legend(title='Window size')\n",
    "plt.show()\n",
    "results.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HST: Parameter = Height of tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = tsfel_features_subset(FEATURES_FILENAME, selection.FAULT_CLASSES, ['az'], 'anomaly')\n",
    "\n",
    "results = []\n",
    "for height in (1, 2, 3, 4, 5):\n",
    "    hst = (\n",
    "        preprocessing.MinMaxScaler() |\n",
    "        anomaly.HalfSpaceTrees(n_trees=10, height=height, window_size=30, seed=10)\n",
    "    )\n",
    "    steps = evaluate.iter_progressive_val_score(\n",
    "        model=hst,\n",
    "        dataset=stream.iter_pandas(X, y),\n",
    "        metric=metrics.ROCAUC(),\n",
    "        step=100\n",
    "    )\n",
    "    evolution = []\n",
    "    for step in steps:\n",
    "        evolution.append({\n",
    "            'Step': step['Step'],\n",
    "            height: step['ROCAUC'].get()\n",
    "        })\n",
    "\n",
    "    evolution = pd.DataFrame.from_records(evolution).set_index('Step')\n",
    "    results.append(evolution)\n",
    "\n",
    "results = functools.reduce(lambda a, b: pd.merge(a, b, on=['Step'], how='inner'), results)\n",
    "ax = results.plot(grid=True, figsize=(15, 4), title='Half-space Tree AUC (trees = 10, window = 30)', xlabel='Observation', ylabel='AUC', marker='.')\n",
    "ax.legend(title='Tree height')\n",
    "plt.show()\n",
    "results.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HST: Classification clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hst_visualize_classes(X, y):\n",
    "    hst = (\n",
    "        preprocessing.MinMaxScaler() |\n",
    "        anomaly.HalfSpaceTrees(n_trees=10, height=3, window_size=30, seed=10)\n",
    "    )\n",
    "    y_scores = []\n",
    "    for xs, ys in stream.iter_pandas(X, y):\n",
    "        score = hst.score_one(xs)\n",
    "        hst.learn_one(xs)\n",
    "        y_scores.append(score)\n",
    "\n",
    "    y_scores = np.array(y_scores)\n",
    "    models.project_anomaly_map_plot(X, y, y_scores)\n",
    "\n",
    "\n",
    "X, y = tsfel_features_subset(FEATURES_FILENAME, selection.FAULT_CLASSES, ['az'], 'anomaly')\n",
    "hst_visualize_classes(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dca216-9915-401d-aa2a-0eb1869877e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# Feature selection\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.feature_selection import mutual_info_classif, f_classif\n",
    "from sklearn.feature_selection import SelectPercentile, SelectKBest\n",
    "\n",
    "# Preprocessing of selected features\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Models - Nearest neigbors, Isolation forest, DBSCAN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Streaming algorithms\n",
    "import functools\n",
    "from river import cluster       \n",
    "from river import anomaly\n",
    "from river import preprocessing\n",
    "from river import neighbors\n",
    "from river import drift\n",
    "from river import stream\n",
    "from river import utils\n",
    "from river import evaluate\n",
    "from river import metrics\n",
    "\n",
    "# from skmultiflow.anomaly_detection import HalfSpaceTrees\n",
    "# from skmultiflow.lazy import KNNClassifier, KNNADWINClassifier\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from kneed import KneeLocator\n",
    "\n",
    "# Plotting and table formatting\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Markdown\n",
    "from tabulate import tabulate\n",
    "import seaborn as sb\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# System modules\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "# Custom modules\n",
    "from feature import mafaulda\n",
    "from feature import discovery as fdiscovery\n",
    "from feature import selection as fselection\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Constants\n",
    "EXTRACT = False\n",
    "MAFAULDA_PATH = '../../datasets/MAFAULDA.zip'\n",
    "FEATURES_PATH =  '../../datasets/features_data/'\n",
    "MAFAULDA_METADATA = os.path.join(FEATURES_PATH, 'mafaulda_metadata.csv')\n",
    "\n",
    "FAULT_CLASSES = {'normal': 'N', 'imbalance': 'I', 'horizontal-misalignment': 'HM', 'vertical-misalignment': 'VM'}\n",
    "RPM = 2900\n",
    "RPM_RANGE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d684ff1-8ecd-45cb-a7e4-b549fb281c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fault_labeling(df, classes, anomaly_severity=0.7, debug=True):\n",
    "    # Faults\n",
    "    df['fault'] = df['fault'].astype('category')\n",
    "    df['fault'] = df['fault'].cat.rename_categories(classes)\n",
    "    # Print classes of faults\n",
    "    if debug is True:\n",
    "        print('Faults:', list(df['fault'].cat.categories), end='\\n\\n')\n",
    "    \n",
    "    # Number fault severities by sequence\n",
    "    df['seq'] = (\n",
    "        df.groupby(by=['fault', 'severity'], observed=True)\n",
    "             .cumcount().astype(int)\n",
    "    )\n",
    "    # Keep only decimal numbers in severity\n",
    "    df['severity'] = df['severity'].str.extract(r'(\\d+\\.?\\d*)').astype(float)\n",
    "\n",
    "    # Number severity per group (0 - best, 1 - worst)\n",
    "    for name, group in df.groupby(by=['fault'], observed=True):\n",
    "        group = group.sort_values(by='severity')\n",
    "            \n",
    "        severities = group['severity'].astype('category').cat.codes.values.reshape(-1, 1)\n",
    "        # Transorm to range (0, 1)\n",
    "        scale_severities = MinMaxScaler().fit_transform(severities)\n",
    "        \n",
    "        df.loc[group.index, 'severity_class'] = severities\n",
    "        df.loc[group.index, 'severity_level'] = scale_severities\n",
    "\n",
    "        if debug is True:\n",
    "            # Print severity scales\n",
    "            sev_names = list(group['severity'].astype('category').cat.categories)\n",
    "            sev = list(group['severity'].astype('category').cat.codes.astype('category').cat.categories)\n",
    "            scale = [float(f'{p:.2f}') for p in pd.Series(scale_severities[:, 0]).astype('category').cat.categories]\n",
    "            print(f'Fault: {name[0]}, Files: {len(group)}, Severity names: {sev_names}, Severity: {sev}, Severity Levels: {scale}')\n",
    "\n",
    "    df['anomaly'] = (df['severity_level'] >= anomaly_severity)\n",
    "    df['anomaly'] = df['anomaly'].astype('category')\n",
    "    return df\n",
    "\n",
    "\n",
    "def highly_correlated_features(df, corr=0.95):\n",
    "    # https://stackoverflow.com/questions/29294983/how-to-calculate-correlation-between-all-columns-and-remove-highly-correlated-on\n",
    "    corr_matrix = df.corr().abs()\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    # Find features with correlation greater than \"corr\"\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > corr)]\n",
    "    return to_drop\n",
    "\n",
    "\n",
    "def filter_out_metadata_columns(df):\n",
    "    return df[df.columns[~df.columns.isin(fselection.METADATA_COLUMNS_ALL)]]\n",
    "\n",
    "\n",
    "def pipeline_v1(features, train, nfeat, \n",
    "                multiclass=True, func_select=mutual_info_classif):\n",
    "\n",
    "    # Split features dataset to training and testing sets\n",
    "    X = filter_out_metadata_columns(features)\n",
    "\n",
    "    if multiclass is True:\n",
    "        y = features['fault']\n",
    "    else:\n",
    "        y = features['anomaly']\n",
    "\n",
    "    # TODO: K-fold validation\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, train_size=train, stratify=y, random_state=100\n",
    "    )\n",
    "    \n",
    "    # Drop colinear features (TODO)\n",
    "    #to_drop = highly_correlated_features(X_train)\n",
    "    #X_train.drop(to_drop, axis=1, inplace=True)\n",
    "    #X_test.drop(to_drop, axis=1, inplace=True)\n",
    "    \n",
    "    # Feature selection\n",
    "    if len(features.columns) == nfeat:\n",
    "        nfeat = 'all'\n",
    "\n",
    "    selector = SelectKBest(func_select, k=nfeat)\n",
    "    # selector = SelectPercentile(mutual_info_classif, percentile=20)\n",
    "    \n",
    "    selector.fit_transform(X_train, y_train)\n",
    "    selector.transform(X_test)\n",
    "    idx = selector.get_support(indices=True)\n",
    "    X_train = X_train.iloc[:,idx]\n",
    "    X_test = X_test.iloc[:,idx]\n",
    "       \n",
    "    # Normalize features (See inverse transform)\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train[X_train.columns] = scaler.fit_transform(X_train)\n",
    "    X_test[X_test.columns] = scaler.transform(X_test)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def cross_cuts_3d(X_train, y_train):\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 3))\n",
    "    for i, axes in enumerate(((0, 1), (0, 2), (1, 2))):\n",
    "        a, b = axes\n",
    "\n",
    "        for label, color in (('VM', 'purple'), ('N', 'green'), ('I', 'blue'), ('HM', 'orange')):\n",
    "            x = X_train.loc[\n",
    "                list(y_train[y_train == label].index), \n",
    "                X_train.columns[a]\n",
    "            ]\n",
    "            y = X_train.loc[\n",
    "                list(y_train[y_train == label].index),\n",
    "                X_train.columns[b]\n",
    "            ]\n",
    "            ax[i].scatter(x, y, s=1, color=color, label=label)\n",
    "        \n",
    "        ax[i].set_xlabel(X_train.columns[a])\n",
    "        ax[i].set_ylabel(X_train.columns[b])\n",
    "        ax[i].grid()\n",
    "        ax[i].legend()\n",
    "\n",
    "\n",
    "def cross_cuts_3d_anomalies(dataframe, anomalies):\n",
    "    df = dataframe.copy()\n",
    "    df['anomaly'] = anomalies\n",
    "    df['anomaly'] = df['anomaly'].astype('category')\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 3))\n",
    "    \n",
    "    for i, axes in enumerate(((0, 1), (0, 2), (1, 2))):\n",
    "        a, b = axes\n",
    "        ax[i].grid()\n",
    "        x = X_train.loc[:, X_train.columns[a]]\n",
    "        y = X_train.loc[:, X_train.columns[b]]\n",
    "        ax[i].scatter(x, y, color='grey', s=1)\n",
    "\n",
    "        for flag, color in ((False, 'green'), (True, 'red')):\n",
    "            points = list(df[df['anomaly'] == flag].index)\n",
    "            x = df.loc[points, df.columns[a]]\n",
    "            y = df.loc[points, df.columns[b]]\n",
    "            ax[i].scatter(x, y, color=color, s=1)\n",
    "\n",
    "\n",
    "def load_dataset_info():\n",
    "    meta = pd.read_csv(MAFAULDA_METADATA, index_col='filename')\n",
    "    files = meta[\n",
    "        (meta['fault'].isin(FAULT_CLASSES)) &\n",
    "        (meta['rpm'].between(RPM - RPM_RANGE, RPM + RPM_RANGE, inclusive='both'))\n",
    "    ].copy()\n",
    "    return files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a170b8a-d0e4-40a7-bd68-a1257564587f",
   "metadata": {},
   "source": [
    "## Extract metadata about files from whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b395aafc-e9c3-4e42-9f89-80b3bf9e0a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXTRACT:\n",
    "    file_index = mafaulda.dataset_index(MAFAULDA_PATH)\n",
    "    file_index.to_csv(MAFAULDA_METADATA, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c268be9-9eab-4c5e-882d-2f4f0471e930",
   "metadata": {},
   "source": [
    "## Import metadata about Mafaulda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e9164b-cac8-4c64-a7a6-91e35edffad1",
   "metadata": {},
   "source": [
    "## File names selection\n",
    "Choose 4 types of faults within limited rpm range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8d3da9-6fbd-49d9-ba8e-13c4d8bd2005",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = load_dataset_info()   \n",
    "files.info()\n",
    "files.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa28fa9-3894-4c31-a3b2-9ccbba24dda8",
   "metadata": {},
   "source": [
    "### Frequency spectrum comparison of faults in low and high RPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cff5b2-e043-4be9-9340-995496ce9132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rpm_comparison(files, fault, dB):\n",
    "    table = files[\n",
    "        (files['rpm'] == files['rpm'].min()) |\n",
    "        (files['rpm'] == files['rpm'].max())\n",
    "    ] \n",
    "    dataset = ZipFile(MAFAULDA_PATH)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 3), sharey=True)\n",
    "    ax.set_title(f'{fault}')\n",
    "    for filename, series in table.iterrows():\n",
    "        fdiscovery.plot_frequency_spectrum(dataset, filename, 'ax', ax, dB=dB, label=f'{series[\"rpm\"]:.2f}')\n",
    "\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad9b5b2-1bd5-4d1d-a571-3f586729fbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = fault_labeling(files.copy(), FAULT_CLASSES, 0.6, debug=True)\n",
    "files.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c911fa8c-2dec-4e8e-942d-7bd57c9ecede",
   "metadata": {},
   "source": [
    "#### Scale in m/s^2: frequency spectrum between lowest rpm and highest RPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b652388-fdba-412d-95bb-67e57ea64bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fault, level in [('N', 0), ('I', 1), ('VM', 1), ('HM', 1)]:\n",
    "    sources = files[(files['fault'] == fault) &  (files['severity_level'] == level)]\n",
    "    plot_rpm_comparison(sources, fault, dB=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc1b112-2c89-4d2e-a84d-cee635252730",
   "metadata": {},
   "source": [
    "#### Scale in dB (baseline is 1 um/s^2): frequency spectrum between lowest rpm and highest RPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298e564d-0446-4f37-90e5-ef9c0371032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fault, level in [('N', 0), ('I', 1), ('VM', 1), ('HM', 1)]:\n",
    "    sources = files[(files['fault'] == fault) &  (files['severity_level'] == level)]\n",
    "    plot_rpm_comparison(sources, fault, dB=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bf9af0-d582-4798-9e99-d95a238cc63a",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ea0099-b589-469d-8fce-ff334f93550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbd188a-5451-4ad9-a02a-14b29a7f4505",
   "metadata": {},
   "source": [
    "### Export features for chosen files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f8ff97-57f2-4a06-95fb-88521c89c697",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ZipFile(MAFAULDA_PATH)\n",
    "filenames = list(files.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206fd967-96cc-4614-89e0-4dcf32a58bd2",
   "metadata": {},
   "source": [
    "#### 1A. Time domain features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5e88c4-627c-452d-b774-b5d79db5e0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXTRACT:\n",
    "    features = mafaulda.import_files_split(dataset, filenames, fdiscovery.features_time_domain, parts=5)\n",
    "    features.to_csv(FEATURES_PATH + fselection.TIME_FEATURES_PATH_NEW, index=False)\n",
    "    features.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65261f92-22e7-4fa5-b3a8-2a0eef6184bc",
   "metadata": {},
   "source": [
    "#### 1B. Frequency domain features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27ea0f9-336b-48fb-af1b-91b7fddd6c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXTRACT:\n",
    "    features = mafaulda.import_files_split(dataset, filenames, fdiscovery.features_frequency_domain, parts=5)\n",
    "    features.to_csv(FEATURES_PATH + fselection.FREQ_FEATURES_PATH_NEW, index=False)\n",
    "    features.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d6bf2f-1461-4edb-ac70-5c41bdae3f56",
   "metadata": {},
   "source": [
    "#### 1C. TSFEL package features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393f134a-29b8-4d9b-ad60-0c867777dd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXTRACT:\n",
    "    features = mafaulda.import_files_split(dataset, filenames, fdiscovery.tsfel_features_import, parts=5)\n",
    "    features.to_csv(FEATURES_PATH + 'tsfel_features.csv', index=False)\n",
    "    features.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eddda8b-d58f-492f-b9ea-efb1a73d231a",
   "metadata": {},
   "source": [
    "#### 1D. Wavelet packet features (Mayer wavelet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb60e36-168d-4bb6-baaa-4181d75ec0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXTRACT:\n",
    "    features = mafaulda.import_files_split(dataset, filenames, fdiscovery.features_wavelet_domain, parts=5)\n",
    "    features.to_csv(FEATURES_PATH + 'tsfel_features.csv', index=False)\n",
    "    features.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dc15f9-75a4-440d-8bee-f6f14fd8c855",
   "metadata": {},
   "source": [
    "## Features' explanatory data analysis\n",
    "#### TD: Features from one sensor position: (ax, ay, az)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcab441-5281-4a06-916a-3381feb7b112",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = fselection.load_td_feat(['ax', 'ay', 'az'], path=FEATURES_PATH)\n",
    "td_features = fault_labeling(features.copy(), FAULT_CLASSES)\n",
    "X_train, X_test, y_train, y_test = pipeline_v1(td_features, train=0.6, nfeat=3)\n",
    "\n",
    "print()\n",
    "X_train.info()\n",
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8e5d6d-f2af-44fb-98a0-662d066227a8",
   "metadata": {},
   "source": [
    "#### TD: Statistical distribution of features in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc4669f-8cdf-475a-b587-9d8e8b394a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.hist(bins=100, figsize=(15, 3), layout=(1, 3), color='grey', ec='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9de72c-2bc0-477a-b2c6-95e77ce86dd5",
   "metadata": {},
   "source": [
    "#### TD: Cross sectional plots in pairs of axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bac4e3f-023f-4062-87b4-6f2516bf2b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_cuts_3d(X_train, y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4771b62-50cb-4029-90fd-0db1a511e006",
   "metadata": {},
   "source": [
    "#### TD: 3D distribution of data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b301e58e-543d-46ad-8677-510fb554f24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(\n",
    "    X_train.loc[:,X_train.columns[0]],\n",
    "    X_train.loc[:,X_train.columns[1]],\n",
    "    X_train.loc[:,X_train.columns[2]],\n",
    "    s=1\n",
    ")\n",
    "ax.set_box_aspect(aspect=None, zoom=0.85)\n",
    "ax.set_xlabel(X_train.columns[0])\n",
    "ax.set_ylabel(X_train.columns[1])\n",
    "ax.set_zlabel(X_train.columns[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396af8d6-f283-4394-935a-d6bb4bdb7d31",
   "metadata": {},
   "source": [
    "#### TD: Cross sectional plots of anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edbace4-aee3-41f7-8ef1-0537dd99afd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = pipeline_v1(td_features, train=0.6, nfeat=3, multiclass=True)\n",
    "cross_cuts_3d_anomalies(X_train, td_features['anomaly'].iloc[list(X_train.index)])\n",
    "\n",
    "percentage = len(td_features[td_features['anomaly'] == True]) / len(td_features)\n",
    "print(f'Percentage of anomalies: {percentage * 100:.2f} %')  # TODO: too high anomaly rate (adjust stratify)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b21ab4d-44ba-43f7-b216-910445be2902",
   "metadata": {},
   "source": [
    "#### FD: Features from one sensor position: (ax, ay, az)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1ea2ad-c1c4-4642-ba0c-8d545d5e795b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = fselection.load_td_feat(['ax', 'ay', 'az'], path=FEATURES_PATH)\n",
    "fd_features = fault_labeling(features.copy(), FAULT_CLASSES)\n",
    "X_train, X_test, y_train, y_test = pipeline_v1(fd_features, train=0.6, nfeat=3)\n",
    "\n",
    "print()\n",
    "X_train.info()\n",
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7d926e-38fb-4160-a473-92a1f248bdc5",
   "metadata": {},
   "source": [
    "#### FD: Statistical distribution of features in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a04aa6-6a7c-486d-b02e-b3903a400125",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.hist(bins=100, figsize=(15, 3), layout=(1, 3), color='grey', ec='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51702e7b-69f8-4ba3-bbe9-b1e2b4953e6d",
   "metadata": {},
   "source": [
    "#### FD: Cross sectional plots in pairs of axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e709fb9-d555-4de8-9408-ae33cc1d7300",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_cuts_3d(X_train, y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccc91eb-f8c5-44cc-91b1-d217a38f8899",
   "metadata": {},
   "source": [
    "#### FD: Cross sectional plots of anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ccc121-273b-4ef0-a735-2a6b4e714bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = pipeline_v1(fd_features, train=0.6, nfeat=3, multiclass=True)\n",
    "cross_cuts_3d_anomalies(X_train, fd_features['anomaly'].iloc[list(X_train.index)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e4fb79-b0dd-48ae-bf5d-b2b4da8cebbb",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. K Nearest Neighbors\n",
    "Parameters:\n",
    "- Distance metric\n",
    "- k neighbours (odd numbers because of majority voting) - elbow curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e67e970-111c-448b-837a-1c84144e7a1a",
   "metadata": {},
   "source": [
    "#### 2A-TD. Time domain features import and transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20368894-f312-4312-897a-08fe8144cddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SET_RATIO = 0.6\n",
    "N_FEATURES = 3\n",
    "N_NEIGHBOURS = 5\n",
    "DIST_METRIC = 'euclidean'\n",
    "\n",
    "features = fselection.load_td_feat(['ax', 'ay', 'az'], path=FEATURES_PATH)\n",
    "td_features = fault_labeling(features.copy(), FAULT_CLASSES)\n",
    "X_train, X_test, y_train, y_test = pipeline_v1(\n",
    "    td_features, \n",
    "    train=TRAINING_SET_RATIO,\n",
    "    func_select=mutual_info_classif,\n",
    "    nfeat=N_FEATURES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf2a32d-8a8b-44c9-990b-2f400fdbf3f8",
   "metadata": {},
   "source": [
    "#### 2B-TD. Classification with kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5a69d3-46ee-44aa-9863-a217a7c45bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=N_NEIGHBOURS, metric=DIST_METRIC, algorithm='kd_tree')\n",
    "knn.fit(X_train, y_train)\n",
    "y_predict = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027b5b80-d7a4-4b75-8837-67b5a6ec3187",
   "metadata": {},
   "source": [
    "#### 2C-TD. Get the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b735c6a-6d43-4182-b5cb-2df0538f067a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_predict) * 100\n",
    "print(f'Accuracy: {accuracy:.4f} %')\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162c8afb-0b73-42eb-b840-90ca1a56cad4",
   "metadata": {},
   "source": [
    "#### 2D-TD. Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f5a17e-896a-4a54-951d-47e7014e6ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_predict)\n",
    "ax = sb.heatmap(cm, cbar=True, cmap='BuGn', annot=True, fmt='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48554857-8dce-4d62-af84-26d2b5ec87c2",
   "metadata": {},
   "source": [
    "#### TD: Find best k neighbors - elbow analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603e5e41-1005-4b43-a956-1ee1fe7e7b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knn_error_rates(k_values, X_train, y_train, X_test, y_test):\n",
    "    errors = []\n",
    "    for k in k_values:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k, algorithm='kd_tree', metric=DIST_METRIC)\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_predict = knn.predict(X_test)\n",
    "        errors.append(np.mean(y_predict != y_test))\n",
    "    return errors\n",
    "\n",
    "\n",
    "def get_knn_accuracies(k_values, X_train, y_train, X_test, y_test):\n",
    "    accuracies = []\n",
    "\n",
    "    for k in k_values:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k, algorithm='kd_tree', metric=DIST_METRIC)\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_predict = knn.predict(X_test)\n",
    "        accuracies.append(accuracy_score(y_test, y_predict))\n",
    "    return accuracies\n",
    "\n",
    "\n",
    "def plot_knn_k_param(k_values, accuracies, error_rates):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15, 4))\n",
    "    \n",
    "    ax[0].plot(k_values, accuracies, color='darkblue', marker='o', markerfacecolor='darkgreen', markersize=5)\n",
    "    ax[0].set_xlabel('K neighbors')\n",
    "    ax[0].set_ylabel('Accuracy')\n",
    "    ax[0].grid(True)\n",
    "\n",
    "    ax[1].plot(k_values, error_rates, color='darkblue', marker='o', markerfacecolor='darkgreen', markersize=5)\n",
    "    ax[1].set_xlabel('K neighbors')\n",
    "    ax[1].set_ylabel('Error rate')\n",
    "    ax[1].grid(True)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90f455e-a7af-4d73-b86f-4dce2eb7a809",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = list(range(3, 40, 2))\n",
    "accuracies = get_knn_accuracies(k_values, X_train, y_train, X_test, y_test)\n",
    "error_rates = get_knn_error_rates(k_values, X_train, y_train, X_test, y_test)\n",
    "plot_knn_k_param(k_values, accuracies, error_rates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b991e407-b7d8-48bc-9739-ee7c7f6a211c",
   "metadata": {},
   "source": [
    "#### 2A-FD. Frequncy domain features import and transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07ea8f9-653b-4f70-982b-021925ce4f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SET_RATIO = 0.6\n",
    "N_FEATURES = 3\n",
    "N_NEIGHBOURS = 5\n",
    "DIST_METRIC = 'euclidean'\n",
    "\n",
    "features = fselection.load_fd_feat(['ax', 'ay', 'az'], path=FEATURES_PATH)\n",
    "fd_features = fault_labeling(features.copy(), FAULT_CLASSES)\n",
    "X_train, X_test, y_train, y_test = pipeline_v1(fd_features, train=TRAINING_SET_RATIO, nfeat=N_FEATURES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4d6c70-bbdf-458a-b453-c299c0fb6eff",
   "metadata": {},
   "source": [
    "#### 2B-FD. Classification with kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4e90fe-7c83-415e-88ac-04cc9f60a67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=N_NEIGHBOURS, metric=DIST_METRIC, algorithm='kd_tree')\n",
    "knn.fit(X_train, y_train)\n",
    "y_predict = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0662a757-1551-4678-9187-d63defde74ed",
   "metadata": {},
   "source": [
    "#### 2C-FD. Get the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e7fae3-53a9-4fcc-ae7f-84d54e91bfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_predict) * 100\n",
    "print(f'Accuracy: {accuracy:.4f} %')\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe36dca-3825-4e7e-b611-d34da12313e1",
   "metadata": {},
   "source": [
    "#### 2D-FD. Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd9ef98-3dbb-4683-8779-a358c79a987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_predict)\n",
    "ax = sb.heatmap(cm, cbar=True, cmap='BuGn', annot=True, fmt='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3344d1ce-ed62-4276-bfce-5e3083613b33",
   "metadata": {},
   "source": [
    "#### FD: Find best k neighbors - elbow analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48b705f-ba5c-4a76-a108-ba67dcb15938",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = list(range(3, 40, 2))\n",
    "accuracies = get_knn_accuracies(k_values, X_train, y_train, X_test, y_test)\n",
    "error_rates = get_knn_error_rates(k_values, X_train, y_train, X_test, y_test)\n",
    "plot_knn_k_param(k_values, accuracies, error_rates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d087b112-6526-4371-907e-f99e38ec3f70",
   "metadata": {},
   "source": [
    "### Change number of features\n",
    "- evaluate kNN classification accuracies in each feature domain\n",
    "  - features for each axis separately (x, y, z)\n",
    "  - features in each measurement poins (a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c250be43-c75b-455f-bd0c-927a7598809a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SET_RATIO = 0.6\n",
    "DIST_METRIC = 'euclidean'\n",
    "FEATURE_SELECTION_METHOD = mutual_info_classif\n",
    "KNN_K_VALUES = list(range(3, 20, 2))\n",
    "\n",
    "def evaluate_knn_number_of_features(features, columns):    \n",
    "    results = []\n",
    "    for n in tqdm(range(1, len(columns) + 1)):\n",
    "        X_train, X_test, y_train, y_test = pipeline_v1(\n",
    "            fd_features, \n",
    "            train=TRAINING_SET_RATIO,\n",
    "            func_select=FEATURE_SELECTION_METHOD,\n",
    "            nfeat=n\n",
    "        )\n",
    "        metric = get_knn_error_rates(KNN_K_VALUES, X_train, y_train, X_test, y_test)\n",
    "        kneedle = KneeLocator(KNN_K_VALUES, metric, S=1.0, curve='convex', direction='decreasing')\n",
    "        results.append([n, kneedle.elbow, kneedle.knee_y])\n",
    "    \n",
    "    return pd.DataFrame(results, columns=['n_features', 'k_neighbors', 'error_rate'])\n",
    "\n",
    "\n",
    "def find_minimal_error_rate(success):\n",
    "    plt.plot(success['n_features'], success['error_rate'])\n",
    "    plt.grid()\n",
    "    plt.xlabel('Number of features')\n",
    "    plt.ylabel('Error rate')\n",
    "\n",
    "    # TODO: Find knee instead of min\n",
    "    best = success[success['error_rate'] == success['error_rate'].min()]\n",
    "    return best\n",
    "\n",
    "\n",
    "def knn_best_evaluate(best):\n",
    "    k_best = best['k_neighbors'].to_numpy()[0]\n",
    "    n_best = best['n_features'].to_numpy()[0]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = pipeline_v1(fd_features, train=TRAINING_SET_RATIO, nfeat=n_best)\n",
    "    knn = KNeighborsClassifier(n_neighbors=k_best, metric=DIST_METRIC)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_predict = knn.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_predict) * 100\n",
    "    print(f'Accuracy: {accuracy:.4f} %')\n",
    "    print(classification_report(y_test, y_predict))\n",
    "    \n",
    "    print('Most informative features:')\n",
    "    print(list(X_train.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812b8d02-a539-4d1e-af59-c63e555f731a",
   "metadata": {},
   "source": [
    "### 1. Domain: time, Axis: ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9bb578-d65e-441b-9948-c20cef82b8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = fselection.load_td_feat(['ax'], path=FEATURES_PATH)\n",
    "fd_features = fault_labeling(features.copy(), FAULT_CLASSES, debug=False)\n",
    "\n",
    "columns = filter_out_metadata_columns(features.copy()).columns\n",
    "success = evaluate_knn_number_of_features(fd_features, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443ea4f2-4b79-4051-b4cf-9257ff72e585",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = find_minimal_error_rate(success)\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ba738c-8ce9-41d1-b579-c6f25d1e9e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_best_evaluate(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91423b7d-2f55-40c1-9265-0b317cf16dad",
   "metadata": {},
   "source": [
    "### 2. Domain: frequency, Axis: ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32b7cb4-2d26-4621-8809-26a738c80650",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = fselection.load_fd_feat(['ax'], path=FEATURES_PATH)\n",
    "fd_features = fault_labeling(features.copy(), FAULT_CLASSES, debug=False)\n",
    "\n",
    "columns = filter_out_metadata_columns(features.copy()).columns\n",
    "success = evaluate_knn_number_of_features(fd_features, columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f4d538-24b4-4ae3-83a0-f0e24df7b1c7",
   "metadata": {},
   "source": [
    "Find best (minimal) error rate of kNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c3c24b-a995-475e-9a3e-6e3aad33fbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = find_minimal_error_rate(success)\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19fe1df-38d9-4b25-9fbe-790644dafcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_best_evaluate(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e952cd0-3ac0-4710-aa2e-aca5c134698a",
   "metadata": {},
   "source": [
    "### 3. Domain: time, Axis: (ax, ay, az)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb6f569-157f-4e86-b005-f8cc390320ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = fselection.load_td_feat(['ax', 'ay', 'az'], path=FEATURES_PATH)\n",
    "fd_features = fault_labeling(features.copy(), FAULT_CLASSES, debug=False)\n",
    "\n",
    "columns = filter_out_metadata_columns(features.copy()).columns\n",
    "success = evaluate_knn_number_of_features(fd_features, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dcb563-9adc-40d4-9bd3-e13902da2f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = find_minimal_error_rate(success)\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42b1102-e4d3-4a1a-a258-64b5649beeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_best_evaluate(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d4409c-65ed-42bc-a3f0-217dc81901c9",
   "metadata": {},
   "source": [
    "### 4. Domain: frequency, Axis: (ax, ay, az)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c57fba8-5cfa-4665-8639-1803da7caa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = fselection.load_fd_feat(['ax', 'ay', 'az'], path=FEATURES_PATH)\n",
    "fd_features = fault_labeling(features.copy(), FAULT_CLASSES, debug=False)\n",
    "\n",
    "columns = filter_out_metadata_columns(features.copy()).columns\n",
    "success = evaluate_knn_number_of_features(fd_features, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667c86cf-f0a1-4bc6-a628-1d13191d537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = find_minimal_error_rate(success)\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef144349-c8bd-4aea-99cc-83b89c8dc22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_best_evaluate(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a6d35e-9d24-4eb9-a59e-5c5ad887799f",
   "metadata": {},
   "source": [
    "## Compression ratio \n",
    "- when all features are in use\n",
    "- calculate compression ratio: dimensions of feature matrix : dimensions of waveform source matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b66cae-6310-41a1-935e-0764a0b85551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compression_percentage(waveforms, domain, one_file):\n",
    "    if domain == 'td':\n",
    "        features = fselection.load_td_feat(waveforms, path=FEATURES_PATH)\n",
    "    elif domain == 'fd':\n",
    "        features = fselection.load_fd_feat(waveforms, path=FEATURES_PATH)\n",
    "        \n",
    "    files = load_dataset_info()\n",
    "    features_clean = filter_out_metadata_columns(features.copy())\n",
    "\n",
    "    if one_file:\n",
    "        files = files[:1]\n",
    "        features_clean = features_clean[:1]\n",
    "    \n",
    "    original_size = np.sum(len(waveforms) * files['length'].to_numpy())\n",
    "    new_size = np.prod(features_clean.shape)\n",
    "    compression_percentage = (new_size / original_size) * 100\n",
    "\n",
    "    return compression_percentage\n",
    "\n",
    "columns = ['ax']\n",
    "print('Time domain')\n",
    "print(f'One file: features from raw rata {compression_percentage(columns, \"td\", one_file=True):.4f} %')\n",
    "print(f'All files: features from raw rata {compression_percentage(columns, \"td\", one_file=False):.4f} %')\n",
    "\n",
    "print('Frequency domain')\n",
    "print(f'One file: features from raw rata {compression_percentage(columns, \"fd\", one_file=True):.4f} %')\n",
    "print(f'All files: features from raw rata {compression_percentage(columns, \"fd\", one_file=False):.4f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc655ae5-ec05-4628-adae-c8bc2e9d6ff9",
   "metadata": {},
   "source": [
    "---\n",
    "## Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0246d957-652d-40cd-882a-895ecd2d82b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomalies_cluster_plot(dataframe):\n",
    "    df = dataframe.copy()\n",
    "    df['outlier'] = test_outliers\n",
    "    df['outlier'] = df['outlier'].astype('category')\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 3))\n",
    "    \n",
    "    for i, axes in enumerate(((0, 1), (0, 2), (1, 2))):\n",
    "        a, b = axes\n",
    "        ax[i].grid()\n",
    "        x = X_train.loc[:, X_train.columns[a]]\n",
    "        y = X_train.loc[:, X_train.columns[b]]\n",
    "        ax[i].scatter(x, y, color='grey', s=1)\n",
    "    \n",
    "        inliers = list(df[df['outlier'] == +1].index)\n",
    "        x = df.loc[inliers, df.columns[a]]\n",
    "        y = df.loc[inliers, df.columns[b]]\n",
    "        ax[i].scatter(x, y, color='green', s=1)\n",
    "    \n",
    "        outliers = list(df[df['outlier'] == -1].index)\n",
    "        x = df.loc[outliers, df.columns[a]]\n",
    "        y = df.loc[outliers, df.columns[b]]\n",
    "        ax[i].scatter(x, y, color='red', s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b1b434-933d-41bf-b943-08a571cacc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fselection.load_fd_feat(['ax', 'ay', 'az'], path=FEATURES_PATH)\n",
    "dataset = fault_labeling(dataset.copy(), FAULT_CLASSES, debug=False)\n",
    "X_train, X_test, y_train, y_test = pipeline_v1(dataset, train=0.6, nfeat=3)\n",
    "\n",
    "forest = IsolationForest(n_estimators=10)\n",
    "forest.fit(X_train)\n",
    "test_outliers = forest.predict(X_test)    # For each observation, tells whether or not (+1 or -1) is inlier\n",
    "anomalies_cluster_plot(X_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c5a9fd-7d3b-4edb-bf8b-8c42a860902c",
   "metadata": {},
   "source": [
    "# TODO \n",
    "- (Use KFold validation\n",
    "- Get training vs. testing accuracies\n",
    "- Find knee in error rate insted of min\n",
    "---\n",
    "## K Nearest Neighbors Classifier (streaming algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3ff7c0-fe8d-490b-9b7e-05a1d820b783",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_dist = functools.partial(utils.math.minkowski_distance, p=1)\n",
    "\n",
    "model = (\n",
    "    preprocessing.StandardScaler() |\n",
    "    neighbors.KNNClassifier(\n",
    "        engine=neighbors.SWINN(\n",
    "            dist_func=l1_dist,\n",
    "            seed=42\n",
    "        )\n",
    "    )\n",
    ")\n",
    "# learn_one, predict_one\n",
    "dataset = fselection.load_fd_feat(['ax', 'ay', 'az'], path=FEATURES_PATH)\n",
    "dataset = fault_labeling(dataset.copy(), FAULT_CLASSES, debug=False)\n",
    "#evaluate.progressive_val_score(dataset, model, metrics.Accuracy())\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b0f7db-30e4-461d-95d7-a0d8e979af7e",
   "metadata": {},
   "source": [
    "## Local outlier factor (streaming algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34610e00-33c4-4034-a1c3-20c803ed96c9",
   "metadata": {},
   "source": [
    "## DBSCAN\n",
    "https://stats.stackexchange.com/questions/88872/a-routine-to-choose-eps-and-minpts-for-dbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4eca76-59ca-4a45-8592-dee3bbad2021",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fselection.load_fd_feat(['ax', 'ay', 'az'], path=FEATURES_PATH)\n",
    "dataset = fault_labeling(dataset.copy(), FAULT_CLASSES, debug=False)\n",
    "X_train, X_test, y_train, y_test = pipeline_v1(dataset, train=0.6, nfeat=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df793d42-7dfd-4b79-9606-5c2d2f6d15fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find distances between points\n",
    "cnt_neighbors = 6\n",
    "neighbors = NearestNeighbors(n_neighbors=cnt_neighbors)\n",
    "neighbors.fit(X_train)\n",
    "distances, indices = neighbors.kneighbors(X_train)\n",
    "\n",
    "# PLot distances\n",
    "distance_desc = sorted(distances[:, 1], reverse=True)\n",
    "plt.plot(list(range(1,len(distance_desc)+1)), distance_desc)\n",
    "plt.xlabel('Number of points')\n",
    "plt.ylabel('Distance')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f4eb03-59d7-45cc-a2d5-67f277a99794",
   "metadata": {},
   "outputs": [],
   "source": [
    "kneedle = KneeLocator(range(1, len(distance_desc) + 1), distance_desc,\n",
    "                      S=1.0, curve='convex', direction='decreasing')\n",
    "kneedle.plot_knee_normalized()\n",
    "print(kneedle.elbow, kneedle.knee_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ddaee1-3d1e-48fa-a56e-d2be78d18369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_cuts_3d_cluster(X_train, y_train, cluster):\n",
    "    df = X_train.copy()\n",
    "    df['cluster'] = cluster\n",
    "    df['cluster'] = df['cluster'].astype('category')\n",
    "\n",
    "    categories = df['cluster'].cat.categories\n",
    "    colors = sb.color_palette(\"hls\", len(categories))\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 3))\n",
    "\n",
    "    for i, axes in enumerate(((0, 1), (0, 2), (1, 2))):\n",
    "        a, b = axes\n",
    "         \n",
    "        for label, color in zip(categories, colors):\n",
    "            rows = list(df[df['cluster'] == label].index)\n",
    "            x = df.loc[rows, df.columns[a]]\n",
    "            y = df.loc[rows, df.columns[b]]\n",
    "            ax[i].scatter(x, y, s=1, color=color, label=label)\n",
    "\n",
    "        ax[i].set_xlabel(df.columns[a])\n",
    "        ax[i].set_ylabel(df.columns[b])\n",
    "        ax[i].grid()\n",
    "        ax[i].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbdec95-9834-431f-8ece-7a479f6cec4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range of values is MinMaxScaled in range (0, 1) - eps must be smaller than 1\n",
    "# Noisy samples are given the label -1.\n",
    "clustering = DBSCAN(eps=0.1, min_samples=5, metric='l2')\n",
    "clustering.fit(X_train)\n",
    "y_train_labels = clustering.labels_\n",
    "y_predict = clustering.fit_predict(X_test)\n",
    "\n",
    "cross_cuts_3d_cluster(X_train, y_train, y_train_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdb31b2-0a7e-4470-a70d-fa499fe23fe9",
   "metadata": {},
   "source": [
    "## Half-space Trees (online)\n",
    "Half-Space Trees (window size, ensemble size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e9f2d9-8ae6-44e0-af3c-b143c4f2daff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train.iloc[:,0].to_numpy()\n",
    "\n",
    "hst = anomaly.HalfSpaceTrees(n_trees=5, height=3, window_size=3, seed=42)\n",
    "\n",
    "for x in X[:3]:\n",
    "    hst = hst.learn_one({'x': x})\n",
    "\n",
    "for x in X:\n",
    "    features = {'x': x}\n",
    "    hst = hst.learn_one(features)\n",
    "    print(f'Anomaly score for x={x:.3f}: {hst.score_one(features):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8278cc-c5f1-4b16-99fa-438dde8d0910",
   "metadata": {},
   "source": [
    "## DenStream (online)\n",
    "DenStream (μ, ε, beta, λ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8acd25-c6d6-4d8e-8e3b-d91586ccc639",
   "metadata": {},
   "outputs": [],
   "source": [
    "denstream = cluster.DenStream(\n",
    "    decaying_factor=0.01,\n",
    "    beta=0.5,\n",
    "    mu=2.5,\n",
    "    epsilon=0.5,\n",
    "    n_samples_init=10\n",
    ")\n",
    "# Choose one feature (from example)\n",
    "X = X_train.to_numpy()\n",
    "\n",
    "for x, _ in stream.iter_array(X):\n",
    "    denstream = denstream.learn_one(x)\n",
    "\n",
    "denstream.predict_one({0: -1, 1: -2})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

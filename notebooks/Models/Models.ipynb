{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dca216-9915-401d-aa2a-0eb1869877e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "from sklearn.feature_selection import mutual_info_classif, f_classif\n",
    "\n",
    "from sklearn.feature_selection import SelectPercentile, SelectKBest\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "from river import cluster       # cluster.DenStream\n",
    "from river import anomaly       # anomaly.HalfSpaceTrees, LocalOutlierFactor\n",
    "from river import preprocessing # preprocessing.StandardScaler\n",
    "from river import neighbors     # neighbors.KNNClassifier, SWINN\n",
    "from river import drift         # ADWIN\n",
    "from river import stream\n",
    "import warnings\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Markdown\n",
    "import seaborn as sb\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from feature import mafaulda\n",
    "from feature import discovery as fdiscovery\n",
    "from feature import selection as fselection\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# from skmultiflow.anomaly_detection import HalfSpaceTrees\n",
    "# from skmultiflow.lazy import KNNClassifier, KNNADWINClassifier\n",
    "EXTRACT = False\n",
    "MAFAULDA_PATH = '../../datasets/MAFAULDA.zip'\n",
    "FEATURES_PATH =  '../../datasets/features_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b395aafc-e9c3-4e42-9f89-80b3bf9e0a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract metadata (Skip)\n",
    "if EXTRACT:\n",
    "    file_index = mafaulda.dataset_index(MAFAULDA_PATH)\n",
    "    file_index.to_csv(FEATURES_PATH + 'mafaulda_metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8d3da9-6fbd-49d9-ba8e-13c4d8bd2005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import metadata about Mafaulda\n",
    "meta = pd.read_csv(FEATURES_PATH + 'mafaulda_metadata.csv', index_col='filename')\n",
    "# Show dataframe\n",
    "meta.info()\n",
    "meta.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82b576f-c2e0-4e5b-9c12-7d47d26d8a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose 4 types of faults within limited rpm range\n",
    "classes = {'normal': 'N', 'imbalance': 'I', 'horizontal-misalignment': 'HM', 'vertical-misalignment': 'VM'}\n",
    "rpm = 2900\n",
    "rpm_range = 300\n",
    "\n",
    "files = meta[\n",
    "    (meta['fault'].isin(classes)) &\n",
    "    (meta['rpm'].between(rpm - rpm_range, rpm + rpm_range, inclusive='both'))\n",
    "].copy()\n",
    "files.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1877e0de-e1df-44e2-835f-56be6cef1b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fault_labeling(df, debug=True):\n",
    "    # Faults\n",
    "    df['fault'] = df['fault'].astype('category')\n",
    "    df['fault'] = df['fault'].cat.rename_categories(classes)\n",
    "    # Print classes of faults\n",
    "    print('Faults:', list(df['fault'].cat.categories), end='\\n\\n')\n",
    "    \n",
    "    # Number fault classes\n",
    "    df['seq'] = (\n",
    "        df.groupby(by=['fault', 'severity'], observed=True)\n",
    "             .cumcount().astype(int)\n",
    "    )\n",
    "    # Keep only decimal numbers in severity\n",
    "    df['severity'] = df['severity'].str.extract(r'(\\d+\\.?\\d*)').astype(float)\n",
    "\n",
    "    # Number severity per group (0 - best, 1 - worst)\n",
    "    for name, group in df.groupby(by=['fault'], observed=True):\n",
    "        group = group.sort_values(by='severity')\n",
    "            \n",
    "        severities = group['severity'].astype('category').cat.codes.values.reshape(-1, 1)\n",
    "        # Transorm to range (0, 1)\n",
    "        scale_severities = MinMaxScaler().fit_transform(severities)\n",
    "        \n",
    "        df.loc[group.index, 'severity_class'] = severities\n",
    "        df.loc[group.index, 'severity_level'] = scale_severities\n",
    "\n",
    "        if debug is True:\n",
    "            # Print severity scales\n",
    "            sev_names = list(group['severity'].astype('category').cat.categories)\n",
    "            sev = list(group['severity'].astype('category').cat.codes.astype('category').cat.categories)\n",
    "            scale = [float(f'{p:.2f}') for p in pd.Series(scale_severities[:, 0]).astype('category').cat.categories]\n",
    "            print(f'Fault: {name[0]}, Files: {len(group)}, Severity names: {sev_names}, Severity: {sev}, Severity Levels: {scale}')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff8d25d-e556-4481-a531-264a8e0b2e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = fault_labeling(files)\n",
    "print()\n",
    "files.info()\n",
    "files.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cff5b2-e043-4be9-9340-995496ce9132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rpm_comparison(files, fault, dB):\n",
    "    table = files[\n",
    "        (files['rpm'] == files['rpm'].min()) |\n",
    "        (files['rpm'] == files['rpm'].max())\n",
    "    ] \n",
    "    dataset = ZipFile(MAFAULDA_PATH)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 3), sharey=True)\n",
    "    ax.set_title(f'{fault}')\n",
    "    for filename, series in table.iterrows():\n",
    "        fdiscovery.plot_frequency_spectrum(dataset, filename, 'ax', ax, dB=dB, label=f'{series[\"rpm\"]:.2f}')\n",
    "\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b652388-fdba-412d-95bb-67e57ea64bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference in frequency spectrum between lowest rpm and highest rpm (non dB)\n",
    "for fault, level in [('N', 0), ('I', 1), ('VM', 1), ('HM', 1)]:\n",
    "    sources = files[(files['fault'] == fault) &  (files['severity_level'] == level)]\n",
    "    plot_rpm_comparison(sources, fault, dB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298e564d-0446-4f37-90e5-ef9c0371032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference in frequency spectrum between lowest rpm and highest rpm (dB)\n",
    "for fault, level in [('N', 0), ('I', 1), ('VM', 1), ('HM', 1)]:\n",
    "    sources = files[(files['fault'] == fault) &  (files['severity_level'] == level)]\n",
    "    plot_rpm_comparison(sources, fault, dB=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bf9af0-d582-4798-9e99-d95a238cc63a",
   "metadata": {},
   "source": [
    "## Test train split and Feature selection\n",
    "- Break severity to two levels (accept, no accept) in each fault - use accept as normal baseline\n",
    "- Stratified sampling (Train: 0.7, Test: 0.3)\n",
    "- Choose few faults/states: normal, unbalance, horizonatl misalignment, vertical misalignment (exclude bearings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ea0099-b589-469d-8fce-ff334f93550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbd188a-5451-4ad9-a02a-14b29a7f4505",
   "metadata": {},
   "source": [
    "### Export features for chosen files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f8ff97-57f2-4a06-95fb-88521c89c697",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ZipFile(MAFAULDA_PATH)\n",
    "filenames = list(files.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5e88c4-627c-452d-b774-b5d79db5e0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time domain features\n",
    "if EXTRACT:\n",
    "    features = mafaulda.import_files_split(dataset, filenames, fdiscovery.features_time_domain, parts=5)\n",
    "    features.to_csv(FEATURES_PATH + fselection.TIME_FEATURES_PATH_NEW, index=False)\n",
    "    features.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27ea0f9-336b-48fb-af1b-91b7fddd6c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency domain features\n",
    "if EXTRACT:\n",
    "    features = mafaulda.import_files_split(dataset, filenames, fdiscovery.features_frequency_domain, parts=5)\n",
    "    features.to_csv(FEATURES_PATH + fselection.FREQ_FEATURES_PATH_NEW, index=False)\n",
    "    features.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393f134a-29b8-4d9b-ad60-0c867777dd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TSFEL package features\n",
    "if EXTRACT:\n",
    "    features = mafaulda.import_files_split(dataset, filenames, fdiscovery.tsfel_features_import, parts=5)\n",
    "    features.to_csv(FEATURES_PATH + 'tsfel_features.csv', index=False)\n",
    "    features.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dc15f9-75a4-440d-8bee-f6f14fd8c855",
   "metadata": {},
   "source": [
    "### Import features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d684ff1-8ecd-45cb-a7e4-b549fb281c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highly_correlated_features(df, corr=0.95):\n",
    "    # https://stackoverflow.com/questions/29294983/how-to-calculate-correlation-between-all-columns-and-remove-highly-correlated-on\n",
    "    corr_matrix = df.corr().abs()\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    # Find features with correlation greater than \"corr\"\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > corr)]\n",
    "    return to_drop\n",
    "\n",
    "\n",
    "def pipeline_v1(features, train, nfeat):\n",
    "    # Split features dataset to training and testing sets\n",
    "    X = features[features.columns[~features.columns.isin(fselection.METADATA_COLUMNS_ALL)]]\n",
    "    y = features['fault']\n",
    "\n",
    "    # TODO: K-fold validation\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train, stratify=y)\n",
    "    \n",
    "    # Drop colinear features\n",
    "    to_drop = highly_correlated_features(X_train)\n",
    "    X_train.drop(to_drop, axis=1, inplace=True)\n",
    "    X_test.drop(to_drop, axis=1, inplace=True)\n",
    "    \n",
    "    # Feature selection\n",
    "    selector = SelectKBest(mutual_info_classif, k=nfeat)\n",
    "    # selector = SelectPercentile(mutual_info_classif, percentile=20)\n",
    "    \n",
    "    selector.fit_transform(X_train, y_train)\n",
    "    selector.transform(X_test)\n",
    "    idx = selector.get_support(indices=True)\n",
    "    X_train = X_train.iloc[:,idx]\n",
    "    X_test = X_test.iloc[:,idx]\n",
    "       \n",
    "    # Normalize features (See inverse transform)\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train[X_train.columns] = scaler.fit_transform(X_train)\n",
    "    X_test[X_test.columns] = scaler.transform(X_test)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcab441-5281-4a06-916a-3381feb7b112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get features from one sensor (ax, ay, az) features\n",
    "features = fselection.load_td_feat(['ax', 'ay', 'az'], path=FEATURES_PATH)\n",
    "td_features = fault_labeling(features.copy())\n",
    "print()\n",
    "td_features.info()\n",
    "td_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244a7028-33b3-42f4-b33f-98360102cfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = pipeline_v1(td_features, train=0.5, nfeat=3)\n",
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc4669f-8cdf-475a-b587-9d8e8b394a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical distribution of features\n",
    "X_train.hist(bins=100, figsize=(15, 3), layout=(1, 3), color='grey', ec='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bac4e3f-023f-4062-87b4-6f2516bf2b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross sections plots in pairs of axis\n",
    "def cross_cuts_3d(X_train, y_train):\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 3))\n",
    "    for i, axes in enumerate(((0, 1), (0, 2), (1, 2))):\n",
    "        a, b = axes\n",
    "        x = X_train.loc[:,X_train.columns[a]]\n",
    "        y = X_train.loc[:,X_train.columns[b]]\n",
    "\n",
    "        for label, color in (('VM', 'purple'), ('N', 'green'), ('I', 'blue'), ('HM', 'orange')):\n",
    "            x = X_train.loc[\n",
    "                list(y_train[y_train == label].index), \n",
    "                X_train.columns[a]\n",
    "            ]\n",
    "            y = X_train.loc[\n",
    "                list(y_train[y_train == label].index),\n",
    "                X_train.columns[b]\n",
    "            ]\n",
    "            ax[i].scatter(x, y, s=1, color=color, label=label)\n",
    "        \n",
    "        ax[i].set_xlabel(X_train.columns[a])\n",
    "        ax[i].set_ylabel(X_train.columns[b])\n",
    "        ax[i].grid()\n",
    "        ax[i].legend()\n",
    "\n",
    "cross_cuts_3d(X_train, y_train)    # TODO: color according to class\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b301e58e-543d-46ad-8677-510fb554f24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D distribution of datapoints\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(\n",
    "    X_train.loc[:,X_train.columns[0]],\n",
    "    X_train.loc[:,X_train.columns[1]],\n",
    "    X_train.loc[:,X_train.columns[2]],\n",
    "    s=1\n",
    ")\n",
    "ax.set_box_aspect(aspect=None, zoom=0.85)\n",
    "ax.set_xlabel(X_train.columns[0])\n",
    "ax.set_ylabel(X_train.columns[1])\n",
    "ax.set_zlabel(X_train.columns[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e4fb79-b0dd-48ae-bf5d-b2b4da8cebbb",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors\n",
    "KNN (distance metric, k neighbours - elbow) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5a69d3-46ee-44aa-9863-a217a7c45bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification with kNN\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_predict = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b735c6a-6d43-4182-b5cb-2df0538f067a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the classification report\n",
    "accuracy = accuracy_score(y_test, y_predict) * 100\n",
    "print(\"Accuracy: \" + str(accuracy) + '%')\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f5a17e-896a-4a54-951d-47e7014e6ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_predict)\n",
    "ax = sb.heatmap(cm, cbar=True, cmap=\"BuGn\", annot=True, fmt='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b991e407-b7d8-48bc-9739-ee7c7f6a211c",
   "metadata": {},
   "source": [
    "### Freqency domain features - KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07ea8f9-653b-4f70-982b-021925ce4f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = fselection.load_fd_feat(['ax', 'ay', 'az'], path=FEATURES_PATH)\n",
    "fd_features = fault_labeling(features.copy())\n",
    "print()\n",
    "fd_features.info()\n",
    "fd_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a96ab5-aac4-4561-b873-bcfc4c99eb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = pipeline_v1(fd_features, train=0.5, nfeat=3)\n",
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4e90fe-7c83-415e-88ac-04cc9f60a67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical distribution of features\n",
    "X_train.hist(bins=100, figsize=(15, 3), layout=(1, 3), color='grey', ec='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32e56a5-fff1-4eea-81c0-3bb5bd022536",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_cuts_3d(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e7fae3-53a9-4fcc-ae7f-84d54e91bfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification with kNN\n",
    "knn = KNeighborsClassifier(n_neighbors=7, algorithm='kd_tree', metric='l2', weights='uniform')\n",
    "knn.fit(X_train, y_train)\n",
    "y_predict = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd9ef98-3dbb-4683-8779-a358c79a987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the classification report\n",
    "accuracy = accuracy_score(y_test, y_predict) * 100\n",
    "print(\"Accuracy: \" + str(accuracy) + '%')\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48b705f-ba5c-4a76-a108-ba67dcb15938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_predict)\n",
    "ax = sb.heatmap(cm, cbar=True, cmap=\"BuGn\", annot=True, fmt='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c5a9fd-7d3b-4edb-bf8b-8c42a860902c",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors (online)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3ff7c0-fe8d-490b-9b7e-05a1d820b783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from river import utils\n",
    "from river import evaluate\n",
    "from river import metrics\n",
    "l1_dist = functools.partial(utils.math.minkowski_distance, p=1)\n",
    "\n",
    "model = (\n",
    "    preprocessing.StandardScaler() |\n",
    "    neighbors.KNNClassifier(\n",
    "        engine=neighbors.SWINN(\n",
    "            dist_func=l1_dist,\n",
    "            seed=42\n",
    "        )\n",
    "    )\n",
    ")\n",
    "# learn_one, predict_one\n",
    "dataset = fselection.load_fd_feat(['ax', 'ay', 'az'], path=FEATURES_PATH)\n",
    "dataset = fault_labeling(dataset.copy(), debug=False)\n",
    "#evaluate.progressive_val_score(dataset, model, metrics.Accuracy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b0f7db-30e4-461d-95d7-a0d8e979af7e",
   "metadata": {},
   "source": [
    "## Local outlier factor (online, experimental)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc655ae5-ec05-4628-adae-c8bc2e9d6ff9",
   "metadata": {},
   "source": [
    "## Isolation Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdb31b2-0a7e-4470-a70d-fa499fe23fe9",
   "metadata": {},
   "source": [
    "## Half-space Trees (online)\n",
    "Half-Space Trees (window size, ensemble size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34610e00-33c4-4034-a1c3-20c803ed96c9",
   "metadata": {},
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8278cc-c5f1-4b16-99fa-438dde8d0910",
   "metadata": {},
   "source": [
    "## DenStream (online)\n",
    "DenStream (μ, ε, beta, λ)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

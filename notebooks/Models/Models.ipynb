{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dca216-9915-401d-aa2a-0eb1869877e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# Feature selection\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.feature_selection import mutual_info_classif, f_classif\n",
    "from sklearn.feature_selection import SelectPercentile, SelectKBest\n",
    "\n",
    "# Preprocessing of selected features\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Models - Nearest neigbors, Isolation forest, DBSCAN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Streaming algorithms\n",
    "import functools\n",
    "from river import cluster       \n",
    "from river import anomaly\n",
    "from river import preprocessing\n",
    "from river import neighbors\n",
    "from river import drift\n",
    "from river import stream\n",
    "from river import utils\n",
    "from river import evaluate\n",
    "from river import metrics\n",
    "\n",
    "# from skmultiflow.anomaly_detection import HalfSpaceTrees\n",
    "# from skmultiflow.lazy import KNNClassifier, KNNADWINClassifier\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from kneed import KneeLocator\n",
    "\n",
    "# Plotting and table formatting\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Markdown\n",
    "from tabulate import tabulate\n",
    "import seaborn as sb\n",
    "\n",
    "# System modules\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "# Custom modules\n",
    "from feature import mafaulda\n",
    "from feature import discovery as fdiscovery\n",
    "from feature import selection as fselection\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Constants\n",
    "EXTRACT = False\n",
    "MAFAULDA_PATH = '../../datasets/MAFAULDA.zip'\n",
    "FEATURES_PATH =  '../../datasets/features_data/'\n",
    "\n",
    "FAULT_CLASSES = {'normal': 'N', 'imbalance': 'I', 'horizontal-misalignment': 'HM', 'vertical-misalignment': 'VM'}\n",
    "RPM = 2900\n",
    "RPM_RANGE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d684ff1-8ecd-45cb-a7e4-b549fb281c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fault_labeling(df, classes, anomaly_severity=0.7, debug=True):\n",
    "    # Faults\n",
    "    df['fault'] = df['fault'].astype('category')\n",
    "    df['fault'] = df['fault'].cat.rename_categories(classes)\n",
    "    # Print classes of faults\n",
    "    if debug is True:\n",
    "        print('Faults:', list(df['fault'].cat.categories), end='\\n\\n')\n",
    "    \n",
    "    # Number fault severities by sequence\n",
    "    df['seq'] = (\n",
    "        df.groupby(by=['fault', 'severity'], observed=True)\n",
    "             .cumcount().astype(int)\n",
    "    )\n",
    "    # Keep only decimal numbers in severity\n",
    "    df['severity'] = df['severity'].str.extract(r'(\\d+\\.?\\d*)').astype(float)\n",
    "\n",
    "    # Number severity per group (0 - best, 1 - worst)\n",
    "    for name, group in df.groupby(by=['fault'], observed=True):\n",
    "        group = group.sort_values(by='severity')\n",
    "            \n",
    "        severities = group['severity'].astype('category').cat.codes.values.reshape(-1, 1)\n",
    "        # Transorm to range (0, 1)\n",
    "        scale_severities = MinMaxScaler().fit_transform(severities)\n",
    "        \n",
    "        df.loc[group.index, 'severity_class'] = severities\n",
    "        df.loc[group.index, 'severity_level'] = scale_severities\n",
    "\n",
    "        if debug is True:\n",
    "            # Print severity scales\n",
    "            sev_names = list(group['severity'].astype('category').cat.categories)\n",
    "            sev = list(group['severity'].astype('category').cat.codes.astype('category').cat.categories)\n",
    "            scale = [float(f'{p:.2f}') for p in pd.Series(scale_severities[:, 0]).astype('category').cat.categories]\n",
    "            print(f'Fault: {name[0]}, Files: {len(group)}, Severity names: {sev_names}, Severity: {sev}, Severity Levels: {scale}')\n",
    "\n",
    "    df['anomaly'] = (df['severity_level'] >= anomaly_severity)\n",
    "    df['anomaly'] = df['anomaly'].astype('category')\n",
    "    return df\n",
    "\n",
    "\n",
    "def highly_correlated_features(df, corr=0.95):\n",
    "    # https://stackoverflow.com/questions/29294983/how-to-calculate-correlation-between-all-columns-and-remove-highly-correlated-on\n",
    "    corr_matrix = df.corr().abs()\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    # Find features with correlation greater than \"corr\"\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > corr)]\n",
    "    return to_drop\n",
    "\n",
    "\n",
    "def pipeline_v1(features, train, nfeat, multiclass=True):\n",
    "    # Split features dataset to training and testing sets\n",
    "    X = features[features.columns[~features.columns.isin(fselection.METADATA_COLUMNS_ALL)]]\n",
    "\n",
    "    if multiclass is True:\n",
    "        y = features['fault']\n",
    "    else:\n",
    "        y = features['anomaly']\n",
    "\n",
    "    # TODO: K-fold validation\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train, stratify=y)\n",
    "    \n",
    "    # Drop colinear features\n",
    "    to_drop = highly_correlated_features(X_train)\n",
    "    X_train.drop(to_drop, axis=1, inplace=True)\n",
    "    X_test.drop(to_drop, axis=1, inplace=True)\n",
    "    \n",
    "    # Feature selection\n",
    "    selector = SelectKBest(mutual_info_classif, k=nfeat)\n",
    "    # selector = SelectPercentile(mutual_info_classif, percentile=20)\n",
    "    \n",
    "    selector.fit_transform(X_train, y_train)\n",
    "    selector.transform(X_test)\n",
    "    idx = selector.get_support(indices=True)\n",
    "    X_train = X_train.iloc[:,idx]\n",
    "    X_test = X_test.iloc[:,idx]\n",
    "       \n",
    "    # Normalize features (See inverse transform)\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train[X_train.columns] = scaler.fit_transform(X_train)\n",
    "    X_test[X_test.columns] = scaler.transform(X_test)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def cross_cuts_3d(X_train, y_train):\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 3))\n",
    "    for i, axes in enumerate(((0, 1), (0, 2), (1, 2))):\n",
    "        a, b = axes\n",
    "\n",
    "        for label, color in (('VM', 'purple'), ('N', 'green'), ('I', 'blue'), ('HM', 'orange')):\n",
    "            x = X_train.loc[\n",
    "                list(y_train[y_train == label].index), \n",
    "                X_train.columns[a]\n",
    "            ]\n",
    "            y = X_train.loc[\n",
    "                list(y_train[y_train == label].index),\n",
    "                X_train.columns[b]\n",
    "            ]\n",
    "            ax[i].scatter(x, y, s=1, color=color, label=label)\n",
    "        \n",
    "        ax[i].set_xlabel(X_train.columns[a])\n",
    "        ax[i].set_ylabel(X_train.columns[b])\n",
    "        ax[i].grid()\n",
    "        ax[i].legend()\n",
    "\n",
    "\n",
    "def cross_cuts_3d_anomalies(dataframe, anomalies):\n",
    "    df = dataframe.copy()\n",
    "    df['anomaly'] = anomalies\n",
    "    df['anomaly'] = df['anomaly'].astype('category')\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 3))\n",
    "    \n",
    "    for i, axes in enumerate(((0, 1), (0, 2), (1, 2))):\n",
    "        a, b = axes\n",
    "        ax[i].grid()\n",
    "        x = X_train.loc[:, X_train.columns[a]]\n",
    "        y = X_train.loc[:, X_train.columns[b]]\n",
    "        ax[i].scatter(x, y, color='grey', s=1)\n",
    "\n",
    "        for flag, color in ((False, 'green'), (True, 'red')):\n",
    "            points = list(df[df['anomaly'] == flag].index)\n",
    "            x = df.loc[points, df.columns[a]]\n",
    "            y = df.loc[points, df.columns[b]]\n",
    "            ax[i].scatter(x, y, color=color, s=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a170b8a-d0e4-40a7-bd68-a1257564587f",
   "metadata": {},
   "source": [
    "## Extract metadata about files from whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b395aafc-e9c3-4e42-9f89-80b3bf9e0a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXTRACT:\n",
    "    file_index = mafaulda.dataset_index(MAFAULDA_PATH)\n",
    "    file_index.to_csv(os.path.join(FEATURES_PATH, 'mafaulda_metadata.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c268be9-9eab-4c5e-882d-2f4f0471e930",
   "metadata": {},
   "source": [
    "## Import metadata about Mafaulda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8d3da9-6fbd-49d9-ba8e-13c4d8bd2005",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv(os.path.join(FEATURES_PATH, 'mafaulda_metadata.csv'), index_col='filename')\n",
    "meta.info()\n",
    "meta.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e9164b-cac8-4c64-a7a6-91e35edffad1",
   "metadata": {},
   "source": [
    "## File names selection\n",
    "Choose 4 types of faults within limited rpm range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82b576f-c2e0-4e5b-9c12-7d47d26d8a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = meta[\n",
    "    (meta['fault'].isin(FAULT_CLASSES)) &\n",
    "    (meta['rpm'].between(RPM - RPM_RANGE, RPM + RPM_RANGE, inclusive='both'))\n",
    "].copy()\n",
    "files.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa28fa9-3894-4c31-a3b2-9ccbba24dda8",
   "metadata": {},
   "source": [
    "### Frequency spectrum comparison of faults in low and high RPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cff5b2-e043-4be9-9340-995496ce9132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rpm_comparison(files, fault, dB):\n",
    "    table = files[\n",
    "        (files['rpm'] == files['rpm'].min()) |\n",
    "        (files['rpm'] == files['rpm'].max())\n",
    "    ] \n",
    "    dataset = ZipFile(MAFAULDA_PATH)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 3), sharey=True)\n",
    "    ax.set_title(f'{fault}')\n",
    "    for filename, series in table.iterrows():\n",
    "        fdiscovery.plot_frequency_spectrum(dataset, filename, 'ax', ax, dB=dB, label=f'{series[\"rpm\"]:.2f}')\n",
    "\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad9b5b2-1bd5-4d1d-a571-3f586729fbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = fault_labeling(files.copy(), FAULT_CLASSES, 0.6, debug=True)\n",
    "files.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c911fa8c-2dec-4e8e-942d-7bd57c9ecede",
   "metadata": {},
   "source": [
    "#### Scale in m/s^2: frequency spectrum between lowest rpm and highest RPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b652388-fdba-412d-95bb-67e57ea64bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fault, level in [('N', 0), ('I', 1), ('VM', 1), ('HM', 1)]:\n",
    "    sources = files[(files['fault'] == fault) &  (files['severity_level'] == level)]\n",
    "    plot_rpm_comparison(sources, fault, dB=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc1b112-2c89-4d2e-a84d-cee635252730",
   "metadata": {},
   "source": [
    "#### Scale in dB (baseline is 1 um/s^2): frequency spectrum between lowest rpm and highest RPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298e564d-0446-4f37-90e5-ef9c0371032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fault, level in [('N', 0), ('I', 1), ('VM', 1), ('HM', 1)]:\n",
    "    sources = files[(files['fault'] == fault) &  (files['severity_level'] == level)]\n",
    "    plot_rpm_comparison(sources, fault, dB=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bf9af0-d582-4798-9e99-d95a238cc63a",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ea0099-b589-469d-8fce-ff334f93550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbd188a-5451-4ad9-a02a-14b29a7f4505",
   "metadata": {},
   "source": [
    "### Export features for chosen files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f8ff97-57f2-4a06-95fb-88521c89c697",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ZipFile(MAFAULDA_PATH)\n",
    "filenames = list(files.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206fd967-96cc-4614-89e0-4dcf32a58bd2",
   "metadata": {},
   "source": [
    "#### 1A. Time domain features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5e88c4-627c-452d-b774-b5d79db5e0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXTRACT:\n",
    "    features = mafaulda.import_files_split(dataset, filenames, fdiscovery.features_time_domain, parts=5)\n",
    "    features.to_csv(FEATURES_PATH + fselection.TIME_FEATURES_PATH_NEW, index=False)\n",
    "    features.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65261f92-22e7-4fa5-b3a8-2a0eef6184bc",
   "metadata": {},
   "source": [
    "#### 1B. Frequency domain features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27ea0f9-336b-48fb-af1b-91b7fddd6c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXTRACT:\n",
    "    features = mafaulda.import_files_split(dataset, filenames, fdiscovery.features_frequency_domain, parts=5)\n",
    "    features.to_csv(FEATURES_PATH + fselection.FREQ_FEATURES_PATH_NEW, index=False)\n",
    "    features.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d6bf2f-1461-4edb-ac70-5c41bdae3f56",
   "metadata": {},
   "source": [
    "#### 1C. TSFEL package features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393f134a-29b8-4d9b-ad60-0c867777dd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXTRACT:\n",
    "    features = mafaulda.import_files_split(dataset, filenames, fdiscovery.tsfel_features_import, parts=5)\n",
    "    features.to_csv(FEATURES_PATH + 'tsfel_features.csv', index=False)\n",
    "    features.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eddda8b-d58f-492f-b9ea-efb1a73d231a",
   "metadata": {},
   "source": [
    "#### 1D. Wavelet packet features (Mayer wavelet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb60e36-168d-4bb6-baaa-4181d75ec0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXTRACT:\n",
    "    features = mafaulda.import_files_split(dataset, filenames, fdiscovery.features_wavelet_domain, parts=5)\n",
    "    features.to_csv(FEATURES_PATH + 'tsfel_features.csv', index=False)\n",
    "    features.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dc15f9-75a4-440d-8bee-f6f14fd8c855",
   "metadata": {},
   "source": [
    "## Features' explanatory data analysis\n",
    "#### TD: Features from one sensor position: (ax, ay, az)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcab441-5281-4a06-916a-3381feb7b112",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = fselection.load_td_feat(['ax', 'ay', 'az'], path=FEATURES_PATH)\n",
    "td_features = fault_labeling(features.copy(), FAULT_CLASSES)\n",
    "X_train, X_test, y_train, y_test = pipeline_v1(td_features, train=0.6, nfeat=3)\n",
    "\n",
    "print()\n",
    "X_train.info()\n",
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8e5d6d-f2af-44fb-98a0-662d066227a8",
   "metadata": {},
   "source": [
    "#### TD: Statistical distribution of features in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc4669f-8cdf-475a-b587-9d8e8b394a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.hist(bins=100, figsize=(15, 3), layout=(1, 3), color='grey', ec='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9de72c-2bc0-477a-b2c6-95e77ce86dd5",
   "metadata": {},
   "source": [
    "#### TD: Cross sectional plots in pairs of axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bac4e3f-023f-4062-87b4-6f2516bf2b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_cuts_3d(X_train, y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4771b62-50cb-4029-90fd-0db1a511e006",
   "metadata": {},
   "source": [
    "#### TD: 3D distribution of data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b301e58e-543d-46ad-8677-510fb554f24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(\n",
    "    X_train.loc[:,X_train.columns[0]],\n",
    "    X_train.loc[:,X_train.columns[1]],\n",
    "    X_train.loc[:,X_train.columns[2]],\n",
    "    s=1\n",
    ")\n",
    "ax.set_box_aspect(aspect=None, zoom=0.85)\n",
    "ax.set_xlabel(X_train.columns[0])\n",
    "ax.set_ylabel(X_train.columns[1])\n",
    "ax.set_zlabel(X_train.columns[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396af8d6-f283-4394-935a-d6bb4bdb7d31",
   "metadata": {},
   "source": [
    "#### TD: Cross sectional plots of anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edbace4-aee3-41f7-8ef1-0537dd99afd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = pipeline_v1(td_features, train=0.6, nfeat=3, multiclass=True)\n",
    "cross_cuts_3d_anomalies(X_train, td_features['anomaly'].iloc[list(X_train.index)])\n",
    "\n",
    "percentage = len(td_features[td_features['anomaly'] == True]) / len(td_features)\n",
    "print(f'Percentage of anomalies: {percentage * 100:.2f} %')  # TODO: too high anomaly rate (adjust stratify)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b21ab4d-44ba-43f7-b216-910445be2902",
   "metadata": {},
   "source": [
    "#### FD: Features from one sensor position: (ax, ay, az)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1ea2ad-c1c4-4642-ba0c-8d545d5e795b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = fselection.load_td_feat(['ax', 'ay', 'az'], path=FEATURES_PATH)\n",
    "fd_features = fault_labeling(features.copy(), FAULT_CLASSES)\n",
    "X_train, X_test, y_train, y_test = pipeline_v1(fd_features, train=0.6, nfeat=3)\n",
    "\n",
    "print()\n",
    "X_train.info()\n",
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7d926e-38fb-4160-a473-92a1f248bdc5",
   "metadata": {},
   "source": [
    "#### FD: Statistical distribution of features in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a04aa6-6a7c-486d-b02e-b3903a400125",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.hist(bins=100, figsize=(15, 3), layout=(1, 3), color='grey', ec='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51702e7b-69f8-4ba3-bbe9-b1e2b4953e6d",
   "metadata": {},
   "source": [
    "#### FD: Cross sectional plots in pairs of axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e709fb9-d555-4de8-9408-ae33cc1d7300",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_cuts_3d(X_train, y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccc91eb-f8c5-44cc-91b1-d217a38f8899",
   "metadata": {},
   "source": [
    "#### FD: Cross sectional plots of anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ccc121-273b-4ef0-a735-2a6b4e714bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = pipeline_v1(fd_features, train=0.6, nfeat=3, multiclass=True)\n",
    "cross_cuts_3d_anomalies(X_train, fd_features['anomaly'].iloc[list(X_train.index)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e4fb79-b0dd-48ae-bf5d-b2b4da8cebbb",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. K Nearest Neighbors\n",
    "Parameters:\n",
    "- Distance metric\n",
    "- k neighbours (odd numbers because of majority voting) - elbow curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e67e970-111c-448b-837a-1c84144e7a1a",
   "metadata": {},
   "source": [
    "#### 2A-TD. Time domain features import and transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20368894-f312-4312-897a-08fe8144cddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SET_RATIO = 0.6\n",
    "N_FEATURES = 3\n",
    "N_NEIGHBOURS = 5\n",
    "DIST_METRIC = 'euclidean'\n",
    "\n",
    "features = fselection.load_td_feat(['ax', 'ay', 'az'], path=FEATURES_PATH)\n",
    "td_features = fault_labeling(features.copy(), FAULT_CLASSES)\n",
    "X_train, X_test, y_train, y_test = pipeline_v1(td_features, train=TRAINING_SET_RATIO, nfeat=N_FEATURES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf2a32d-8a8b-44c9-990b-2f400fdbf3f8",
   "metadata": {},
   "source": [
    "#### 2B-TD. Classification with kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5a69d3-46ee-44aa-9863-a217a7c45bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=N_NEIGHBOURS, metric=DIST_METRIC, algorithm='kd_tree')\n",
    "knn.fit(X_train, y_train)\n",
    "y_predict = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027b5b80-d7a4-4b75-8837-67b5a6ec3187",
   "metadata": {},
   "source": [
    "#### 2C-TD. Get the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b735c6a-6d43-4182-b5cb-2df0538f067a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_predict) * 100\n",
    "print(f'Accuracy: {accuracy:.4f} %')\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162c8afb-0b73-42eb-b840-90ca1a56cad4",
   "metadata": {},
   "source": [
    "#### 2D-TD. Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f5a17e-896a-4a54-951d-47e7014e6ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_predict)\n",
    "ax = sb.heatmap(cm, cbar=True, cmap='BuGn', annot=True, fmt='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48554857-8dce-4d62-af84-26d2b5ec87c2",
   "metadata": {},
   "source": [
    "#### TD: Find best k neighbors - elbow analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603e5e41-1005-4b43-a956-1ee1fe7e7b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_k_parameter_knn(X_train, y_train, X_test, y_test):\n",
    "    errors = []\n",
    "    k_values = list(range(3, 40, 2),)\n",
    "    for k in k_values:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k, algorithm='kd_tree', metric=DIST_METRIC)\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_predict = knn.predict(X_test)\n",
    "        errors.append(np.mean(y_predict != y_test))\n",
    "    \n",
    "    plt.plot(range(3, 40, 2), errors, color='darkblue', marker='o', markerfacecolor='darkgreen', markersize=5)\n",
    "    plt.xlabel('K neighbors')\n",
    "    plt.ylabel('Error rate')\n",
    "    plt.grid(True)\n",
    "\n",
    "find_best_k_parameter_knn(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b991e407-b7d8-48bc-9739-ee7c7f6a211c",
   "metadata": {},
   "source": [
    "#### 2A-FD. Frequncy domain features import and transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07ea8f9-653b-4f70-982b-021925ce4f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SET_RATIO = 0.6\n",
    "N_FEATURES = 3\n",
    "N_NEIGHBOURS = 5\n",
    "DIST_METRIC = 'euclidean'\n",
    "\n",
    "features = fselection.load_fd_feat(['ax', 'ay', 'az'], path=FEATURES_PATH)\n",
    "fd_features = fault_labeling(features.copy(), FAULT_CLASSES)\n",
    "X_train, X_test, y_train, y_test = pipeline_v1(fd_features, train=TRAINING_SET_RATIO, nfeat=N_FEATURES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4d6c70-bbdf-458a-b453-c299c0fb6eff",
   "metadata": {},
   "source": [
    "#### 2B-FD. Classification with kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4e90fe-7c83-415e-88ac-04cc9f60a67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=N_NEIGHBOURS, metric=DIST_METRIC, algorithm='kd_tree')\n",
    "knn.fit(X_train, y_train)\n",
    "y_predict = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0662a757-1551-4678-9187-d63defde74ed",
   "metadata": {},
   "source": [
    "#### 2C-FD. Get the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e7fae3-53a9-4fcc-ae7f-84d54e91bfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_predict) * 100\n",
    "print(f'Accuracy: {accuracy:.4f} %')\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe36dca-3825-4e7e-b611-d34da12313e1",
   "metadata": {},
   "source": [
    "#### 2D-FD. Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd9ef98-3dbb-4683-8779-a358c79a987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_predict)\n",
    "ax = sb.heatmap(cm, cbar=True, cmap='BuGn', annot=True, fmt='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3344d1ce-ed62-4276-bfce-5e3083613b33",
   "metadata": {},
   "source": [
    "#### FD: Find best k neighbors - elbow analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48b705f-ba5c-4a76-a108-ba67dcb15938",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_k_parameter_knn(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc655ae5-ec05-4628-adae-c8bc2e9d6ff9",
   "metadata": {},
   "source": [
    "---\n",
    "## Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0246d957-652d-40cd-882a-895ecd2d82b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomalies_cluster_plot(dataframe):\n",
    "    df = dataframe.copy()\n",
    "    df['outlier'] = test_outliers\n",
    "    df['outlier'] = df['outlier'].astype('category')\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 3))\n",
    "    \n",
    "    for i, axes in enumerate(((0, 1), (0, 2), (1, 2))):\n",
    "        a, b = axes\n",
    "        ax[i].grid()\n",
    "        x = X_train.loc[:, X_train.columns[a]]\n",
    "        y = X_train.loc[:, X_train.columns[b]]\n",
    "        ax[i].scatter(x, y, color='grey', s=1)\n",
    "    \n",
    "        inliers = list(df[df['outlier'] == +1].index)\n",
    "        x = df.loc[inliers, df.columns[a]]\n",
    "        y = df.loc[inliers, df.columns[b]]\n",
    "        ax[i].scatter(x, y, color='green', s=1)\n",
    "    \n",
    "        outliers = list(df[df['outlier'] == -1].index)\n",
    "        x = df.loc[outliers, df.columns[a]]\n",
    "        y = df.loc[outliers, df.columns[b]]\n",
    "        ax[i].scatter(x, y, color='red', s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b1b434-933d-41bf-b943-08a571cacc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fselection.load_fd_feat(['ax', 'ay', 'az'], path=FEATURES_PATH)\n",
    "dataset = fault_labeling(dataset.copy(), FAULT_CLASSES, debug=False)\n",
    "X_train, X_test, y_train, y_test = pipeline_v1(dataset, train=0.6, nfeat=3)\n",
    "\n",
    "forest = IsolationForest(n_estimators=10)\n",
    "forest.fit(X_train)\n",
    "test_outliers = forest.predict(X_test)    # For each observation, tells whether or not (+1 or -1) is inlier\n",
    "anomalies_cluster_plot(X_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b66cae-6310-41a1-935e-0764a0b85551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO plot true anomalies, compare to true anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00927c2-7e13-44db-800b-1fc5892bd8bb",
   "metadata": {},
   "source": [
    "# TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c5a9fd-7d3b-4edb-bf8b-8c42a860902c",
   "metadata": {},
   "source": [
    "---\n",
    "## K Nearest Neighbors Classifier (streaming algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3ff7c0-fe8d-490b-9b7e-05a1d820b783",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_dist = functools.partial(utils.math.minkowski_distance, p=1)\n",
    "\n",
    "model = (\n",
    "    preprocessing.StandardScaler() |\n",
    "    neighbors.KNNClassifier(\n",
    "        engine=neighbors.SWINN(\n",
    "            dist_func=l1_dist,\n",
    "            seed=42\n",
    "        )\n",
    "    )\n",
    ")\n",
    "# learn_one, predict_one\n",
    "dataset = fselection.load_fd_feat(['ax', 'ay', 'az'], path=FEATURES_PATH)\n",
    "dataset = fault_labeling(dataset.copy(), FAULT_CLASSES, debug=False)\n",
    "#evaluate.progressive_val_score(dataset, model, metrics.Accuracy())\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b0f7db-30e4-461d-95d7-a0d8e979af7e",
   "metadata": {},
   "source": [
    "## Local outlier factor (streaming algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34610e00-33c4-4034-a1c3-20c803ed96c9",
   "metadata": {},
   "source": [
    "## DBSCAN\n",
    "https://stats.stackexchange.com/questions/88872/a-routine-to-choose-eps-and-minpts-for-dbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4eca76-59ca-4a45-8592-dee3bbad2021",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fselection.load_fd_feat(['ax', 'ay', 'az'], path=FEATURES_PATH)\n",
    "dataset = fault_labeling(dataset.copy(), FAULT_CLASSES, debug=False)\n",
    "X_train, X_test, y_train, y_test = pipeline_v1(dataset, train=0.6, nfeat=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df793d42-7dfd-4b79-9606-5c2d2f6d15fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find distances between points\n",
    "cnt_neighbors = 6\n",
    "neighbors = NearestNeighbors(n_neighbors=cnt_neighbors)\n",
    "neighbors.fit(X_train)\n",
    "distances, indices = neighbors.kneighbors(X_train)\n",
    "\n",
    "# PLot distances\n",
    "distance_desc = sorted(distances[:, 1], reverse=True)\n",
    "plt.plot(list(range(1,len(distance_desc)+1)), distance_desc)\n",
    "plt.xlabel('Number of points')\n",
    "plt.ylabel('Distance')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f4eb03-59d7-45cc-a2d5-67f277a99794",
   "metadata": {},
   "outputs": [],
   "source": [
    "kneedle = KneeLocator(range(1, len(distance_desc) + 1), distance_desc,\n",
    "                      S=1.0, curve='convex', direction='decreasing')\n",
    "kneedle.plot_knee_normalized()\n",
    "print(kneedle.elbow, kneedle.knee_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ddaee1-3d1e-48fa-a56e-d2be78d18369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_cuts_3d_cluster(X_train, y_train, cluster):\n",
    "    df = X_train.copy()\n",
    "    df['cluster'] = cluster\n",
    "    df['cluster'] = df['cluster'].astype('category')\n",
    "\n",
    "    categories = df['cluster'].cat.categories\n",
    "    colors = sb.color_palette(\"hls\", len(categories))\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 3))\n",
    "\n",
    "    for i, axes in enumerate(((0, 1), (0, 2), (1, 2))):\n",
    "        a, b = axes\n",
    "         \n",
    "        for label, color in zip(categories, colors):\n",
    "            rows = list(df[df['cluster'] == label].index)\n",
    "            x = df.loc[rows, df.columns[a]]\n",
    "            y = df.loc[rows, df.columns[b]]\n",
    "            ax[i].scatter(x, y, s=1, color=color, label=label)\n",
    "\n",
    "        ax[i].set_xlabel(df.columns[a])\n",
    "        ax[i].set_ylabel(df.columns[b])\n",
    "        ax[i].grid()\n",
    "        ax[i].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbdec95-9834-431f-8ece-7a479f6cec4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range of values is MinMaxScaled in range (0, 1) - eps must be smaller than 1\n",
    "# Noisy samples are given the label -1.\n",
    "clustering = DBSCAN(eps=0.1, min_samples=5, metric='l2')\n",
    "clustering.fit(X_train)\n",
    "y_train_labels = clustering.labels_\n",
    "y_predict = clustering.fit_predict(X_test)\n",
    "\n",
    "cross_cuts_3d_cluster(X_train, y_train, y_train_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdb31b2-0a7e-4470-a70d-fa499fe23fe9",
   "metadata": {},
   "source": [
    "## Half-space Trees (online)\n",
    "Half-Space Trees (window size, ensemble size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e9f2d9-8ae6-44e0-af3c-b143c4f2daff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train.iloc[:,0].to_numpy()\n",
    "\n",
    "hst = anomaly.HalfSpaceTrees(n_trees=5, height=3, window_size=3, seed=42)\n",
    "\n",
    "for x in X[:3]:\n",
    "    hst = hst.learn_one({'x': x})\n",
    "\n",
    "for x in X:\n",
    "    features = {'x': x}\n",
    "    hst = hst.learn_one(features)\n",
    "    print(f'Anomaly score for x={x:.3f}: {hst.score_one(features):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8278cc-c5f1-4b16-99fa-438dde8d0910",
   "metadata": {},
   "source": [
    "## DenStream (online)\n",
    "DenStream (μ, ε, beta, λ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8acd25-c6d6-4d8e-8e3b-d91586ccc639",
   "metadata": {},
   "outputs": [],
   "source": [
    "denstream = cluster.DenStream(\n",
    "    decaying_factor=0.01,\n",
    "    beta=0.5,\n",
    "    mu=2.5,\n",
    "    epsilon=0.5,\n",
    "    n_samples_init=10\n",
    ")\n",
    "# Choose one feature (from example)\n",
    "X = X_train.to_numpy()\n",
    "\n",
    "for x, _ in stream.iter_array(X):\n",
    "    denstream = denstream.learn_one(x)\n",
    "\n",
    "denstream.predict_one({0: -1, 1: -2})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

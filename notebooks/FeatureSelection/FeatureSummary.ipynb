{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gmean\n",
    "from sklearn.feature_selection import mutual_info_classif, f_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.decomposition import PCA\n",
    "from typing import List, Set, Tuple, Dict\n",
    "from river import feature_selection, stream, preprocessing\n",
    "from tqdm.notebook import tqdm\n",
    "from enum import Enum, auto\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from vibrodiagnostics import selection, models\n",
    "\n",
    "\n",
    "PATH_PREFIX = '../../datasets/'\n",
    "FEATURES_PATH =  os.path.join(PATH_PREFIX, 'features_data')\n",
    "\n",
    "TD_FD_FEATURES = os.path.join(FEATURES_PATH, selection.TIME_AND_FREQ_FEATURES_PATH)\n",
    "TD_FEATURES = os.path.join(FEATURES_PATH, selection.TIME_FEATURES_PATH)\n",
    "FD_FEATURES = os.path.join(FEATURES_PATH, selection.FREQ_FEATURES_PATH)\n",
    "\n",
    "# METRICS_TITLES = ('Correlation', 'F statistic', 'Mutual information')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faults = {\n",
    "    'A': {\n",
    "        'normal': 'normal',\n",
    "        'imbalance': 'imbalance',\n",
    "        'horizontal-misalignment': 'misalignment',\n",
    "        'vertical-misalignment': 'misalignment',\n",
    "        'underhang-outer_race': 'outer race fault',\n",
    "        'underhang-cage_fault': 'cage fault',\n",
    "        'underhang-ball_fault': 'ball fault'\n",
    "    },\n",
    "    'B': {\n",
    "        'normal': 'normal',\n",
    "        'imbalance': 'imbalance',\n",
    "        'horizontal-misalignment': 'misalignment',\n",
    "        'vertical-misalignment': 'misalignment',\n",
    "        'overhang-cage_fault': 'cage fault',\n",
    "        'overhang-ball_fault': 'ball fault',\n",
    "        'overhang-outer_race': 'outer race fault'\n",
    "    }\n",
    "}\n",
    "\n",
    "placements = {\n",
    "    'A': ['ax', 'ay', 'az'],\n",
    "    'B': ['bx', 'by', 'bz']\n",
    "}\n",
    "\n",
    "\n",
    "domains = {'temporal': TD_FEATURES, 'spectral': FD_FEATURES}\n",
    "rpm_limit = [False, True]\n",
    "target = ['fault', 'anomaly_60', 'anomaly_90']\n",
    "placement = ['A', 'B']\n",
    "online = [False, True]\n",
    "GENERATE = False\n",
    "\n",
    "\n",
    "class ExperimentOutput(Enum):\n",
    "    COUNTS = auto()\n",
    "    BEST_SET = auto()\n",
    "    RANKS = auto()\n",
    "    SCORES_RANGE = auto()\n",
    "    PCA = auto()\n",
    "    SILHOUETTE = auto()\n",
    "    BEST_CORR = auto()\n",
    "    BEST_F_STAT = auto()\n",
    "    BEST_MI = auto()\n",
    "\n",
    "\n",
    "def get_features_list(domains):\n",
    "    features = []\n",
    "    for dname, dataset in domains.items():\n",
    "        names = pd.read_csv(dataset)\n",
    "        names = names.columns.str.extract(r'([a-z]{2})_([a-z\\_\\-]+)')[1].unique()\n",
    "        features.extend([f'{dname}_{col.strip(\"_\")}' for col in names if not pd.isnull(col)])\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "temporal_columns = get_features_list({'temporal': TD_FEATURES})\n",
    "spectral_columns = get_features_list({'spectral': FD_FEATURES})\n",
    "all_columns = temporal_columns + spectral_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silhouette_scores(X_train, X_test, Y_train, Y_test, best_features, pc):\n",
    "    Y_train = Y_train.reset_index(drop=True).astype('category')\n",
    "    Y_test = Y_test.reset_index(drop=True).astype('category')\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train[X_train.columns] = scaler.fit_transform(X_train)\n",
    "    X_test[X_test.columns] = scaler.transform(X_test)    \n",
    "\n",
    "    model = PCA(n_components=pc).fit(X_train)\n",
    "    X_train_pca = pd.DataFrame(model.transform(X_train))\n",
    "    X_test_pca = pd.DataFrame(model.transform(X_test))\n",
    "\n",
    "    return {\n",
    "        'train': silhouette_score(X_train[best_features], Y_train),\n",
    "        'test': silhouette_score(X_test[best_features], Y_test),\n",
    "        'train_pca': silhouette_score(X_train_pca, Y_train),\n",
    "        'test_pca': silhouette_score(X_test_pca, Y_test)\n",
    "    }\n",
    "\n",
    "\n",
    "def pca_explained_variances(X_train: pd.DataFrame, pc: int) -> Dict[str, float]:\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train[X_train.columns] = scaler.fit_transform(X_train)\n",
    "    model = PCA(n_components=pc).fit(X_train)    \n",
    "    return {f'PC{pc}': var for pc, var in enumerate(model.explained_variance_ratio_, start=1)}\n",
    "\n",
    "\n",
    "def batch_feature_ranking(X: pd.DataFrame, Y: pd.DataFrame, mode: str = 'rank') -> pd.DataFrame:\n",
    "    metric_ranks = pd.DataFrame()\n",
    "    METRICS_OFFLINE = {\n",
    "        'corr': selection.corr_classif, \n",
    "        'f_stat': f_classif,\n",
    "        'mi': mutual_info_classif\n",
    "    }\n",
    "\n",
    "    if mode in METRICS_OFFLINE:\n",
    "        metric = METRICS_OFFLINE[mode]\n",
    "        scores = metric(X, Y)\n",
    "        if isinstance(scores, tuple):\n",
    "            scores = scores[0]\n",
    "        leaderboard = (\n",
    "            pd.DataFrame(zip(X.columns, scores), columns=['feature', 'rank'])\n",
    "            .set_index('feature')\n",
    "            .sort_values(by='rank', ascending=False)\n",
    "        )\n",
    "        return leaderboard\n",
    "\n",
    "    elif mode == 'rank':\n",
    "        for metric_name, metric in METRICS_OFFLINE.items():\n",
    "            scores = metric(X, Y)\n",
    "            if isinstance(scores, tuple):\n",
    "                scores = scores[0]\n",
    "            leaderboard = (\n",
    "                pd.DataFrame(zip(X.columns, scores), columns=['feature', 'score'])\n",
    "                .set_index('feature')\n",
    "                .sort_values(by='score', ascending=False)\n",
    "            )\n",
    "            metric_ranks[metric_name] = leaderboard\n",
    "        \n",
    "        ranks = metric_ranks.rank(axis='rows', method='first', ascending=False)\n",
    "        return ranks.apply(gmean, axis=1).sort_values().to_frame(name='rank')\n",
    "    \n",
    "\n",
    "def online_feature_ranking(X: pd.DataFrame, Y: pd.Series, mode: str = 'rank') -> pd.DataFrame:\n",
    "    METRICS_ONLINE = {\n",
    "        'corr': selection.Correlation, \n",
    "        'f_stat': selection.FisherScore,\n",
    "        'mi': selection.MutualInformation\n",
    "    }\n",
    "\n",
    "    if mode in METRICS_ONLINE:\n",
    "        metric = METRICS_ONLINE[mode]\n",
    "        estimator = feature_selection.SelectKBest(similarity=metric(), k=2)\n",
    "        for xs, ys in stream.iter_pandas(X, Y):\n",
    "            estimator.learn_one(xs, ys)\n",
    "\n",
    "        best = [dict(estimator.leaderboard.copy())]\n",
    "        features = pd.DataFrame.from_records(best)\n",
    "\n",
    "    elif mode == 'rank':\n",
    "        estimators = [\n",
    "            feature_selection.SelectKBest(similarity=metric(), k=2)\n",
    "            for metric in METRICS_ONLINE.values()\n",
    "        ]\n",
    "\n",
    "        best = []\n",
    "        for xs, ys in stream.iter_pandas(X, Y):\n",
    "            for method in estimators:\n",
    "                method.learn_one(xs, ys)\n",
    "\n",
    "            scores = [method.leaderboard.copy() for method in estimators]\n",
    "            scores = pd.DataFrame.from_records(scores).T\n",
    "            ranks = scores.rank(axis='rows', method='first', ascending=False)\n",
    "            ranks = ranks.apply(gmean, axis=1).to_dict()   # Smallest rank is the best\n",
    "            best.append(ranks)   \n",
    "\n",
    "        features = pd.DataFrame.from_records(best)\n",
    "\n",
    "    return (\n",
    "        features.tail(1)\n",
    "        .reset_index(drop=True)\n",
    "        .T.rename(columns={0: 'rank'})\n",
    "        .reset_index()\n",
    "        .rename(columns={'index': 'feature'})\n",
    "        .set_index('feature')\n",
    "        .sort_values(by='rank', ascending=True)\n",
    "    )\n",
    "\n",
    "\n",
    "def compute_correlations(X: pd.DataFrame, corr_above: float) -> Set[Tuple[str, str]]:\n",
    "    corr = [\n",
    "        {'feature_1': k[0], 'feature_2': k[1], 'corr': v}\n",
    "        for k, v in X.corr().abs().stack().to_dict().items()\n",
    "        if k[0] != k[1]\n",
    "    ]\n",
    "    corr = pd.DataFrame.from_records(corr)\n",
    "\n",
    "    # Remove correlated features independent of tuple order\n",
    "    correlations = corr[corr['corr'] >= corr_above][\n",
    "        ['feature_1', 'feature_2']\n",
    "    ].to_numpy()\n",
    "    similar_pairs = set([(a, b) for a, b in correlations])\n",
    "    similar_pairs.update([(b, a) for a, b in correlations])\n",
    "    return  similar_pairs\n",
    "\n",
    "\n",
    "def best_columns(ranks: pd.DataFrame, corr: Set[Tuple[str, str]], n: int) -> List[str]:\n",
    "    columns = []\n",
    "    for feature in ranks.index:\n",
    "        # Make pairs with existing columns\n",
    "        candidates = [\n",
    "            col for col in columns \n",
    "            if (feature, col) in corr\n",
    "        ]        \n",
    "        # Append only if not correlation detected\n",
    "        if len(candidates) == 0:\n",
    "            columns.append(feature)\n",
    "\n",
    "    # Limit to n features\n",
    "    columns = columns[:n]\n",
    "    return columns\n",
    "\n",
    "\n",
    "def best_subset(ranks: pd.DataFrame, corr: Set[Tuple[str, str]], n: int) -> pd.DataFrame:\n",
    "    columns = best_columns(ranks, corr, n)\n",
    "    subset = ranks.copy()\n",
    "    subset['rank'] = False\n",
    "    subset[subset.index.isin(tuple(columns))] = True\n",
    "    return subset\n",
    "\n",
    "\n",
    "def load_source(dataset: str, domain: str, row: dict):\n",
    "    RPM = 2500\n",
    "    RPM_RANGE = 500\n",
    "    features = pd.read_csv(dataset).fillna(0)\n",
    "\n",
    "    # Choosing rpm range\n",
    "    if row['rpm_limit']:\n",
    "        features = features[features['rpm'].between(RPM - RPM_RANGE, RPM + RPM_RANGE, inclusive='both')]\n",
    "\n",
    "    # Labeling anomaly severity levels\n",
    "    target = re.search(r'([a-z]+)_?(\\d+)?', row['target'])\n",
    "    anomaly_severity = target.group(2) or '60'\n",
    "    anomaly_severity = float(anomaly_severity) / 100\n",
    "\n",
    "    # Choose measurement placement: A or B\n",
    "    place = row['placement']\n",
    "    axis = placements[place]\n",
    "    features = features[features['fault'].isin(tuple(faults[place]))]\n",
    "    features = models.fault_labeling(features, faults[place], anomaly_severity)\n",
    "\n",
    "    columns = features.columns.str.startswith(tuple(axis))\n",
    "    X = features[features.columns[columns]]\n",
    "\n",
    "    # Select predicted variable column\n",
    "    label = target.group(1)\n",
    "    Y = features[label].astype('category')\n",
    "\n",
    "    # Filter columns in feature domain with window size 2**14\n",
    "    if domain == 'spectral':\n",
    "        window_size = 2**14\n",
    "        X = X.loc[:,X.columns.str.endswith(f'_{window_size}')]\n",
    "        X.columns = X.columns.str.extract(r'(\\w+)_\\w+$')[0]\n",
    "\n",
    "    # Calculate feature magnitudes from 3D vector\n",
    "    feature_names = get_features_list({domain: dataset})\n",
    "    result = pd.DataFrame()\n",
    "    for name in feature_names:              \n",
    "        # Remove prefix: temporal, spectral\n",
    "        name = re.search(r'[a-z]+_([\\w\\_]+)', name).group(1)\n",
    "        vector_dims = [f'{dim}_{name}' for dim in axis]\n",
    "        result[name] = X[vector_dims].apply(np.linalg.norm, axis=1)\n",
    "    X = result\n",
    "\n",
    "    # Batch / Online hold-out (balance and event sequencing)\n",
    "    train_size = 0.8\n",
    "    if row['online']:\n",
    "        # Shuffle order within severity level and order event with increasing severity\n",
    "        groups = [\n",
    "            df.sample(frac=1, random_state=10)\n",
    "            for i, df in (\n",
    "                features.sort_values(by='severity_level').groupby('severity_level')\n",
    "            )\n",
    "        ]\n",
    "        rows = list(pd.concat(groups).index)\n",
    "        X = X.loc[rows].reset_index(drop=True)\n",
    "        Y = Y.loc[rows].reset_index(drop=True)\n",
    "\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "            X, Y, train_size=train_size, random_state=10\n",
    "        )   \n",
    "        X_train, X_test, Y_train, Y_test = (\n",
    "            X_train.sort_index(), X_test.sort_index(),\n",
    "            Y_train.sort_index(), Y_test.sort_index()\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        oversample = RandomOverSampler(sampling_strategy='not majority', random_state=10)\n",
    "        X, Y = oversample.fit_resample(X, Y.to_numpy())\n",
    "        X.reset_index(drop=True, inplace=True)\n",
    "        Y = pd.Series(Y)\n",
    "\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "            X, Y, train_size=train_size, stratify=Y, random_state=10\n",
    "        )\n",
    "\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "\n",
    "def run_experiments(conditions: List[dict], exp_output: ExperimentOutput, pc=3) -> pd.DataFrame:\n",
    "    experiments = []\n",
    "\n",
    "    for row in tqdm(conditions):\n",
    "        experiment = row.copy()\n",
    "\n",
    "        for domain_label, dataset in domains.items():\n",
    "            X_train, X_test, Y_train, Y_test = load_source(dataset, domain_label, row)\n",
    "\n",
    "            # Count samples\n",
    "            if exp_output == ExperimentOutput.COUNTS:\n",
    "                experiment.update({'n_train': len(X_train), 'n_test': len(X_test), 'sum': len(X)})\n",
    "                break\n",
    "\n",
    "            elif exp_output == ExperimentOutput.PCA:\n",
    "                experiment = row.copy()\n",
    "                experiment.update({'domain': domain_label})\n",
    "                experiment.update(pca_explained_variances(X_train, pc))\n",
    "                experiments.append(experiment)\n",
    "                continue\n",
    "\n",
    "            elif exp_output == ExperimentOutput.SILHOUETTE:\n",
    "                synonyms = compute_correlations(X_train, corr_above=0.95)\n",
    "                if row['online']:\n",
    "                    ranks = online_feature_ranking(X_train, Y_train)\n",
    "                else:\n",
    "                    ranks = batch_feature_ranking(X_train, Y_train)\n",
    "    \n",
    "                best_features = best_columns(ranks, synonyms, n=3)\n",
    "                scores = silhouette_scores(X_train, X_test, Y_train, Y_test, best_features, pc)\n",
    "                experiment = row.copy()\n",
    "                experiment.update({'domain': domain_label})\n",
    "                experiment.update(scores)\n",
    "                experiments.append(experiment)\n",
    "                continue\n",
    "\n",
    "            elif exp_output == ExperimentOutput.BEST_SET:\n",
    "                if row['online']:\n",
    "                    ranks = online_feature_ranking(X_train, Y_train)\n",
    "                else:\n",
    "                    ranks = batch_feature_ranking(X_train, Y_train)\n",
    "                synonyms = compute_correlations(X_train, corr_above=0.95)\n",
    "                subset = best_subset(ranks, synonyms, n=3)\n",
    "                output = subset\n",
    "\n",
    "            elif exp_output == ExperimentOutput.BEST_CORR:\n",
    "                if row['online']:\n",
    "                    ranks = online_feature_ranking(X_train, Y_train, 'corr')\n",
    "                else:\n",
    "                    ranks = batch_feature_ranking(X_train, Y_train, 'corr')\n",
    "                synonyms = compute_correlations(X_train, corr_above=0.95)\n",
    "                subset = best_subset(ranks, synonyms, n=3)\n",
    "                output = subset\n",
    "\n",
    "            elif exp_output == ExperimentOutput.BEST_F_STAT:\n",
    "                if row['online']:\n",
    "                    ranks = online_feature_ranking(X_train, Y_train, 'f_stat')\n",
    "                else:\n",
    "                    ranks = batch_feature_ranking(X_train, Y_train,'f_stat')\n",
    "                synonyms = compute_correlations(X_train, corr_above=0.95)\n",
    "                subset = best_subset(ranks, synonyms, n=3)\n",
    "                output = subset\n",
    "\n",
    "            elif exp_output == ExperimentOutput.BEST_MI:\n",
    "                if row['online']:\n",
    "                    ranks = online_feature_ranking(X_train, Y_train, 'mi')\n",
    "                else:\n",
    "                    ranks = batch_feature_ranking(X_train, Y_train, 'mi')\n",
    "                synonyms = compute_correlations(X_train, corr_above=0.95)\n",
    "                subset = best_subset(ranks, synonyms, n=3)\n",
    "                output = subset\n",
    "    \n",
    "            elif exp_output == ExperimentOutput.RANKS:\n",
    "                if row['online']:\n",
    "                    ranks = online_feature_ranking(X_train, Y_train)\n",
    "                else:\n",
    "                    ranks = batch_feature_ranking(X_train, Y_train)\n",
    "                output = ranks\n",
    "\n",
    "            output.reset_index(inplace=True)\n",
    "            output['feature'] = output['feature'].apply(lambda s: f'{domain_label}_{s}')\n",
    "            output = dict(zip(list(output['feature']), list(output['rank'])))\n",
    "            experiment.update(output)\n",
    "\n",
    "        if exp_output not in (ExperimentOutput.PCA, ExperimentOutput.SILHOUETTE):\n",
    "            experiments.append(experiment)\n",
    "\n",
    "    return pd.DataFrame.from_records(experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['rpm_limit', 'target', 'placement', 'online']\n",
    "initial_conditions = [\n",
    "    dict(zip(column_names, row)) \n",
    "    for row in itertools.product(rpm_limit, target, placement, online)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Majority voting: feature in subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 member sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE:\n",
    "    membership = run_experiments(initial_conditions, ExperimentOutput.BEST_SET)\n",
    "    membership.to_csv('best_set/rank_product.csv', index=False)\n",
    "    membership = run_experiments(initial_conditions, ExperimentOutput.BEST_CORR)\n",
    "    membership.to_csv('best_set/corr.csv', index=False)\n",
    "    membership = run_experiments(initial_conditions, ExperimentOutput.BEST_F_STAT)\n",
    "    membership.to_csv('best_set/fstat.csv', index=False)\n",
    "    membership = run_experiments(initial_conditions, ExperimentOutput.BEST_MI)\n",
    "    membership.to_csv('best_set/mi.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globally best features (batch and online)\n",
    "def globally_best_batch_features(filename):\n",
    "    best_set_membership = pd.read_csv(filename)\n",
    "\n",
    "    group = best_set_membership[best_set_membership['online'] == False]\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 4))\n",
    "    for i, col in enumerate([temporal_columns, spectral_columns]):\n",
    "        graph = group[col][group == True].count(axis=0).sort_values(ascending=False)\n",
    "        print(graph)\n",
    "        ax[i].grid()\n",
    "        ax[i].bar([re.search('[a-z]+_(\\w+)', s).group(1) for s in graph.index], graph)\n",
    "    plt.show()\n",
    "\n",
    "    # Online\n",
    "    group = best_set_membership[best_set_membership['online'] == True]\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 4))\n",
    "    for i, col in enumerate([temporal_columns, spectral_columns]):\n",
    "        graph = group[col][group == True].count(axis=0).sort_values(ascending=False)\n",
    "        print(graph)\n",
    "        ax[i].grid()\n",
    "        ax[i].bar([re.search('[a-z]+_(\\w+)', s).group(1) for s in graph.index], graph)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globally_best_batch_features('best_set/rank_product.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globally_best_batch_features('best_set/corr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globally_best_batch_features('best_set/fstat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globally_best_batch_features('best_set/mi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_set_membership = pd.read_csv('best_set/rank_product.csv')\n",
    "agg = pd.DataFrame()\n",
    "for key, group in best_set_membership.groupby(by=['rpm_limit', 'online']):\n",
    "    t_situation = group[temporal_columns][group == True].count(axis=0).sort_values(ascending=False).head(3)\n",
    "    f_situation = group[spectral_columns][group == True].count(axis=0).sort_values(ascending=False).head(3)\n",
    "    agg[key] = pd.concat([t_situation, f_situation]).index\n",
    "agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_set_membership = pd.read_csv('best_set/rank_product.csv')\n",
    "agg = pd.DataFrame()\n",
    "for key, group in best_set_membership.groupby(by=['rpm_limit', 'online', 'target']):\n",
    "    t_situation = group[temporal_columns][group == True].count(axis=0).sort_values(ascending=False).head(3)\n",
    "    f_situation = group[spectral_columns][group == True].count(axis=0).sort_values(ascending=False).head(3)\n",
    "    agg[key] = pd.concat([t_situation, f_situation]).index\n",
    "agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rank product: feature ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE:\n",
    "    best_set_ranks = run_experiments(initial_conditions, ExperimentOutput.RANKS)    # 6 minutes\n",
    "    best_set_ranks.to_csv('best_set_ranks.csv', index=False)\n",
    "    best_set_ranks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_set_ranks = pd.read_csv('best_set_ranks.csv')\n",
    "# Globally best features (lower rank is better)\n",
    "\n",
    "group = best_set_ranks[best_set_ranks['online'] == False]\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 4))\n",
    "for i, col in enumerate([temporal_columns, spectral_columns]):\n",
    "    graph = group[col].apply(gmean, axis=0).sort_values(ascending=True)\n",
    "    print(graph)\n",
    "    ax[i].grid()\n",
    "    ax[i].bar([re.search('[a-z]+_(\\w+)', s).group(1) for s in graph.index], graph)\n",
    "plt.show()\n",
    "\n",
    "# Online\n",
    "group = best_set_ranks[best_set_ranks['online'] == True]\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 4))\n",
    "for i, col in enumerate([temporal_columns, spectral_columns]):\n",
    "    graph = group[col].apply(gmean, axis=0).sort_values(ascending=True)\n",
    "    print(graph)\n",
    "    ax[i].grid()\n",
    "    ax[i].bar([re.search('[a-z]+_(\\w+)', s).group(1) for s in graph.index], graph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary (absolute counts) - RPM limited/unlimted and machinery element\n",
    "best_set_ranks = pd.read_csv('best_set_ranks.csv')\n",
    "agg = pd.DataFrame()\n",
    "for key, group in best_set_ranks.groupby(by=['rpm_limit', 'online']):\n",
    "    agg[key] = group[all_columns].apply(gmean, axis=0)\n",
    "agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_set_ranks = pd.read_csv('best_set_ranks.csv')\n",
    "agg = pd.DataFrame()\n",
    "for key, group in best_set_ranks.groupby(by=['rpm_limit', 'online']):\n",
    "    t_situation = group[temporal_columns].apply(gmean, axis=0).sort_values(ascending=True).head(3)\n",
    "    f_situation = group[spectral_columns].apply(gmean, axis=0).sort_values(ascending=True).head(3)\n",
    "    agg[key] = pd.concat([t_situation, f_situation]).index\n",
    "agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary (absolute counts) - RPM limited/unlimted and machinery element\n",
    "best_set_ranks = pd.read_csv('best_set_ranks.csv')\n",
    "agg = pd.DataFrame()\n",
    "for key, group in best_set_ranks.groupby(by=['rpm_limit', 'online', 'target']):\n",
    "    agg[key] = group[all_columns].apply(gmean, axis=0)\n",
    "agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_set_ranks = pd.read_csv('best_set_ranks.csv')\n",
    "agg = pd.DataFrame()\n",
    "for key, group in best_set_ranks.groupby(by=['rpm_limit', 'online', 'target']):\n",
    "    t_situation = group[temporal_columns].apply(gmean, axis=0).sort_values(ascending=False).head(3)\n",
    "    f_situation = group[spectral_columns].apply(gmean, axis=0).sort_values(ascending=False).head(3)\n",
    "    agg[key] = pd.concat([t_situation, f_situation]).index\n",
    "agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best features by experiment\n",
    "- Majority voting\n",
    "- Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature_names(feature_set):\n",
    "    return [re.search('[a-z]+_(\\w+)', s).group(1) for s in feature_set.index]\n",
    "\n",
    "def best_featue_set_methods(filename):\n",
    "    best_set_membership = pd.read_csv(filename)\n",
    "    feature_sets = []\n",
    "    indexer = ['placement', 'online', 'rpm_limit', 'target']\n",
    "    for key, group in best_set_membership.groupby(by=indexer):\n",
    "        t_situation = group[temporal_columns][group == True].count(axis=0).sort_values(ascending=False).head(3)\n",
    "        f_situation = group[spectral_columns][group == True].count(axis=0).sort_values(ascending=False).head(3)\n",
    "\n",
    "        # Extract feature names\n",
    "        temporal = list(sorted(extract_feature_names(t_situation)))\n",
    "        spectral = list(sorted(extract_feature_names(f_situation)))\n",
    "\n",
    "        fset = {'placement': key[0], 'online': key[1], 'rpm_limit': key[2], 'target': key[3], 'temporal': temporal , 'spectral': spectral}\n",
    "        feature_sets.append(fset)\n",
    "\n",
    "    return pd.DataFrame.from_records(feature_sets).set_index(indexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_featue_set_methods('best_set/rank_product.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_featue_set_methods('best_set/corr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_featue_set_methods('best_set/fstat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_featue_set_methods('best_set/mi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature_names(feature_set):\n",
    "    return [re.search('[a-z]+_(\\w+)', s).group(1) for s in feature_set.index]\n",
    "\n",
    "best_set_membership = pd.read_csv('best_set_ranks.csv')\n",
    "feature_sets = []\n",
    "indexer = ['placement', 'online', 'rpm_limit', 'target']\n",
    "for key, group in best_set_membership.groupby(by=indexer):\n",
    "    t_situation = group[temporal_columns].apply(gmean, axis=0).sort_values(ascending=False).head(3)\n",
    "    f_situation = group[spectral_columns].apply(gmean, axis=0).sort_values(ascending=False).head(3)\n",
    "\n",
    "    # Extract feature names\n",
    "    temporal = list(sorted(extract_feature_names(t_situation)))\n",
    "    spectral = list(sorted(extract_feature_names(f_situation)))\n",
    "\n",
    "    fset = {'placement': key[0], 'online': key[1], 'rpm_limit': key[2], 'target': key[3], 'temporal': temporal , 'spectral': spectral}\n",
    "    feature_sets.append(fset)\n",
    "\n",
    "pd.DataFrame.from_records(feature_sets).set_index(indexer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA explained variance (batch only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['rpm_limit', 'target', 'placement', 'online']\n",
    "batch_initial_conditions = [\n",
    "    dict(zip(column_names, row)) \n",
    "    for row in itertools.product(rpm_limit, target, placement, [False])\n",
    "]\n",
    "pca_vars = run_experiments(batch_initial_conditions, ExperimentOutput.PCA)\n",
    "pca_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_explained_variances(pca_vars_in):\n",
    "    selected_columns = ['target', 'PC1', 'PC2', 'PC3']\n",
    "    groupby_columns = ['target']\n",
    "\n",
    "    pca_A_temporal = pca_vars_in[\n",
    "        (pca_vars_in['placement'] == 'A') & (pca_vars_in['domain'] == 'temporal')\n",
    "    ][selected_columns].set_index(groupby_columns)\n",
    "    pca_B_temporal = pca_vars_in[\n",
    "        (pca_vars_in['placement'] == 'B') & (pca_vars_in['domain'] == 'temporal')\n",
    "    ][selected_columns].set_index(groupby_columns)\n",
    "\n",
    "    pca_A_spectral = pca_vars_in[\n",
    "        (pca_vars_in['placement'] == 'A') & (pca_vars_in['domain'] == 'spectral')\n",
    "    ][selected_columns].set_index(groupby_columns)\n",
    "    pca_B_spectral = pca_vars_in[\n",
    "        (pca_vars_in['placement'] == 'B') & (pca_vars_in['domain'] == 'spectral')\n",
    "    ][selected_columns].set_index(groupby_columns)\n",
    "\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(8, 8))\n",
    "    pca_A_temporal.plot.bar(stacked=True, grid=True, ax=ax[0][0], title='Temporal features, Placement: A', xlabel='', ylabel='Explained variance')\n",
    "    pca_B_temporal.plot.bar(stacked=True, grid=True, ax=ax[0][1], title='Temporal features, Placement: B', xlabel='', ylabel='Explained variance')\n",
    "    pca_A_spectral.plot.bar(stacked=True, grid=True, ax=ax[1][0], title='Spectral features, Placement: A', xlabel='', ylabel='Explained variance')\n",
    "    pca_B_spectral.plot.bar(stacked=True, grid=True, ax=ax[1][1], title='Spectral features, Placement: B', xlabel='', ylabel='Explained variance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# No RPM limit\n",
    "plot_explained_variances(pca_vars[pca_vars['rpm_limit'] == False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RPM limited\n",
    "plot_explained_variances(pca_vars[pca_vars['rpm_limit'] == True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline for number of features: Principal components explanation power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column_names = ['rpm_limit', 'target', 'placement', 'online']\n",
    "# batch_initial_conditions = [\n",
    "#     dict(zip(column_names, row)) \n",
    "#     for row in itertools.product(rpm_limit, target, placement, [False])\n",
    "# ]\n",
    "\n",
    "# pca_components_power = []\n",
    "# for pc in range(1, 5):\n",
    "#     e_pc = (\n",
    "#         run_experiments(batch_initial_conditions, ExperimentOutput.PCA, pc=pc)\n",
    "#         .drop(columns=['online'])\n",
    "#         .set_index(['rpm_limit', 'target', 'placement', 'domain'])\n",
    "#     )\n",
    "#     e_silh = (\n",
    "#         run_experiments(batch_initial_conditions, ExperimentOutput.SILHOUETTE, pc=pc)\n",
    "#         .drop(columns=['online'])\n",
    "#         .set_index(['rpm_limit', 'target', 'placement', 'domain'])\n",
    "#     )\n",
    "#     e = e_pc.join(e_silh)\n",
    "#     e['n_pc'] = pc\n",
    "#     pca_components_power.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_power = pd.concat(pca_components_power).fillna(0).reset_index()\n",
    "pca_power = pca_power[(pca_power['rpm_limit'] == False) & (pca_power['target'].str.startswith('fault'))]\n",
    "pca_power = pca_power[['n_pc'] + list(pca_power.columns[pca_power.columns.str.startswith('PC')])]\n",
    "pca_power.groupby(by='n_pc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_power = pd.concat(pca_components_power).fillna(0).reset_index()\n",
    "pca_power = pca_power[(pca_power['rpm_limit'] == False) & (pca_power['target'].str.startswith('anomaly'))]\n",
    "pca_power = pca_power[['n_pc'] + list(pca_power.columns[pca_power.columns.str.startswith('PC')])]\n",
    "pca_power.groupby(by='n_pc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_power = pd.concat(pca_components_power).fillna(0).reset_index()\n",
    "pca_power = pca_power[(pca_power['rpm_limit'] == False)  & (pca_power['target'].str.startswith('fault'))]\n",
    "pca_power = pca_power[['n_pc'] + list(pca_power.columns[pca_power.columns.str.startswith('PC')])]\n",
    "pca_power.groupby(by='n_pc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_power = pd.concat(pca_components_power).fillna(0).reset_index()\n",
    "pca_power = pca_power[(pca_power['rpm_limit'] == False) & (pca_power['target'].str.startswith('anomaly'))]\n",
    "pca_power = pca_power[['n_pc'] + list(pca_power.columns[pca_power.columns.str.startswith('PC')])]\n",
    "pca_power.groupby(by='n_pc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_power = pd.concat(pca_components_power).fillna(0).reset_index()\n",
    "pca_power = pca_power[(pca_power['rpm_limit'] == False) & (pca_power['target'].str.startswith('anomaly'))]\n",
    "pca_power = pca_power[['n_pc'] + list(pca_power.columns[pca_power.columns.str.endswith('_pca')])]\n",
    "pca_power.groupby(by='n_pc').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Silhouette scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = run_experiments(batch_initial_conditions, ExperimentOutput.SILHOUETTE)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_silhouette_scores(scores, cols):\n",
    "    selected_columns = ['target'] + cols\n",
    "    groupby_columns = ['target']\n",
    "\n",
    "    scores_A_temporal = scores[\n",
    "        (scores['placement'] == 'A') & (scores['domain'] == 'temporal')\n",
    "    ][selected_columns].set_index(groupby_columns)\n",
    "    scores_B_temporal = scores[\n",
    "        (scores['placement'] == 'B') & (scores['domain'] == 'temporal')\n",
    "    ][selected_columns].set_index(groupby_columns)\n",
    "\n",
    "    scores_A_spectral = scores[\n",
    "        (scores['placement'] == 'A') & (scores['domain'] == 'spectral')\n",
    "    ][selected_columns].set_index(groupby_columns)\n",
    "    scores_B_spectral = scores[\n",
    "        (scores['placement'] == 'B') & (scores['domain'] == 'spectral')\n",
    "    ][selected_columns].set_index(groupby_columns)\n",
    "\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
    "    scores_A_temporal.plot.bar(grid=True, ax=ax[0][0], title='Temporal features, Placement: A', xlabel='', ylabel='Silhouette score')\n",
    "    scores_B_temporal.plot.bar(grid=True, ax=ax[0][1], title='Temporal features, Placement: B', xlabel='', ylabel='Silhouette variance')\n",
    "    scores_A_spectral.plot.bar(grid=True, ax=ax[1][0], title='Spectral features, Placement: A', xlabel='', ylabel='Silhouette variance')\n",
    "    scores_B_spectral.plot.bar(grid=True, ax=ax[1][1], title='Spectral features, Placement: B', xlabel='', ylabel='Silhouette variance')\n",
    "    plt.tight_layout()\n",
    "\n",
    "plot_silhouette_scores(scores[scores['rpm_limit'] == False], ['train', 'test'])\n",
    "#plt.suptitle('Best features, all RPM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_silhouette_scores(scores[scores['rpm_limit'] == False], ['train_pca', 'test_pca'])\n",
    "plt.suptitle('PCA, all RPM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counters = run_experiments(initial_conditions, ExperimentOutput.COUNTS)  \n",
    "counters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = (counters[['rpm_limit', 'online', 'target', 'n_train', 'n_test', 'sum']]\n",
    ".groupby(by=['rpm_limit', 'online', 'target'])\n",
    ".first())\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.loc[:, samples.columns != 'sum'].plot.bar(stacked=True, grid=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature distribution in diffrent classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_features(conditions: List[dict]):\n",
    "    for row in tqdm(conditions):\n",
    "        experiment = row.copy()\n",
    "\n",
    "        for domain_label, dataset in domains.items():\n",
    "            X_train, X_test, Y_train, Y_test = load_source(dataset, domain_label, row)\n",
    "\n",
    "            # MinMax scaled result\n",
    "            scaler = MinMaxScaler()\n",
    "            X_train_scaled = pd.DataFrame()\n",
    "            X_train_scaled[X_train.columns] = scaler.fit_transform(X_train)\n",
    "\n",
    "            # Diagonal of covariance matrix to see explained variance cov(A, A) = var(A)\n",
    "            # Variance threshold\n",
    "            train_cov = X_train_scaled.cov()\n",
    "            diagonal_cov = pd.Series(np.diag(train_cov), index=[train_cov.index, train_cov.columns])\n",
    "            diagonal_cov = diagonal_cov / diagonal_cov.sum()\n",
    "            diagonal_cov = diagonal_cov.sort_values(ascending=False)\n",
    "            print(row)\n",
    "            print(diagonal_cov)\n",
    "\n",
    "            X_train_scaled['target'] = Y_train\n",
    "            # Show boxplots split by predicted variable\n",
    "            X_train_scaled.boxplot(figsize=(15, 5))\n",
    "            plt.show()\n",
    "            X_train_scaled.boxplot(figsize=(20, 5), layout=(2, 6), by='target', sharey=False)\n",
    "            plt.show()\n",
    "\n",
    "column_names = ['rpm_limit', 'online', 'target', 'placement']\n",
    "batch_initial_conditions = [\n",
    "    dict(zip(column_names, row)) \n",
    "    for row in itertools.product(rpm_limit, target, placement, [False])\n",
    "]\n",
    "boxplot_features(batch_initial_conditions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

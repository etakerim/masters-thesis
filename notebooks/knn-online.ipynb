{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN streaming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DOMAIN = 'TD' \n",
    "DOMAIN = 'FD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import functools\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn import metrics as skmetrics\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from river import metrics\n",
    "from river import preprocessing\n",
    "from river import neighbors, utils, evaluate, stream\n",
    "\n",
    "import extraction\n",
    "import mafaulda\n",
    "import visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_online_learn(X, Y, window_len=1, learn_skip=0, clusters=False):\n",
    "    # Buffer true samples for learning for later: simulate delayed annotation\n",
    "    learning_window = []\n",
    "\n",
    "    # Model consists of scaler to give approximately same weight to all features and kNN\n",
    "    scaler = preprocessing.MinMaxScaler() \n",
    "    knn = neighbors.KNNClassifier(n_neighbors=5)\n",
    "\n",
    "    scores = []                 # List of tuples with accuracy, precision and recall score on each iteration\n",
    "    v_true = []                 # Append y true sample on each iteration\n",
    "    v_predict = []              # Append y predicted sample on each iteration\n",
    "\n",
    "    skipping = 0\n",
    "    started = False\n",
    "    order_saved = []\n",
    "    X['label'] = Y\n",
    "\n",
    "    for idx, row in tqdm(X.iterrows()):\n",
    "        x = {k: v for k, v in dict(row).items() if k != 'label'}\n",
    "        x_scaled = scaler.learn_one(x).transform_one(x)\n",
    "        y_true = row['label']\n",
    "        learning_window.append((x_scaled, y_true))\n",
    "\n",
    "        if started:\n",
    "            # Predict sample after at least one example has been learned\n",
    "            y_predict = knn.predict_one(x_scaled)\n",
    "            v_true.append(y_true)\n",
    "            v_predict.append(y_predict)\n",
    "            order_saved.append(idx)\n",
    "\n",
    "            scores.append([\n",
    "                idx,\n",
    "                skmetrics.accuracy_score(v_true, v_predict),\n",
    "                skmetrics.precision_score(v_true, v_predict, average='micro'),\n",
    "                skmetrics.recall_score(v_true, v_predict, average='micro')\n",
    "            ])\n",
    "\n",
    "        # Provide labels after window length has passed\n",
    "        if len(learning_window) == window_len:\n",
    "            for x, y in learning_window:\n",
    "                # Learn first sample at start of window\n",
    "                if skipping == learn_skip:\n",
    "                    started = True\n",
    "                    knn.learn_one(x, y)\n",
    "                    skipping = 0\n",
    "                else:\n",
    "                    skipping += 1\n",
    "            learning_window = []\n",
    "\n",
    "    if clusters:\n",
    "        return pd.Series(v_predict, index=order_saved)\n",
    "        \n",
    "    return pd.DataFrame(scores, columns=['step', 'accuracy', 'precision', 'recall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_source(domain: str, row: dict):\n",
    "    PATH = '../datasets/'\n",
    "    FEATURES_PATH = os.path.join(PATH, 'features')\n",
    "    MAFAULDA_TEMPORAL = os.path.join(FEATURES_PATH, 'MAFAULDA_TD.csv')\n",
    "    MAFAULDA_SPECTRAL = os.path.join(FEATURES_PATH, 'MAFAULDA_FD.csv')\n",
    "\n",
    "    dataset = {\n",
    "        'TD': MAFAULDA_TEMPORAL,\n",
    "        'FD': MAFAULDA_SPECTRAL,\n",
    "        'axis': {\n",
    "            'A': ['ax', 'ay', 'az'],\n",
    "            'B': ['bx', 'by', 'bz']\n",
    "        },\n",
    "        'labels': ['fault', 'severity', 'rpm']\n",
    "    }\n",
    "\n",
    "    placement = row['placement']\n",
    "    df = extraction.load_features(\n",
    "        dataset[domain],\n",
    "        dataset['axis'][placement],\n",
    "        dataset['labels']\n",
    "    )\n",
    "    frame = mafaulda.assign_labels(df, placement)\n",
    "    Y = frame['label']\n",
    "    X = frame.drop(columns=['label'])\n",
    "\n",
    "    # Batch / Online hold-out (balance and event sequencing)\n",
    "    train_size = 0.8\n",
    "\n",
    "    # Shuffle order within severity level and order event with increasing severity\n",
    "    features = mafaulda.label_severity(df, placement, 0.5, keep=True)\n",
    "    # Shuffle order within severity level and order event with increasing severity\n",
    "    groups = [\n",
    "        frame.sample(frac=1, random_state=10)\n",
    "        for i, frame in (\n",
    "            features\n",
    "            .sort_values(by='severity_level')\n",
    "            .groupby('severity_level')\n",
    "        )\n",
    "    ]\n",
    "    rows = list(pd.concat(groups).index)\n",
    "    \n",
    "    X = X.loc[rows].reset_index(drop=True)\n",
    "    Y = Y.loc[rows].reset_index(drop=True)\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, train_size=train_size, random_state=10\n",
    "    )  \n",
    "    X_train, X_test, Y_train, Y_test = (\n",
    "        X_train.sort_index(), X_test.sort_index(),\n",
    "        Y_train.sort_index(), Y_test.sort_index()\n",
    "    )\n",
    "\n",
    "    serevity_groups = pd.concat(groups)['severity_level'].reset_index(drop=True).sort_index()\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.plot(np.arange(0, len(X_train)), serevity_groups.loc[X_train.index], color='red')\n",
    "    ax.set_xlabel('Observations')\n",
    "    ax.set_ylabel('Severity level')\n",
    "    ax.grid()\n",
    "    plt.show()\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test   # WARNING: order matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XStream_fault, YStream_fault, _, YF1 = load_source(DOMAIN, {'placement': 'A', 'domain': DOMAIN})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evolution of faults and anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = visualize.plot_label_occurences(YStream_fault)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.plot_label_occurences(YF1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradual learning\n",
    "- 6 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = knn_online_learn(XStream_fault, YStream_fault, window_len=1)\n",
    "ax = results[['accuracy']].plot(\n",
    "    grid=True, legend=False, figsize=(8, 4),\n",
    "    xlabel='Sample', ylabel='Accuracy', title='Fault classes: 6, Window size: 1'\n",
    ")\n",
    "best = results.tail(1)\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Window learning\n",
    "- Compare classification accuracies for window sizes in one graph: (1, 10, 50, 100, 250)\n",
    "- Scenarios: fault, anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_window_lengths = (1, 10, 50, 100, 250)\n",
    "\n",
    "fault_evolution = pd.DataFrame()\n",
    "for n in tqdm(learning_window_lengths):\n",
    "    results = knn_online_learn(XStream_fault, YStream_fault, window_len=n)\n",
    "    accuracy = results['accuracy']\n",
    "    accuracy.index += n             # Starts learning after at least one window has been filled\n",
    "    fault_evolution[str(n)] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = fault_evolution.fillna(0).plot(\n",
    "    grid=True, legend=True, figsize=(8, 4), #ylim=(0.8, 1.01),\n",
    "    xlabel='Sample', ylabel='Accuracy' #, title='Faults: Label with delay'\n",
    ")\n",
    "fault_evolution.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing labels - Faults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_len = 10\n",
    "labels_skips = (0, 5, 15, 25, 50, 100)\n",
    "\n",
    "fault_skip_evolution = pd.DataFrame()\n",
    "for s in tqdm(labels_skips):\n",
    "    results = knn_online_learn(XStream_fault, YStream_fault, window_len=window_len, learn_skip=s)\n",
    "    accuracy = results['accuracy']\n",
    "    accuracy.index += len(XStream_fault) - len(accuracy)\n",
    "    fault_skip_evolution[str(s)] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = fault_skip_evolution.fillna(0).plot(\n",
    "    grid=True, legend=True, figsize=(8, 4), # ylim=(0, 1.01),\n",
    "    xlabel='Sample', ylabel='Accuracy' # , title=f'Faults (4 classes): Skip labels (out of {len(XStream_fault)} total), Window: {window_len}'\n",
    ")\n",
    "fault_skip_evolution.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatter plot - True labels vs. Predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.project_classifier_map_plot(\n",
    "    XStream_fault.drop(columns=['label']).reset_index(drop=True),\n",
    "    YStream_fault.reset_index(drop=True),\n",
    "    knn_online_learn(XStream_fault.reset_index(drop=True), YStream_fault.reset_index(drop=True), window_len=1, learn_skip=0, clusters=True)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_model_setup(n):\n",
    "    engine = neighbors.SWINN(\n",
    "        dist_func=functools.partial(utils.math.minkowski_distance, p=2),\n",
    "        seed=10\n",
    "    )\n",
    "    model = (\n",
    "        preprocessing.MinMaxScaler() |\n",
    "        neighbors.KNNClassifier(n_neighbors=n, engine=engine)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def knn_accuracy_with_delays(X, y, delays):\n",
    "    knn = knn_model_setup(5)\n",
    "\n",
    "    evolution = defaultdict(dict)\n",
    "    for delay in delays:\n",
    "        steps = evaluate.iter_progressive_val_score(\n",
    "            model=knn,\n",
    "            dataset=stream.iter_pandas(X, y),\n",
    "            metric=metrics.Accuracy(),\n",
    "            step=100,\n",
    "            delay=delay\n",
    "        )\n",
    "        for step in steps:\n",
    "            step_num = step['Step']\n",
    "            evolution[step_num]['Observation'] = step_num\n",
    "            evolution[step_num][delay] = step['Accuracy'].get()\n",
    "\n",
    "    evolution = (\n",
    "        pd.DataFrame\n",
    "        .from_records(list(evolution.values()))\n",
    "        .set_index('Observation')\n",
    "    )\n",
    "    evolution.plot(\n",
    "        grid=True, figsize=(8, 4), \n",
    "        ylabel='Accuracy'\n",
    "       # title='Accuracy with different delays'\n",
    "    )\n",
    "    return evolution\n",
    "\n",
    "\n",
    "def knn_conf_matrix_plot(X, y):\n",
    "    knn = knn_model_setup(5)\n",
    "    #confmatrix = metrics.ConfusionMatrix()\n",
    "    y_predictions = []\n",
    "\n",
    "    for x, y_true in stream.iter_pandas(X, y):\n",
    "        y_predict = knn.predict_one(x) or 0\n",
    "        knn.learn_one(x, y_true)\n",
    "        y_predictions.append(y_predict)\n",
    "        # confmatrix.update(y_true, y_predict)\n",
    "\n",
    "    cm = skmetrics.confusion_matrix(y, y_predictions)\n",
    "    ax = sb.heatmap(cm, cbar=True, cmap='BuGn', annot=True, fmt='d')\n",
    "    ax.set(xlabel='Prediction', ylabel='Truth')\n",
    "\n",
    "\n",
    "def knn_visualize_classes(X, y):\n",
    "    knn = knn_model_setup(5)\n",
    "\n",
    "    y_predictions = []\n",
    "    for xs, ys in stream.iter_pandas(X, y):\n",
    "        y_predict = knn.predict_one(xs)\n",
    "        knn.learn_one(xs, ys)\n",
    "        y_predictions.append(y_predict)\n",
    "\n",
    "    y_predictions = pd.Series(y_predictions)\n",
    "    mismatch = visualize.project_classifier_map_plot(X, y, y_predictions)\n",
    "    print(f'Error rate: {100 * (len(mismatch) / len(y)):.2f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN classifier (Faults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = XStream_fault.drop(columns=['label']), YStream_fault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evolution = knn_accuracy_with_delays(X, y, (1, 50, 100, 250))\n",
    "plt.show()\n",
    "evolution.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification report (Faults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate.progressive_val_score(\n",
    "    model=knn_model_setup(5),\n",
    "    dataset=stream.iter_pandas(X, y),\n",
    "    metric=metrics.ClassificationReport()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix (Faults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_conf_matrix_plot(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize clusters of nearest neighbors (Faults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaled = X.reset_index(drop=True)\n",
    "y_scaled = y.reset_index(drop=True)\n",
    "x_scaled[x_scaled.columns] = MinMaxScaler().fit_transform(x_scaled)\n",
    "knn_visualize_classes(x_scaled, y_scaled)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

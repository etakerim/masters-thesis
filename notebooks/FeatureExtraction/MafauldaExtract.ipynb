{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tsfel\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from vibrodiagnostics import (\n",
    "    mafaulda,\n",
    "    selection,\n",
    "    discovery,\n",
    "    models\n",
    ")\n",
    "\n",
    "MAFAULDA_PATH = '../../datasets/MAFAULDA.zip'\n",
    "FEATURES_PATH =  '../../datasets/features_data/'\n",
    "MAFAULDA_METADATA = os.path.join(FEATURES_PATH, selection.MAFAULDA_METADATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract metadata about files from whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_index = mafaulda.dataset_index(MAFAULDA_PATH)\n",
    "file_index.to_csv(MAFAULDA_METADATA, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load files for whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = pd.read_csv(MAFAULDA_METADATA, index_col='filename')\n",
    "files['fault'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_time_domain(zip_file: ZipFile, filename: str, parts: int=None) -> pd.DataFrame:\n",
    "    print(f'Processing: {filename}')\n",
    "\n",
    "    columns = mafaulda.COLUMNS\n",
    "    ts = mafaulda.csv_import(zip_file, filename)\n",
    "    fault, severity, seq = mafaulda.parse_filename(filename)\n",
    "\n",
    "    dataframe = discovery.split_dataframe(ts, parts)\n",
    "    dataframe = discovery.detrending_filter(dataframe, columns)\n",
    "    dataframe = discovery.lowpass_filter_extract(dataframe, columns)\n",
    "\n",
    "    result = []\n",
    "    for i, df in enumerate(dataframe):\n",
    "        fvector = [\n",
    "            ('fault', [fault]),\n",
    "            ('severity', [severity]),\n",
    "            ('seq', [f'{seq}.part.{i}']),\n",
    "            ('rpm', [df['rpm'].mean()])\n",
    "        ]\n",
    "        for col in columns:\n",
    "            fvector.extend(discovery.time_features_calc(df, col))\n",
    "        result.append(pd.DataFrame(dict(fvector))) \n",
    "\n",
    "    return pd.concat(result).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def features_frequency_domain(zip_file: ZipFile, filename: str, parts: int=None) -> pd.DataFrame:\n",
    "    # Calculate FFT with Welch method in 5 different Hann window sizes\n",
    "    print(f'Processing: {filename}')\n",
    "    OVERLAP = 0.5\n",
    "    WINDOW_SIZES = (2**6, 2**8, 2**10, 2**12, 2**14)\n",
    "\n",
    "    columns = mafaulda.COLUMNS\n",
    "    ts = mafaulda.csv_import(zip_file, filename)\n",
    "    fault, severity, seq = mafaulda.parse_filename(filename)\n",
    "\n",
    "    dataframe = discovery.split_dataframe(ts, parts)\n",
    "    dataframe = discovery.detrending_filter(dataframe, columns)\n",
    "    dataframe = discovery.lowpass_filter_extract(dataframe, columns)\n",
    "\n",
    "    result = []\n",
    "    for i, df in enumerate(dataframe):\n",
    "        fvector = [\n",
    "            ('fault', [fault]),\n",
    "            ('severity', [severity]),\n",
    "            ('seq', [f'{seq}.part.{i}']),\n",
    "            ('rpm', [df['rpm'].mean()])\n",
    "        ]\n",
    "        for window in WINDOW_SIZES:\n",
    "            for col in columns:\n",
    "                fvector.extend(discovery.frequency_features_calc(df, col, window))\n",
    "        result.append(pd.DataFrame(dict(fvector))) \n",
    "\n",
    "    return pd.concat(result).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export features for all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ZipFile(MAFAULDA_PATH)\n",
    "filenames = list(files.index)\n",
    "filenames[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time domain features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_FILENAME = os.path.join(FEATURES_PATH, selection.TIME_FEATURES_PATH)\n",
    "\n",
    "features = mafaulda.import_files_split(dataset, filenames, features_time_domain, parts=5)\n",
    "features.to_csv(FEATURES_FILENAME, index=False)\n",
    "features.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequency domain features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_FILENAME = os.path.join(FEATURES_PATH, selection.FREQ_FEATURES_PATH)\n",
    "\n",
    "features = mafaulda.import_files_split(dataset, filenames, features_frequency_domain, parts=5)\n",
    "features.to_csv(FEATURES_FILENAME, index=False)\n",
    "features.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge time and frequency domain features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_domain_filename = os.path.join(FEATURES_PATH, selection.TIME_FEATURES_PATH)\n",
    "freq_domain_filename = os.path.join(FEATURES_PATH, selection.FREQ_FEATURES_PATH)\n",
    "merged_filename = os.path.join(FEATURES_PATH, selection.TIME_AND_FREQ_FEATURES_PATH)\n",
    "\n",
    "result = selection.merge_feature_domains(time_domain_filename, freq_domain_filename)\n",
    "result.to_csv(merged_filename, index=False)\n",
    "\n",
    "result.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EDA of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RPM = 2500\n",
    "RPM_RANGE = 500\n",
    "SHAFT_FAULTS = {'normal': 'N', 'imbalance': 'I', 'horizontal-misalignment': 'HM', 'vertical-misalignment': 'VM'}\n",
    "BEARING_FAULTS = {'overhang-cage_fault': 'O-Cage', 'underhang-cage_fault': 'U-Cage',\n",
    "                  'underhang-ball_fault': 'U-Ball', 'overhang-ball_fault': 'O-Ball',\n",
    "                  'underhang-outer_race': 'U-Race', 'overhang-ball_fault': 'O-Race'}\n",
    "\n",
    "shaft_fault_all = files[\n",
    "    (files['fault'].isin(SHAFT_FAULTS))\n",
    "].copy()\n",
    "\n",
    "shaft_fault_rpm =  files[\n",
    "    (files['fault'].isin(SHAFT_FAULTS)) &\n",
    "    (files['rpm'].between(RPM - RPM_RANGE, RPM + RPM_RANGE, inclusive='both'))\n",
    "].copy()\n",
    "\n",
    "shaft_fault_all = files[\n",
    "    (files['fault'].isin(SHAFT_FAULTS))\n",
    "].copy()\n",
    "\n",
    "shaft_fault_rpm =  files[\n",
    "    (files['fault'].isin(SHAFT_FAULTS)) &\n",
    "    (files['rpm'].between(RPM - RPM_RANGE, RPM + RPM_RANGE, inclusive='both'))\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequency spectrum comparison of faults in low and high RPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_frequency_spectrum(dataset, file, axis, p, window=8192, dB=False, label=None):\n",
    "    ts = csv_import(dataset, file)\n",
    "    f, pxx = discovery.spectral_transform(ts, axis, window)\n",
    "    p.set_xlabel('Frequency [Hz]')\n",
    "    if dB:\n",
    "        p.set_ylabel('Amplitude [dB]')\n",
    "        pxx = 20 * np.log10(pxx / DB_REF)\n",
    "    else:\n",
    "        p.set_ylabel('Amplitude [m/s^2]')\n",
    "    p.plot(f, pxx, label=label)\n",
    "    p.grid(True)\n",
    "\n",
    "\n",
    "def plot_rpm_comparison(files, fault, dB):\n",
    "    table = files[\n",
    "        (files['rpm'] == files['rpm'].min()) |\n",
    "        (files['rpm'] == files['rpm'].max())\n",
    "    ] \n",
    "    dataset = ZipFile(MAFAULDA_PATH)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 3), sharey=True)\n",
    "    ax.set_title(f'{fault}')\n",
    "    for filename, series in table.iterrows():\n",
    "        plot_frequency_spectrum(dataset, filename, 'ax', ax, dB=dB, label=f'{series[\"rpm\"]:.2f}')\n",
    "\n",
    "    ax.set_xlim(0, 1000)\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shaft faults: Scale in m/s^2: frequency spectrum between lowest rpm and highest RPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = pd.read_csv(MAFAULDA_METADATA, index_col='filename')\n",
    "files = fault_labeling(files, SHAFT_FAULTS, 0.8, debug=True)\n",
    "files.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fault, level in [('N', 0), ('I', 1), ('VM', 1), ('HM', 1)]:\n",
    "    sources = files[(files['fault'] == fault) &  (files['severity_level'] == level)]\n",
    "    plot_rpm_comparison(sources, fault, dB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bearing faults: Scale in m/s^2: frequency spectrum between lowest rpm and highest RPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = pd.read_csv(MAFAULDA_METADATA, index_col='filename')\n",
    "files = fault_labeling(files, BEARING_FAULTS, 0.8, debug=True)\n",
    "files.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fault, level in [(fault, 1) for fault in BEARING_FAULTS.values()]:\n",
    "    sources = files[(files['fault'] == fault) &  (files['severity_level'] == level)]\n",
    "    plot_rpm_comparison(sources, fault, dB=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

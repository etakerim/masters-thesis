{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures for IIT SRC article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import os\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from scipy.signal import find_peaks, butter, lfilter, windows, welch\n",
    "from typing import Tuple\n",
    "\n",
    "import re\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from adjustText import adjust_text\n",
    "from tqdm.notebook import tqdm\n",
    "import itertools\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "from vibrodiagnostics import ranking\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "USE_ONE_AXIS = False  # or false\n",
    "MAFAULDA_LABEL_METHODS = ['bearing-A', 'all-bearings', 'severity']\n",
    "MAFAULDA_LABEL_METHOD = MAFAULDA_LABEL_METHODS[0]\n",
    "\n",
    "\n",
    "MODEL_TYPE = 'knn'\n",
    "#MODEL_TYPE = 'lda'\n",
    "#MODEL_TYPE = 'bayes'\n",
    "#MODEL_TYPE = 'svm' \n",
    "\n",
    "KNN_METRIC = 'euclidean'\n",
    "#KNN_METRIC = 'cityblock'\n",
    "#KNN_METRIC = 'cosine'\n",
    "\n",
    "\n",
    "FEATURES_PATH = '../datasets/features/'\n",
    "MAFAULDA_TEMPORAL = os.path.join(FEATURES_PATH, 'mafaulda_temporal.csv')\n",
    "MAFAULDA_SPECTRAL = os.path.join(FEATURES_PATH, 'mafaulda_spectral.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_transform(dataset: pd.DataFrame, axis: str, window: int, fs: int) -> Tuple[np.array, np.array]:\n",
    "    overlap = 0.5\n",
    "    step = int(window * overlap)\n",
    "\n",
    "    v = dataset[axis].to_numpy()\n",
    "    f, pxx = welch(\n",
    "        v,\n",
    "        fs=fs,\n",
    "        window='hann',\n",
    "        nperseg=window,\n",
    "        noverlap=step,\n",
    "        scaling='spectrum',\n",
    "        average='mean',\n",
    "        detrend='constant',\n",
    "        return_onesided=True\n",
    "    )\n",
    "    return f, pxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mafaulda_columns = ['ax', 'ay', 'az', 'bx', 'by', 'bz']\n",
    "mafaulda_all_columns = ['tachometer', 'ax', 'ay', 'az', 'bx', 'by', 'bz', 'mic']\n",
    "mafaulda_fs_hz = 50000\n",
    "\n",
    "\n",
    "def rpm_calc(tachometer: pd.Series) -> float:\n",
    "    tacho = tachometer.to_frame()\n",
    "    f, s = spectral_transform(tacho, 'tachometer', 2**17, mafaulda_fs_hz)\n",
    "    peaks, _ = find_peaks(s, height=0.7, distance=1000)\n",
    "    f_rotation = f[peaks][0]\n",
    "    return 60 * f_rotation\n",
    "\n",
    "def mafaulda_lowpass_filter(\n",
    "        data: pd.Series,\n",
    "        cutoff: int = mafaulda_fs_hz // 5,\n",
    "        fs: int = mafaulda_fs_hz,\n",
    "        order: int = 5) -> pd.Series:\n",
    "    \n",
    "    b, a = butter(order, cutoff, fs=fs, btype='lowpass')\n",
    "    y = lfilter(b, a, data.to_numpy())\n",
    "    return pd.Series(data=y, index=data.index)\n",
    "\n",
    "def mafaulda_csv_import(dataset: ZipFile, filename: str) -> pd.DataFrame:\n",
    "    columns = mafaulda_all_columns\n",
    "    ts = pd.read_csv(dataset.open(filename), names=columns)\n",
    "    T = 1 / mafaulda_fs_hz\n",
    "    ts = (\n",
    "        ts\n",
    "        .assign(t = lambda x: x.index * T)\n",
    "        .reset_index()\n",
    "        .assign(t = lambda x: x.index * T)\n",
    "        .set_index('t')\n",
    "        .assign(rpm = lambda x: rpm_calc(x.tachometer))\n",
    "    )\n",
    "    # Detrending\n",
    "    ts[columns] = ts[columns].apply(lambda x: x - x.mean())\n",
    "    # Low pass filter\n",
    "    ts[columns] = ts[columns].apply(mafaulda_lowpass_filter)\n",
    "    return ts.assign(key=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluidpump_columns = ['x', 'y', 'z']\n",
    "fluidpump_all_columns = ['t', 'x', 'y', 'z']\n",
    "fluidpump_fs_hz = 26866\n",
    "\n",
    "def fluidpump_csv_import(dataset: ZipFile, filename: str) -> pd.DataFrame:\n",
    "    ts = pd.read_csv(\n",
    "        dataset.open(filename),\n",
    "        delimiter='\\t',\n",
    "        index_col=False,\n",
    "        header=0,\n",
    "        names=fluidpump_all_columns\n",
    "    ) \n",
    "    g = 9.80665\n",
    "    columns = fluidpump_columns\n",
    "    ts[columns] = ts[columns].apply(lambda x: g * (x / 1000))\n",
    "\n",
    "    T = 1 / fluidpump_fs_hz\n",
    "    ts = ts.assign(t = lambda x: x.index * T)\n",
    "    ts.set_index('t', inplace=True)\n",
    "    # time = 10\n",
    "    # time_diff = 5\n",
    "    # ts = ts.loc[time:time + time_diff]\n",
    "    # Detrending\n",
    "    ts[columns] = ts[columns].apply(lambda x: x - x.mean())\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Signal analysis\n",
    "- 1ks plot (6x subplots) Mafaulda welch from each fault (1s, 2**14 window, hann window)  - largest severity - 2500 rpm\n",
    "- 1ks plot (6x subplots) Custom dataset - each place in one day spectrum (5s segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mafaulda - worst severity at 2500 rpm\n",
    "def plot_bearing_frequencies(freqs, pxx, bearings, ax, name, deltaF):\n",
    "    position = {\n",
    "        'M1-1': 'MTR001',\n",
    "        'M2-1': 'MTR001',\n",
    "        'M1-2': 'MTR002',\n",
    "        'M2-2': 'MTR002',\n",
    "        'P1-3': 'PMP003',\n",
    "        'P2-3': 'PMP003',\n",
    "        'P1-4': 'PMP004',\n",
    "        'P2-4': 'PMP004',\n",
    "    }\n",
    "    bearing = bearings[\n",
    "        bearings['placement'] == position.get(name, name)\n",
    "    ]\n",
    "    columns = ['RPM', 'BPFO', 'BPFI', 'BSF', 'FTF']\n",
    "    colors = ['red', 'purple', 'orange', 'black', 'green']\n",
    "    markers = ['s', 'o', 'D', 'P', 'x']\n",
    "    n_harmonics = 20\n",
    "\n",
    "    for col, color, mark in zip(columns, colors, markers):\n",
    "        f_fundamental = bearing[col].values[0]\n",
    "        f_harmonics = [i * f_fundamental for i in range(1, n_harmonics+1)]\n",
    "        amplitudes = [\n",
    "            pxx[int(f/deltaF)] for f in f_harmonics \n",
    "            if int(f/deltaF) < len(pxx)\n",
    "        ]\n",
    "        f_harmonics = f_harmonics[:len(amplitudes)]\n",
    "        ax.plot(\n",
    "            f_harmonics,\n",
    "            amplitudes,\n",
    "            color=color,\n",
    "            marker=mark,\n",
    "            markerfacecolor='None',\n",
    "            markeredgecolor=color,\n",
    "            linestyle='None',\n",
    "            label=col,\n",
    "            markeredgewidth=2\n",
    "        )\n",
    "\n",
    "    return ax.get_legend_handles_labels()\n",
    "\n",
    "def plot_psd(\n",
    "        ts, axname, fs, name, ax, window=2**15, \n",
    "        xlim=None, ylim=None, dB=False, bearings=None, \n",
    "        freqs=None, pxx=None):\n",
    "\n",
    "    if freqs is None or pxx is None:\n",
    "        freqs, pxx = spectral_transform(ts, axname, window, fs)\n",
    "\n",
    "    if dB is True:\n",
    "        pxx = 20 * np.log10(pxx / 0.000001)\n",
    "        ax.set_ylabel('Amplitude [dB]')\n",
    "    else:\n",
    "        ax.set_ylabel('Amplitude [m/s\\u00B2]')\n",
    "        \n",
    "\n",
    "    ax.plot(freqs, pxx, color='darkblue')\n",
    "    ax.fill_between(freqs, pxx, color='lightblue', alpha=0.3)\n",
    "\n",
    "    legend = None\n",
    "    if bearings is not None:\n",
    "        legend = plot_bearing_frequencies(freqs, pxx, bearings, ax, name, fs / window)\n",
    "\n",
    "    ax.grid(True)\n",
    "    #ax.set_xlabel('Frequency [Hz]')\n",
    "\n",
    "    if xlim is not None:\n",
    "        ax.set_xlim(0, xlim)\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(0, ylim)\n",
    "    ax.set_title(name)\n",
    "\n",
    "    return legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axname = 'ay'\n",
    "dataset = ZipFile('../datasets/MAFAULDA.zip')\n",
    "filenames = {\n",
    "    'normal/43.6224.csv': 'normal',\n",
    "    'horizontal-misalignment/2.0mm/42.5984.csv': 'misalignment',\n",
    "    'imbalance/35g/43.6224.csv': 'imbalance',\n",
    "    'underhang/cage_fault/35g/43.4176.csv': 'cage fault',\n",
    "    'underhang/ball_fault/35g/41.1648.csv': 'ball fault',\n",
    "    'underhang/outer_race/35g/43.4176.csv': 'outer race fault'\n",
    "}\n",
    "fig, ax = plt.subplots(len(filenames), 1, figsize=(10, 12), sharex=True)\n",
    "for i, name in enumerate(filenames.items(), start=0):\n",
    "    filename, title = name\n",
    "    ts = mafaulda_csv_import(dataset, filename)\n",
    "    plot_psd(ts, axname, mafaulda_fs_hz, title, ax[i], xlim=2500, ylim=0.03)\n",
    "ax[-1].set_xlabel('Frequency [Hz]')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Mafaulda faults\n",
    "def maufaulda_bearing_frequencies(rpm):\n",
    "    bearings = {\n",
    "        'balls': 8,\n",
    "        'ball_diameter': 0.7145,\n",
    "        'pitch_diameter': 2.8519,\n",
    "        'bpfo_factor': 2.9980,\n",
    "        'bpfi_factor': 5.0020,\n",
    "        'bsf_factor': 1.8710,\n",
    "        'ftf_factor': 0.3750\n",
    "    }\n",
    "\n",
    "    machine = {}\n",
    "    machine['RPM'] = rpm / 60\n",
    "    machine['BPFO'] = bearings['bpfo_factor'] * machine['RPM'] \n",
    "    machine['BPFI'] = bearings['bpfi_factor'] * machine['RPM']\n",
    "    machine['BSF'] = bearings['bsf_factor'] * machine['RPM']\n",
    "    machine['FTF'] = bearings['ftf_factor'] * machine['RPM']\n",
    "\n",
    "    return machine\n",
    "\n",
    "\n",
    "# Detail on bearing frequencies\n",
    "fig, ax = plt.subplots(len(filenames), 1, figsize=(10, 15), sharex=True)\n",
    "for i, name in enumerate(filenames.items(), start=0):\n",
    "    filename, title = name\n",
    "    ts = mafaulda_csv_import(dataset, filename)\n",
    "    rpm = ts['rpm'].mean()\n",
    "    machine = maufaulda_bearing_frequencies(rpm)\n",
    "    machine['placement'] = title\n",
    "    machine = pd.DataFrame.from_records([machine])\n",
    "\n",
    "    handles, labels = plot_psd(\n",
    "        ts, axname, mafaulda_fs_hz, title, ax[i],\n",
    "        xlim=1000, window=2**15, bearings=machine, dB=False\n",
    "    )\n",
    "    ax[i].set_title(f'{title} ({rpm:.0f} rpm)')\n",
    "    ax[i].set_ylim(0, 0.02)\n",
    "ax[-1].set_xlabel('Frequency [Hz]')\n",
    "\n",
    "lines = 5\n",
    "fig.legend(handles, labels, loc='lower center', ncol=lines, numpoints=1)\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axname = 'z'\n",
    "dataset = ZipFile('../datasets/FluidPump.zip')\n",
    "filenames = {\n",
    "    'compressor/2024-02-20/K3/001/1.tsv': 'C1-1',\n",
    "    'compressor/2024-02-20/K5/001/1.tsv': 'C2-1',\n",
    "    'compressor/2024-02-20/K3/002/1.tsv': 'C1-2',\n",
    "    'compressor/2024-02-20/K5/002/1.tsv': 'C2-2'\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(len(filenames), 1, figsize=(8, 10))\n",
    "for i, name in enumerate(filenames.items(), start=0):\n",
    "    filename, title = name\n",
    "    ts = fluidpump_csv_import(dataset, filename)\n",
    "    plot_psd(ts, axname, fluidpump_fs_hz, title, ax[i], xlim=2000, ylim=2)\n",
    "\n",
    "#fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bearing frequencies\n",
    "BEARINGS_FILE = os.path.join(FEATURES_PATH, 'bearings.csv')\n",
    "BEARINGS_PROCESSED_FILE = os.path.join(FEATURES_PATH, 'bearings_processed.csv')\n",
    "\n",
    "# http://webtools3.skf.com/engcalc/CalcBearingFrequencies.do\n",
    "# https://www.skfbearingselect.com/#/type-arrangement/single-bearing\n",
    "bearings = pd.read_csv(BEARINGS_FILE)\n",
    "bearings['RPM'] = bearings['rpm'] / 60\n",
    "# Outer race\n",
    "bearings['BPFO'] = (\n",
    "    (bearings['balls'] / 2) *\n",
    "    (bearings['rpm'] / 60) *\n",
    "    (1 - (bearings['ball_diameter'] / bearings['pitch_diameter']) * np.cos(np.radians(bearings['angle'])))\n",
    ")\n",
    "# Inner race\n",
    "bearings['BPFI'] = (\n",
    "    (bearings['balls'] / 2) *\n",
    "    (bearings['rpm'] / 60) *\n",
    "    (1 + (bearings['ball_diameter'] / bearings['pitch_diameter']) * np.cos(np.radians(bearings['angle'])))\n",
    ")\n",
    "# Ball\n",
    "bearings['BSF'] = (\n",
    "    (bearings['pitch_diameter'] / (2 * bearings['ball_diameter'])) *\n",
    "    (bearings['rpm'] / 60) *\n",
    "    (1 + ((bearings['ball_diameter'] / bearings['pitch_diameter']) * np.cos(np.radians(bearings['angle'])))**2)\n",
    ")\n",
    "# Cage\n",
    "bearings['FTF'] = (\n",
    "    0.5 * (bearings['rpm'] / 60) *\n",
    "    (1 - (bearings['ball_diameter'] / bearings['pitch_diameter']) * np.cos(np.radians(bearings['angle'])))\n",
    ")\n",
    "bearings.to_csv(BEARINGS_PROCESSED_FILE)\n",
    "bearings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axname = 'z'\n",
    "dataset = ZipFile('../datasets/FluidPump.zip')\n",
    "i = 1\n",
    "date = '2024-03-26'\n",
    "filenames = {\n",
    "    f'pump/{date}/KSB1/MTR001/{i}.tsv': 'M1-1',\n",
    "    f'pump/{date}/KSB7/MTR001/{i}.tsv': 'M2-1',\n",
    "    f'pump/{date}/KSB1/MTR002/{i}.tsv': 'M1-2',\n",
    "    f'pump/{date}/KSB7/MTR002/{i}.tsv': 'M2-2'\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(len(filenames), 1, figsize=(10, 15), sharex=True)\n",
    "for i, name in enumerate(filenames.items(), start=0):\n",
    "    filename, title = name\n",
    "    ts = fluidpump_csv_import(dataset, filename)\n",
    "    plot_psd(ts, axname, fluidpump_fs_hz, title, ax[i], xlim=6000, ylim=0.2)\n",
    "ax[-1].set_xlabel('Frequency [Hz]')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detail on bearing frequencies\n",
    "fig, ax = plt.subplots(len(filenames), 1, figsize=(10, 15), sharex=True)\n",
    "for i, name in enumerate(filenames.items(), start=0):\n",
    "    filename, title = name\n",
    "    ts = fluidpump_csv_import(dataset, filename)\n",
    "    handles, labels = plot_psd(ts, axname, fluidpump_fs_hz, title, ax[i], xlim=1000, dB=False, window=2**16, bearings=bearings)\n",
    "    ax[i].set_ylim(0, 0.02)\n",
    "\n",
    "ax[-1].set_xlabel('Frequency [Hz]')\n",
    "\n",
    "lines = 5\n",
    "fig.legend(handles, labels, loc='lower center', ncol=lines, numpoints=1)\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axname = 'z'\n",
    "dataset = ZipFile('../datasets/FluidPump.zip')\n",
    "i = 1\n",
    "date = '2024-02-27'\n",
    "filenames = {\n",
    "    f'pump/{date}/KSB1/PMP003/{i}.tsv': 'P1-3',\n",
    "    f'pump/{date}/KSB7/PMP003/{i}.tsv': 'P2-3',\n",
    "    f'pump/{date}/KSB1/PMP004/{i}.tsv': 'P1-4',\n",
    "    f'pump/{date}/KSB7/PMP004/{i}.tsv': 'P2-4'\n",
    "}\n",
    "\n",
    "# Overall\n",
    "fig, ax = plt.subplots(len(filenames), 1, figsize=(10, 15),  sharex=True)\n",
    "for i, name in enumerate(filenames.items(), start=0):\n",
    "    filename, title = name\n",
    "    ts = fluidpump_csv_import(dataset, filename)\n",
    "    plot_psd(ts, axname, fluidpump_fs_hz, title, ax[i], xlim=6000, ylim=0.1)\n",
    "\n",
    "ax[-1].set_xlabel('Frequency [Hz]')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detail on bearing frequencies\n",
    "fig, ax = plt.subplots(len(filenames), 1, figsize=(10, 15), sharex=True)\n",
    "for i, name in enumerate(filenames.items(), start=0):\n",
    "    filename, title = name\n",
    "    ts = fluidpump_csv_import(dataset, filename)\n",
    "    handles, labels = plot_psd(ts, axname, fluidpump_fs_hz, title, ax[i], xlim=1000, dB=False, window=2**16, bearings=bearings)\n",
    "    ax[i].set_ylim(0, 0.06)\n",
    "\n",
    "ax[-1].set_xlabel('Frequency [Hz]')\n",
    "\n",
    "lines = 5\n",
    "fig.legend(handles, labels, loc='lower center', ncol=lines, numpoints=1)\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axname = 'z'\n",
    "base_path = '../datasets/ksb-cloud/pumps-compare/'\n",
    "i = 1\n",
    "filenames = {\n",
    "    'ksb-1-27-2-6-27.csv': 'P1-3',\n",
    "    'ksb-7-28-2-11-43.csv': 'P2-3',\n",
    "    'ksb-1-fft-26-3-6-33.csv': 'P1-3',\n",
    "    'ksb-7-fft-13-3-5-33.csv': 'P2-3' \n",
    "}\n",
    "fs_ksb = 2000\n",
    "\n",
    "fig, ax = plt.subplots(len(filenames), 1, figsize=(10, 15))\n",
    "for i, name in enumerate(filenames.items(), start=0):\n",
    "    filename, title = name\n",
    "\n",
    "    ts = pd.read_csv(\n",
    "        os.path.join(base_path, filename),\n",
    "        delimiter=';',\n",
    "        decimal=',',\n",
    "        index_col=False\n",
    "    )\n",
    "    ts.rename(columns={\n",
    "        'Frequency [Hertz]': 'f', \n",
    "        'AmplitudeX [mm/s]': 'x',\n",
    "        'AmplitudeY [mm/s]': 'y',\n",
    "        'AmplitudeZ [mm/s]': 'z'\n",
    "    }, inplace=True)\n",
    "    ts = ts.set_index('f')\n",
    "    \n",
    "    handles, labels = plot_psd(\n",
    "        None, axname, fs_ksb, title, ax[i], \n",
    "        dB=False, window=512, xlim=1000,\n",
    "        bearings=bearings,\n",
    "        freqs=ts.index.to_numpy(), pxx=ts['z'].to_numpy())\n",
    "\n",
    "lines = 5\n",
    "fig.legend(handles, labels, loc='lower center', ncol=lines)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature analysis:\n",
    "Mafaulda (3) a Custom (4) \n",
    "- 1 ks table (how many faults have how many recordings)\n",
    "- 1 ks plot (2 lines TD, FD) - number of PC vs. explained variance\n",
    "- 1 ks plot (2x subplots TD, FD) - loading plot (PC2)\n",
    "- 1 ks (4 subplots) custom: all machines, pumps, compressors, motors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Explained varinace by PCA components and loading plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_whole_dataset(dataset: dict, domain: str):\n",
    "    axis = dataset['axis']\n",
    "    label_cols = dataset['labels']\n",
    "    filename = dataset[domain]\n",
    "\n",
    "    features = pd.read_csv(filename)\n",
    "\n",
    "    columns = features.columns.str.startswith(axis)\n",
    "    X = features[features.columns[columns]]\n",
    "    if label_cols is not None:\n",
    "        Y = features[label_cols]\n",
    "    else:\n",
    "        Y = pd.DataFrame()\n",
    "\n",
    "    names = X.columns.str.extract(r'([a-z]+)_([a-z\\_\\-]+)')[1].unique()\n",
    "    feature_names = [f'{domain}_{col.strip(\"_\")}' for col in names if not pd.isnull(col)]\n",
    "\n",
    "    result = pd.DataFrame()\n",
    "    for name in feature_names:              \n",
    "        name = re.search(r'[a-z]+_([\\w\\_]+)', name).group(1)\n",
    "        \n",
    "        if USE_ONE_AXIS:\n",
    "            dim = dataset['one-axis']\n",
    "            result[name] = X[f'{dim}_{name}']\n",
    "        else:\n",
    "            vector_dims = [f'{dim}_{name}' for dim in axis]\n",
    "            result[name] = X[vector_dims].apply(np.linalg.norm, axis=1)\n",
    "    X = result\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def explained_variance(X):\n",
    "    x_scaled = pd.DataFrame()\n",
    "    x_scaled[X.columns] = MinMaxScaler().fit_transform(X)\n",
    "    pca= PCA(n_components=10)\n",
    "    X_pca = pca.fit_transform(x_scaled)\n",
    "    return pca.explained_variance_ratio_\n",
    "\n",
    "\n",
    "def get_principal_components(X):\n",
    "    x_scaled = pd.DataFrame()\n",
    "    x_scaled[X.columns] = MinMaxScaler().fit_transform(X)\n",
    "    pca= PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(x_scaled)\n",
    "    return pca.components_\n",
    "\n",
    "\n",
    "def plot_cumulative_explained_variance(td_variance, fd_variance):\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    ax.plot(\n",
    "        np.arange(1, len(td_variance) + 1),\n",
    "        100 * np.cumsum(td_variance), \n",
    "        marker='s', label='Temporal features'\n",
    "    )\n",
    "    ax.plot(\n",
    "        np.arange(1, len(fd_variance) + 1), \n",
    "        100 * np.cumsum(fd_variance),\n",
    "        marker='s', label='Spectral features'\n",
    "    )\n",
    "    ax.set_xlabel('Number of principal components')\n",
    "    ax.set_ylabel('Explained variance [%]')\n",
    "    ax.grid()\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def loading_plot(loadings, feature_names, bottom, top):\n",
    "    xs = loadings[0]\n",
    "    ys = loadings[1]\n",
    "\n",
    "    texts = []\n",
    "    # Plot the loadings on a scatterplot\n",
    "    for i, varnames in enumerate(feature_names):\n",
    "        plt.arrow(\n",
    "            0, 0,   # coordinates of arrow base\n",
    "            xs[i],  # length of the arrow along x\n",
    "            ys[i],  # length of the arrow along y\n",
    "            color='r', \n",
    "            head_width=0.01\n",
    "        )\n",
    "        texts.append(plt.text(xs[i], ys[i], varnames))\n",
    "\n",
    "    # Define the axis\n",
    "    adjust_text(texts, only_move={'points':'y', 'texts':'y'})\n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')\n",
    "    plt.xlim(bottom, top)\n",
    "    plt.ylim(bottom, top)\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MaFaulDa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_PATH = '../datasets/features'\n",
    "mafaulda = {\n",
    "    'temporal': MAFAULDA_TEMPORAL,\n",
    "    'spectral': MAFAULDA_SPECTRAL,\n",
    "    'axis': ('ax', 'ay', 'az'),\n",
    "    'labels': ['fault', 'severity', 'rpm'],\n",
    "    'one-axis': 'ay'\n",
    "}\n",
    "\n",
    "mafaulda['X_td'], mafaulda['Y'] = load_whole_dataset(mafaulda, 'temporal')\n",
    "mafaulda['X_fd'], mafaulda['Y'] = load_whole_dataset(mafaulda, 'spectral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class count\n",
    "# 1) Label independently\n",
    "faults = {\n",
    "    'normal': 'normal',\n",
    "    'imbalance': 'imbalance',\n",
    "    'horizontal-misalignment': 'misalignment',\n",
    "    'vertical-misalignment': 'misalignment',\n",
    "    'underhang-outer_race': 'outer race fault',\n",
    "    'underhang-cage_fault': 'cage fault',\n",
    "    'underhang-ball_fault': 'ball fault',\n",
    "    'overhang-outer_race': 'outer race fault',\n",
    "    'overhang-cage_fault': 'cage fault',\n",
    "    'overhang-ball_fault': 'ball fault'\n",
    "}\n",
    "\n",
    "bearing_faults = {\n",
    "    'A': {\n",
    "        'normal': 'normal',\n",
    "        'imbalance': 'imbalance',\n",
    "        'horizontal-misalignment': 'misalignment',\n",
    "        'vertical-misalignment': 'misalignment',\n",
    "        'underhang-outer_race': 'outer race fault',\n",
    "        'underhang-cage_fault': 'cage fault',\n",
    "        'underhang-ball_fault': 'ball fault'\n",
    "    },\n",
    "    'B': {\n",
    "        'normal': 'normal',\n",
    "        'imbalance': 'imbalance',\n",
    "        'horizontal-misalignment': 'misalignment',\n",
    "        'vertical-misalignment': 'misalignment',\n",
    "        'overhang-outer_race': 'outer race fault',\n",
    "        'overhang-cage_fault': 'cage fault',\n",
    "        'overhang-ball_fault': 'ball fault',\n",
    "    }\n",
    "}\n",
    "\n",
    "if MAFAULDA_LABEL_METHOD == 'bearing-A':\n",
    "    mafaulda['Y']['target'] = mafaulda['Y'].apply(lambda row: bearing_faults['A'].get(row['fault']), axis=1)\n",
    "\n",
    "elif MAFAULDA_LABEL_METHOD == 'all-bearings':\n",
    "    mafaulda['Y']['target'] = mafaulda['Y'].apply(lambda row: faults.get(row['fault']), axis=1)\n",
    "\n",
    "elif MAFAULDA_LABEL_METHOD == 'severity':\n",
    "    table = mafaulda['Y'].copy()\n",
    "    table['target'] = mafaulda['Y']['fault'].replace(faults)\n",
    "    table['target'] = table['target'].astype('category')\n",
    "    table['severity_no'] = table['severity'].str.extract(r'(\\d+\\.?\\d*)').astype(float)\n",
    "\n",
    "    for name, group in table.groupby(by=['target'], observed=True):\n",
    "        group = group.sort_values(by='severity_no')\n",
    "            \n",
    "        severities = group['severity_no'].astype('category').cat.codes.values.reshape(-1, 1)\n",
    "        scale_severities = MinMaxScaler().fit_transform(severities)\n",
    "\n",
    "        sev_names = list(group['severity'].astype('category').cat.categories)\n",
    "        sev = list(group['severity'].astype('category').cat.codes.astype('category').cat.categories)\n",
    "        scale = [float(f'{p:.2f}') for p in pd.Series(scale_severities[:, 0]).astype('category').cat.categories]\n",
    "        print(f'Fault: {name[0]}, Files: {len(group)}, Severity names: {sev_names}, Severity: {sev}, Severity Levels: {scale}')\n",
    "        \n",
    "        table.loc[group.index, 'severity_class'] = severities\n",
    "        table.loc[group.index, 'severity_level'] = scale_severities\n",
    "\n",
    "    table.loc[table['severity_level'] < 0.5, 'target'] = 'normal'\n",
    "    mafaulda['Y'] = table\n",
    "\n",
    "\n",
    "mafaulda['Y']['target'] = mafaulda['Y']['target'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count classes\n",
    "counts = mafaulda['Y']['target'].value_counts().to_frame()\n",
    "counts['freq'] = (counts['count'] / counts['count'].sum()) * 100\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explained variance\n",
    "td_variance = explained_variance(mafaulda['X_td'])\n",
    "fd_variance = explained_variance(mafaulda['X_fd'])\n",
    "plot_cumulative_explained_variance(td_variance, fd_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading plots\n",
    "td_pc = get_principal_components(mafaulda['X_td'])\n",
    "fd_pc = get_principal_components(mafaulda['X_fd'])\n",
    "loading_plot(td_pc, mafaulda['X_td'].columns, -0.8, 0.8)\n",
    "loading_plot(fd_pc, mafaulda['X_fd'].columns, -0.8, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fluid pumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pump dataset (all devices, each type - pump, motor, compressor)\n",
    "FEATURES_PATH = '../datasets/features'\n",
    "pump = {\n",
    "    'temporal': os.path.join(FEATURES_PATH, 'fluidpump_temporal.csv'),\n",
    "    'spectral': os.path.join(FEATURES_PATH, 'fluidpump_spectral.csv'),\n",
    "    'axis': ('x', 'y', 'z'),\n",
    "    'labels': ['date', 'device', 'position'],\n",
    "    'one-axis': 'z'\n",
    "}\n",
    "\n",
    "pump['X_td'], pump['Y'] = load_whole_dataset(pump, 'temporal')\n",
    "pump['X_fd'], pump['Y'] = load_whole_dataset(pump, 'spectral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class count\n",
    "machines = {\n",
    "    'KSB1': {\n",
    "        'MTR001': 'M1',\n",
    "        'MTR002': 'M1',\n",
    "        'PMP003': 'P1',\n",
    "        'PMP004': 'P1'\n",
    "    },\n",
    "    'KSB7': {\n",
    "        'MTR001': 'M2',\n",
    "        'MTR002': 'M2',\n",
    "        'PMP003': 'P2',\n",
    "        'PMP004': 'P2'\n",
    "    },\n",
    "    'K3': {\n",
    "        '001': 'C1',\n",
    "        '002': 'C1'\n",
    "    },\n",
    "    'K5': {\n",
    "        '001': 'C2',\n",
    "        '002': 'C2'\n",
    "    }\n",
    "}\n",
    "\n",
    "pump['Y']['target'] = pump['Y'].apply(lambda row: machines.get(row['device'], {}).get(row['position']), axis=1)\n",
    "pump['Y']['target'] = pump['Y']['target'].astype('category')\n",
    "\n",
    "counts = pump['Y']['target'].value_counts().to_frame()\n",
    "counts['freq'] = (counts['count'] / counts['count'].sum()) * 100\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Motor and pump only\n",
    "\n",
    "# Label by device\n",
    "labels_machines = {\n",
    "    'KSB1': {\n",
    "        'MTR001': 'M1',\n",
    "        'MTR002': 'M1',\n",
    "        'PMP003': 'P1',\n",
    "        'PMP004': 'P1'\n",
    "    },\n",
    "    'KSB7': {\n",
    "        'MTR001': 'M2',\n",
    "        'MTR002': 'M2',\n",
    "        'PMP003': 'P2',\n",
    "        'PMP004': 'P2'\n",
    "    }\n",
    "}\n",
    "pump['Y']['label_machine'] = pump['Y'].apply(\n",
    "    lambda row: labels_machines.get(row['device'], {}).get(row['position']), axis=1\n",
    ")\n",
    "\n",
    "# Label by postion\n",
    "label_positions = {\n",
    "    'KSB1': {\n",
    "        'MTR001': 'M1-1',\n",
    "        'MTR002': 'M1-2',\n",
    "        'PMP003': 'P1-3',\n",
    "        'PMP004': 'P1-4'\n",
    "    },\n",
    "    'KSB7': {\n",
    "        'MTR001': 'M2-1',\n",
    "        'MTR002': 'M2-2',\n",
    "        'PMP003': 'P2-3',\n",
    "        'PMP004': 'P2-4'\n",
    "    }\n",
    "}\n",
    "pump['Y']['label_position'] = pump['Y'].apply(\n",
    "    lambda row: label_positions.get(row['device'], {}).get(row['position']), axis=1\n",
    ")\n",
    "\n",
    "# Label only P1-3, P2-3\n",
    "label_binary = {\n",
    "    'KSB1': {\n",
    "        'PMP003': 'P1-3'\n",
    "    },\n",
    "    'KSB7': {\n",
    "        'PMP003': 'P2-3'\n",
    "    }\n",
    "}\n",
    "pump['Y']['label_binary'] = pump['Y'].apply(\n",
    "    lambda row: label_binary.get(row['device'], {}).get(row['position']), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_variance = explained_variance(pump['X_td'])\n",
    "fd_variance = explained_variance(pump['X_fd'])\n",
    "plot_cumulative_explained_variance(td_variance, fd_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading plots\n",
    "td_pc = get_principal_components(pump['X_td'])\n",
    "fd_pc = get_principal_components(pump['X_fd'])\n",
    "loading_plot(td_pc, pump['X_td'].columns, -0.5, 1)\n",
    "loading_plot(fd_pc, pump['X_fd'].columns, -0.5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split by machine\n",
    "Y = pump['Y']\n",
    "compressor = Y[Y['device'].isin(['K3', 'K5'])].index\n",
    "waterpump = Y[\n",
    "    Y['device'].isin(['KSB1', 'KSB7']) & \n",
    "    Y['position'].isin(['PMP003', 'PMP004'])\n",
    "].index\n",
    "motor = Y[\n",
    "    Y['device'].isin(['KSB1', 'KSB7']) & \n",
    "    Y['position'].isin(['MTR001', 'MTR002'])\n",
    "].index\n",
    "\n",
    "td_variance = explained_variance(pump['X_td'].loc[compressor])\n",
    "fd_variance = explained_variance(pump['X_fd'].loc[compressor])\n",
    "plot_cumulative_explained_variance(td_variance, fd_variance)\n",
    "\n",
    "td_pc = get_principal_components(pump['X_td'].loc[compressor])\n",
    "fd_pc = get_principal_components(pump['X_fd'].loc[compressor])\n",
    "loading_plot(td_pc, pump['X_td'].columns, -0.5, 1)\n",
    "loading_plot(fd_pc, pump['X_fd'].columns, -0.5, 1)\n",
    "\n",
    "# -----\n",
    "td_variance = explained_variance(pump['X_td'].loc[waterpump])\n",
    "fd_variance = explained_variance(pump['X_fd'].loc[waterpump])\n",
    "plot_cumulative_explained_variance(td_variance, fd_variance)\n",
    "\n",
    "td_pc = get_principal_components(pump['X_td'].loc[waterpump])\n",
    "fd_pc = get_principal_components(pump['X_fd'].loc[waterpump])\n",
    "loading_plot(td_pc, pump['X_td'].columns, -0.5, 1)\n",
    "loading_plot(fd_pc, pump['X_fd'].columns, -0.5, 1)\n",
    "\n",
    "# -----\n",
    "td_variance = explained_variance(pump['X_td'].loc[motor])\n",
    "fd_variance = explained_variance(pump['X_fd'].loc[motor])\n",
    "plot_cumulative_explained_variance(td_variance, fd_variance)\n",
    "\n",
    "td_pc = get_principal_components(pump['X_td'].loc[motor])\n",
    "fd_pc = get_principal_components(pump['X_fd'].loc[motor])\n",
    "loading_plot(td_pc, pump['X_td'].columns, -0.5, 1)\n",
    "loading_plot(fd_pc, pump['X_fd'].columns, -0.5, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scatter plots of labels after PCA\n",
    "- 1 ks (5 subplots) scatter: mafaulda, all machines, pumps, compressors, motors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_boundaries(X, Y, n=5, model_name='knn'):\n",
    "    # Class balancing\n",
    "    oversample = RandomOverSampler(sampling_strategy='not majority', random_state=10)\n",
    "    X, Y = oversample.fit_resample(X, Y.to_numpy())\n",
    "    X.reset_index(drop=True, inplace=True)\n",
    "    Y = pd.Series(Y)\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "    for train_idx, test_idx in kf.split(X, Y):\n",
    "        # Train / Test split in KFold\n",
    "        x_train, x_test, y_train, y_test = (\n",
    "            X.loc[train_idx].copy(), X.loc[test_idx].copy(),\n",
    "            Y.loc[train_idx].copy(), Y.loc[test_idx].copy()\n",
    "        )\n",
    "        break\n",
    "\n",
    "    if model_name == 'knn':\n",
    "        model = KNeighborsClassifier(n_neighbors=n, metric=KNN_METRIC)#, algorithm='kd_tree')\n",
    "    elif model_name == 'lda':\n",
    "        model = LinearDiscriminantAnalysis()\n",
    "    elif model_name == 'bayes':\n",
    "        model = GaussianNB()\n",
    "    elif model_name == 'svm':\n",
    "        model = LinearSVC()\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    return model\n",
    "    \n",
    "\n",
    "def project_classes(X, Y, size=(10, 8), boundary=False, pc=None):\n",
    "    Y = Y.dropna()\n",
    "    X = X[X.index.isin(Y.index)].copy()\n",
    "    Y = Y[Y.index.isin(X.index)].astype('category')\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X[X.columns] = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "    print(silhouette_score(X, Y))\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    X_pca = pd.DataFrame(X_pca)\n",
    "\n",
    "    categories = Y.cat.categories\n",
    "    colors = sb.color_palette('hls', len(categories))\n",
    "    cmap = ListedColormap(colors.as_hex())\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=size)\n",
    "\n",
    "    i, j = (0, 1) if pc is None else pc\n",
    "\n",
    "    # KNN model\n",
    "    if boundary:\n",
    "        h = .02\n",
    "        model = model_boundaries(X_pca, Y.cat.codes, model_name=MODEL_TYPE)\n",
    "        x_min = X_pca[i].min() - X_pca[i].std()\n",
    "        x_max = X_pca[i].max() + X_pca[i].std()\n",
    "        y_min = X_pca[j].min() - X_pca[j].std()\n",
    "        y_max = X_pca[j].max() + X_pca[j].std()\n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                             np.arange(y_min, y_max, h))\n",
    "        Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "        # Put the result into a color plot\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        ax.pcolormesh(xx, yy, Z, cmap=cmap, alpha=0.5)\n",
    "\n",
    "\n",
    "    ax.scatter(X_pca[0], X_pca[1], c=Y.cat.codes, cmap=cmap, edgecolors='black')\n",
    "\n",
    "    legend_entries = []\n",
    "    for c, n in dict(zip(Y.cat.codes, Y)).items():\n",
    "        if n != 'nan':\n",
    "            legend_entries.append(\n",
    "                mpatches.Patch(color=colors[c], label=n)\n",
    "            )\n",
    "\n",
    "    ax.legend(handles=legend_entries)\n",
    "\n",
    "    var = 100 * pca.explained_variance_ratio_\n",
    "    ax.set_xlabel(f'PC1 ({var[0]:.2f} %)')\n",
    "    ax.set_ylabel(f'PC2 ({var[1]:.2f} %)')\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def project_classes_3d(X, Y, size=(15, 4)):\n",
    "    Y = Y.dropna()\n",
    "    X = X[X.index.isin(Y.index)].copy()\n",
    "    Y = Y[Y.index.isin(X.index)].astype('category')\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X[X.columns] = scaler.fit_transform(X)\n",
    "\n",
    "    print(silhouette_score(X, Y))\n",
    "\n",
    "    pca = PCA(n_components=3)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    X_pca = pd.DataFrame(X_pca)\n",
    "\n",
    "    categories = Y.cat.categories\n",
    "    colors = sb.color_palette('hls', len(categories))\n",
    "    fig, ax = plt.subplots(1, 3, figsize=size)\n",
    "\n",
    "    for pos, dim in enumerate([(0, 1), (0, 2), (1, 2)]):\n",
    "        i, j = dim\n",
    "        for label, color in zip(categories, colors):\n",
    "            rows = list(Y[Y == label].index)\n",
    "            x = X_pca[X_pca.index.isin(rows)][i]\n",
    "            y = X_pca[X_pca.index.isin(rows)][j]\n",
    "            ax[pos].scatter(x, y, s=2, color=color, label=label)\n",
    "\n",
    "        var = 100 * pca.explained_variance_ratio_\n",
    "        ax[pos].set_xlabel(f'PC{i+1} ({var[i]:.2f} %)')\n",
    "        ax[pos].set_ylabel(f'PC{j+1} ({var[j]:.2f} %)')\n",
    "        ax[pos].grid(True)\n",
    "        ax[pos].legend()\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mafaulda temporal\n",
    "project_classes(mafaulda['X_td'], mafaulda['Y']['target'], boundary=True)\n",
    "project_classes_3d(mafaulda['X_td'], mafaulda['Y']['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mafaulda spectral\n",
    "project_classes(mafaulda['X_fd'], mafaulda['Y']['target'], boundary=True)\n",
    "project_classes_3d(mafaulda['X_fd'], mafaulda['Y']['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_places = (pump['Y']['device'] + ',' + pump['Y']['position']).astype('category')\n",
    "project_classes(pump['X_td'], all_places, size=(10, 7), boundary=True)\n",
    "project_classes(pump['X_fd'], all_places, size=(10, 7), boundary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fluid pump temporal\n",
    "project_classes(pump['X_td'], pump['Y']['target'], boundary=True)\n",
    "project_classes_3d(pump['X_td'], pump['Y']['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_classes(pump['X_td'], pump['Y']['label_machine'], boundary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_classes(pump['X_td'], pump['Y']['label_position'], boundary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_classes(pump['X_td'], pump['Y']['label_binary'], boundary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fluid pump spectral\n",
    "project_classes(pump['X_fd'], pump['Y']['target'], boundary=True)\n",
    "project_classes_3d(pump['X_fd'], pump['Y']['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_classes(pump['X_fd'], pump['Y']['label_machine'], boundary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_classes(pump['X_fd'], pump['Y']['label_position'], boundary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_classes(pump['X_fd'], pump['Y']['label_binary'], boundary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_machines(features: pd.DataFrame, labels: pd.DataFrame, machines: tuple):\n",
    "    m = features.copy()\n",
    "    columns = m.columns\n",
    "    m['target'] = labels.astype('str')\n",
    "    m = m[m['target'].isin(machines)].reset_index(drop=True)\n",
    "    m['target'] = m['target'].astype('category')\n",
    "\n",
    "    X = m[columns].copy()\n",
    "    Y = m['target']\n",
    "    project_classes(X, Y, boundary=True)\n",
    "    project_classes_3d(X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressors = ('C1', 'C2')\n",
    "visualize_machines(pump['X_td'], pump['Y']['target'], compressors)\n",
    "visualize_machines(pump['X_fd'], pump['Y']['target'], compressors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterpumps = ('P1', 'P2')\n",
    "visualize_machines(pump['X_td'], pump['Y']['target'], waterpumps)\n",
    "visualize_machines(pump['X_fd'], pump['Y']['target'], waterpumps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motors = ('M1', 'M2')\n",
    "visualize_machines(pump['X_td'], pump['Y']['target'], motors)\n",
    "visualize_machines(pump['X_fd'], pump['Y']['target'], motors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change in compressors features over time\n",
    "- Each domain (2x)\n",
    "    - Scatter plot PCA - position - colors are dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_compressors_by_date(X, Y):\n",
    "    for placement, rows in Y[Y['device'].isin(('K3', 'K5'))].groupby(by=['device', 'position']):\n",
    "        idx = list(rows.index)\n",
    "        rows['date'] = rows['date'].astype('category')\n",
    "        print(placement)\n",
    "        project_classes(X, rows['date'], boundary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_compressors_by_date(pump['X_td'], pump['Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_compressors_by_date(pump['X_fd'], pump['Y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification accuracy \n",
    "- choices of k. and feat. count, 5-fold cross validation\n",
    "\n",
    "- All features \n",
    "    - for mafaulda and custom (which classes - all or just one machine)\n",
    "    - 1 ks All features (2x subplots TD, FD)\n",
    "\t    - Each lineplot (k = 3,5,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_accuracy(X, Y, k_neighbors, kfolds, model_name):\n",
    "    # Remove missing data\n",
    "    Y = Y.dropna()\n",
    "    X = X[X.index.isin(Y.index)]\n",
    "    Y = Y[Y.index.isin(X.index)].astype('category')\n",
    "\n",
    "    # Class balancing\n",
    "    oversample = RandomOverSampler(sampling_strategy='not majority', random_state=10)\n",
    "    X, Y = oversample.fit_resample(X, Y.to_numpy())\n",
    "    X.reset_index(drop=True, inplace=True)\n",
    "    Y = pd.Series(Y)\n",
    "\n",
    "    kf = KFold(n_splits=kfolds, shuffle=True, random_state=10)\n",
    "    round_train_acc = []\n",
    "    round_test_acc = []\n",
    "\n",
    "    for train_idx, test_idx in kf.split(X, Y):\n",
    "        # Train / Test split in KFold\n",
    "        x_train, x_test, y_train, y_test = (\n",
    "            X.loc[train_idx].copy(), X.loc[test_idx].copy(),\n",
    "            Y.loc[train_idx].copy(), Y.loc[test_idx].copy()\n",
    "        )\n",
    "        # Scale\n",
    "        scaler = MinMaxScaler()\n",
    "        x_train[x_train.columns] = scaler.fit_transform(x_train)\n",
    "        x_test[x_test.columns] = scaler.transform(x_test)\n",
    "    \n",
    "        # Train k-NN model on all features\n",
    "        if model_name == 'knn':\n",
    "            model = KNeighborsClassifier(n_neighbors=k_neighbors, metric=KNN_METRIC)#, algorithm='kd_tree')\n",
    "        elif model_name == 'lda':\n",
    "            model = LinearDiscriminantAnalysis()\n",
    "        elif model_name == 'bayes':\n",
    "            model = GaussianNB()\n",
    "        elif model_name == 'svm':\n",
    "            model = LinearSVC()\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "        y_predict_train = model.predict(x_train)\n",
    "        y_predict_test = model.predict(x_test)\n",
    "\n",
    "        round_train_acc.append(metrics.accuracy_score(y_train, y_predict_train))\n",
    "        round_test_acc.append(metrics.accuracy_score(y_test, y_predict_test))\n",
    "    \n",
    "    return {\n",
    "        'train': np.array(round_train_acc).mean(),\n",
    "        'test': np.array(round_test_acc).mean()\n",
    "    }\n",
    "\n",
    "\n",
    "def all_features(X, Y, model, k_neighbors=tuple(range(1, 40, 4)), kfold_param=5) -> dict:\n",
    "    # Remove missing data\n",
    "    Y = Y.dropna()\n",
    "    X = X[X.index.isin(Y.index)]\n",
    "    Y = Y[Y.index.isin(X.index)].astype('category')\n",
    "\n",
    "    # Class balancing\n",
    "    oversample = RandomOverSampler(sampling_strategy='not majority', random_state=10)\n",
    "    X, Y = oversample.fit_resample(X, Y.to_numpy())\n",
    "    X.reset_index(drop=True, inplace=True)\n",
    "    Y = pd.Series(Y)\n",
    "\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "\n",
    "    for k in k_neighbors:\n",
    "        accuracy = kfold_accuracy(X, Y, k, kfold_param, model)\n",
    "        train_accuracy.append(accuracy['train'])\n",
    "        test_accuracy.append(accuracy['test'])\n",
    "\n",
    "    return {\n",
    "        'k': k_neighbors,\n",
    "        'train': train_accuracy,\n",
    "        'test': test_accuracy\n",
    "    }\n",
    "\n",
    "def plot_all_knn(td_results, fd_results, kfold=5):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "    ax.plot(td_results['k'], td_results['train'], marker='x', color='darkblue', label='train - temporal')\n",
    "    ax.plot(td_results['k'], td_results['test'], marker='x', color='blue', label='test - temporal')\n",
    "\n",
    "    ax.plot(fd_results['k'], fd_results['train'], marker='x', color='darkgreen', label='train - spectral')\n",
    "    ax.plot(fd_results['k'], fd_results['test'], marker='x', color='green', label='test - spectral')\n",
    "\n",
    "    ax.set_ylabel(f'Accuracy')\n",
    "    ax.set_xlabel('K-neighbors')\n",
    "    ax.set_xticks(td_results['k'])\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_results = all_features(mafaulda['X_td'], mafaulda['Y']['target'], MODEL_TYPE)\n",
    "fd_results = all_features(mafaulda['X_fd'], mafaulda['Y']['target'], MODEL_TYPE)\n",
    "plot_all_knn(td_results, fd_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_results = all_features(pump['X_td'], pump['Y']['target'], MODEL_TYPE)\n",
    "fd_results = all_features(pump['X_fd'], pump['Y']['target'], MODEL_TYPE)\n",
    "plot_all_knn(td_results, fd_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_results = all_features(pump['X_td'], pump['Y']['label_machine'], MODEL_TYPE)\n",
    "fd_results = all_features(pump['X_fd'], pump['Y']['label_machine'], MODEL_TYPE)\n",
    "plot_all_knn(td_results, fd_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_results = all_features(pump['X_td'], pump['Y']['label_position'], MODEL_TYPE)\n",
    "fd_results = all_features(pump['X_fd'], pump['Y']['label_position'], MODEL_TYPE)\n",
    "plot_all_knn(td_results, fd_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_results = all_features(pump['X_td'], pump['Y']['label_binary'], MODEL_TYPE)\n",
    "fd_results = all_features(pump['X_fd'], pump['Y']['label_binary'], MODEL_TYPE)\n",
    "plot_all_knn(td_results, fd_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All models (Exhausive) \n",
    "    - draw rank, corr, f-stat, mi as horizontal line\n",
    "    - 3 ks plots (2, 3, 4 features)\n",
    "\t    - Each plot 2 boxplot subplots (TD, FD) - k-neigh. vs. accuracy of all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_combinations(\n",
    "        X: pd.DataFrame,\n",
    "        Y: pd.DataFrame,\n",
    "        k_neighbors: int,\n",
    "        num_of_features: int,\n",
    "        kfolds: int,\n",
    "        domain: str,\n",
    "        model: str) -> list:\n",
    "    \n",
    "    results = []\n",
    "    for features in tqdm(itertools.combinations(X.columns, r=num_of_features)):\n",
    "        r = kfold_accuracy(X[list(features)], Y, k_neighbors, kfolds, model)\n",
    "        r.update({'features': list(features), 'f': num_of_features, 'k': k_neighbors, 'domain': domain})\n",
    "        results.append(r)\n",
    "    return results\n",
    "\n",
    "\n",
    "def enumerate_models(\n",
    "        X_temporal: pd.DataFrame,\n",
    "        X_spectral: pd.DataFrame,\n",
    "        Y: pd.DataFrame,\n",
    "        k_neighbors: Tuple[int] = (3, 5, 11, 15),\n",
    "        num_of_features: Tuple[int] = (2, 3, 4, 5), \n",
    "        kfolds=5,\n",
    "        model='knn') -> pd.DataFrame:\n",
    "\n",
    "    models = []\n",
    "    domains = {'temporal': X_temporal, 'spectral': X_spectral}\n",
    "\n",
    "    for fnum in num_of_features:\n",
    "        for domain, X in domains.items():\n",
    "            for k in k_neighbors:\n",
    "                result = feature_combinations(X, Y, k, fnum, kfolds, domain, model)\n",
    "                models.extend(result)\n",
    "                \n",
    "    return pd.DataFrame.from_records(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6156 models (120/165, 210/330, 252/462), 25 minutes (longer because of oversampling)\n",
    "mafaulda_models_summary = enumerate_models(mafaulda['X_td'], mafaulda['X_fd'], mafaulda['Y']['target'], model=MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mafaulda_models_summary.to_csv('mafaulda_models_summary.csv')\n",
    "mafaulda_models_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pump_models_summary_machine = enumerate_models(pump['X_td'], pump['X_fd'], pump['Y']['label_machine'], model=MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pump_models_summary_position = enumerate_models(pump['X_td'], pump['X_fd'], pump['Y']['label_position'], model=MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pump_models_summary_binary = enumerate_models(pump['X_td'], pump['X_fd'], pump['Y']['label_binary'], model=MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_enumerate_models_accuracy(results, metric, plots_col, inplot_col):\n",
    "    for fnum, features in results.groupby(by=plots_col):\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(10, 4), sharey=True)\n",
    "        for i, group in enumerate(features.groupby(by='domain', sort=False)):\n",
    "            domain_name, domain = group \n",
    "            ax[i].grid()\n",
    "            \n",
    "            if plots_col == 'k':\n",
    "                ax[i].set_title(f'K-neighbors: {fnum}, Domain: {domain_name}')\n",
    "            if plots_col == 'f':\n",
    "                ax[i].set_title(f'Features: {fnum}, Domain: {domain_name}')\n",
    "\n",
    "            boxplot_data = {}\n",
    "            for k, models in domain.groupby(by=[inplot_col]):\n",
    "                boxplot_data[k[0]] = models[metric].to_list()\n",
    "\n",
    "            ax[i].boxplot(\n",
    "                boxplot_data.values(),\n",
    "                labels=boxplot_data.keys(),\n",
    "                medianprops = {'linewidth': 2, 'color': 'black'})\n",
    "            ax[i].set_ylabel('Accuracy')\n",
    "            if plots_col == 'f':\n",
    "                ax[i].set_xlabel('K-neighbors')\n",
    "            if plots_col == 'k':\n",
    "                ax[i].set_xlabel('Number of features')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MaFaulDa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_enumerate_models_accuracy(mafaulda_models_summary, 'train', 'f', 'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_enumerate_models_accuracy(mafaulda_models_summary, 'test', 'f', 'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_enumerate_models_accuracy(mafaulda_models_summary, 'train', 'k', 'f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_enumerate_models_accuracy(mafaulda_models_summary, 'test', 'k', 'f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Water pumps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplot_enumerate_models_accuracy(pump_models_summary_machine, 'train', 'f', 'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplot_enumerate_models_accuracy(pump_models_summary_machine, 'test', 'f', 'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplot_enumerate_models_accuracy(pump_models_summary_machine, 'train', 'k', 'f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplot_enumerate_models_accuracy(pump_models_summary_machine, 'test', 'k', 'f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplot_enumerate_models_accuracy(pump_models_summary_position, 'train', 'f', 'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplot_enumerate_models_accuracy(pump_models_summary_position, 'test', 'f', 'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplot_enumerate_models_accuracy(pump_models_summary_position, 'train', 'k', 'f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplot_enumerate_models_accuracy(pump_models_summary_position, 'test', 'k', 'f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplot_enumerate_models_accuracy(pump_models_summary_binary, 'train', 'f', 'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplot_enumerate_models_accuracy(pump_models_summary_binary, 'test', 'f', 'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplot_enumerate_models_accuracy(pump_models_summary_binary, 'train', 'k', 'f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplot_enumerate_models_accuracy(pump_models_summary_binary, 'test', 'k', 'f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compare accuracies of best models in each categories for given number of features and k:\n",
    "    - 1 ks plot - bar chart - color rainbow - one x (td), second x (fd)\n",
    "    - Scores side by side (bar chart)\n",
    "    - best permuted, pca, rank product, corr, fstat, mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def find_best_subset(X, Y, metric, members=3, kfolds=5):\n",
    "    Y = Y.dropna().astype('category')\n",
    "    X = X[X.index.isin(Y.index)].copy()\n",
    "    Y = Y[Y.index.isin(X.index)].astype('category')\n",
    "    X = X.reset_index(drop=True)\n",
    "    Y = Y.reset_index(drop=True)\n",
    "\n",
    "    kf = KFold(n_splits=kfolds, shuffle=True, random_state=10)\n",
    "    elements = []\n",
    "\n",
    "    for train_idx, test_idx in kf.split(X, Y):\n",
    "        x_train, x_test, y_train, y_test = (\n",
    "            X.loc[train_idx].copy(), X.loc[test_idx].copy(),\n",
    "            Y.loc[train_idx].copy(), Y.loc[test_idx].copy()\n",
    "        )\n",
    "        ranks = ranking.batch_feature_ranking(x_train, y_train, metric)\n",
    "        if metric != 'rank':\n",
    "            synonyms = ranking.compute_correlations(x_train, corr_above=0.95)\n",
    "            subset = ranking.best_subset(ranks, synonyms, n=members)\n",
    "            output = subset\n",
    "        else:\n",
    "            output = ranks\n",
    "\n",
    "        output = list(output.reset_index().head(3)['feature'])\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def transform_to_pca(X, n):\n",
    "    scaler = MinMaxScaler()\n",
    "    X[X.columns] = scaler.fit_transform(X)\n",
    "\n",
    "    pca = PCA(n_components=n)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    X_pca = pd.DataFrame(X_pca)\n",
    "    return X_pca\n",
    "\n",
    "\n",
    "def plot_models_performance_bar(\n",
    "        X_temporal: pd.DataFrame,\n",
    "        X_spectral: pd.DataFrame, \n",
    "        Y: pd.DataFrame,\n",
    "        models_summary: pd.DataFrame,\n",
    "        k_neighbors: int = 5,\n",
    "        number_of_features: int = 3):\n",
    "\n",
    "    Y = Y.dropna().astype('category')\n",
    "    X_temporal = X_temporal[X_temporal.index.isin(Y.index)].copy()\n",
    "    X_spectral = X_spectral[X_spectral.index.isin(Y.index)].copy()\n",
    "    Y = Y[Y.index.isin(X_temporal.index)].astype('category')\n",
    "\n",
    "    X_temporal = X_temporal.reset_index(drop=True)\n",
    "    X_spectral = X_spectral.reset_index(drop=True)\n",
    "    Y = Y.reset_index(drop=True)\n",
    "    Y = Y.cat.codes\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5)) \n",
    "    columns = ['train', 'test']\n",
    "    kfolds = 5\n",
    "    x = np.arange(len(columns))\n",
    "    domains = {'temporal': X_temporal, 'spectral': X_spectral}\n",
    "\n",
    "    for i, d in enumerate(domains.items()):\n",
    "        domain, X = d \n",
    "        width = 0.13\n",
    "\n",
    "        y_best = all_features(X, Y, MODEL_TYPE, [k_neighbors])\n",
    "        y_best = [y_best['train'][0], y_best['test'][0]]\n",
    "        rect = ax[i].bar(x - 3*width, y_best, width, label='All features')\n",
    "        ax[i].bar_label(rect, padding=3, fmt=lambda x: f'{x * 100:.0f}')\n",
    "        print('All features', y_best)\n",
    "\n",
    "        y_best = kfold_accuracy(transform_to_pca(X, n=number_of_features), Y, k_neighbors, kfolds, MODEL_TYPE)\n",
    "        y_best = [y_best['train'], y_best['test']]\n",
    "        rect = ax[i].bar(x - 2*width, y_best, width, label='PCA 3 PC')\n",
    "        ax[i].bar_label(rect, padding=3, fmt=lambda x: f'{x * 100:.0f}')\n",
    "        print('PCA 3 PC', y_best)\n",
    "\n",
    "        y_best = models_summary[\n",
    "            (models_summary['domain'] == domain) &\n",
    "            (models_summary['k'] == k_neighbors) & \n",
    "            (models_summary['f'] == number_of_features)\n",
    "        ].sort_values(by='train', ascending=False).head(1).to_dict('records')[0]\n",
    "        print('Best 3 features', y_best)\n",
    "        y_best = [y_best['train'], y_best['test']]\n",
    "        rect = ax[i].bar(x - 1*width, y_best, width, label='Best 3 features')\n",
    "        ax[i].bar_label(rect, padding=3, fmt=lambda x: f'{x * 100:.0f}')\n",
    "        print('Best 3 features', y_best)\n",
    "   \n",
    "        features = find_best_subset(X, Y, 'rank', number=number_of_features)\n",
    "        y_best = kfold_accuracy(X[list(features)], Y, k_neighbors, kfolds, MODEL_TYPE)\n",
    "        y_best = [y_best['train'], y_best['test']]\n",
    "        rect = ax[i].bar(x - 0*width, y_best, width, label='Rank product')\n",
    "        ax[i].bar_label(rect, padding=3, fmt=lambda x: f'{x * 100:.0f}')\n",
    "        print('Rank product', y_best)\n",
    "\n",
    "        features = find_best_subset(X, Y, 'corr', number=number_of_features)\n",
    "        y_best = kfold_accuracy(X[list(features)], Y, k_neighbors, kfolds, MODEL_TYPE)\n",
    "        y_best = [y_best['train'], y_best['test']]\n",
    "        rect = ax[i].bar(x + 1*width, y_best, width, label='Correlation')\n",
    "        ax[i].bar_label(rect, padding=3, fmt=lambda x: f'{x * 100:.0f}')\n",
    "        print('Correlation', y_best)\n",
    "\n",
    "        features = find_best_subset(X, Y, 'f_stat', number=number_of_features)\n",
    "        y_best = kfold_accuracy(X[list(features)], Y, k_neighbors, kfolds, MODEL_TYPE)\n",
    "        y_best = [y_best['train'], y_best['test']]\n",
    "        rect = ax[i].bar(x + 2*width, y_best, width, label='F statistic')\n",
    "        ax[i].bar_label(rect, padding=3, fmt=lambda x: f'{x * 100:.0f}')\n",
    "        print('F statistic', y_best)\n",
    "        \n",
    "        features = find_best_subset(X, Y, 'mi', number=number_of_features)\n",
    "        y_best = kfold_accuracy(X[list(features)], Y, k_neighbors, kfolds, MODEL_TYPE)\n",
    "        y_best = [y_best['train'], y_best['test']]\n",
    "        rect = ax[i].bar(x + 3*width, y_best, width, label='Mutual information')\n",
    "        ax[i].bar_label(rect, padding=3, fmt=lambda x: f'{x * 100:.0f}')\n",
    "        print('Mutual information', y_best)\n",
    "\n",
    "        ax[i].set_xticks(x, columns)\n",
    "        ax[i].legend(loc='lower right')\n",
    "        ax[i].set_ylim(0.5, None)\n",
    "        ax[i].set_title(domain)\n",
    "        \n",
    "        ax[i].set_ylabel('Accuracy')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_models_performance_bar(mafaulda['X_td'], mafaulda['X_fd'], mafaulda['Y']['target'], mafaulda_models_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_models_performance_bar(pump['X_td'], pump['X_fd'], pump['Y']['label_machine'], pump_models_summary_machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_models_performance_bar(pump['X_td'], pump['X_fd'], pump['Y']['label_position'], pump_models_summary_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_models_performance_bar(pump['X_td'], pump['X_fd'], pump['Y']['label_binary'], pump_models_summary_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_models_performance_bar(pump['X_td'], pump['X_fd'], pump['Y']['target'], pump_models_summary)\n",
    "# Scatter plot of best features with rank product\n",
    "def scatter_features_3d(X, Y, features: list, size=(15, 5), boundary=False):\n",
    "    Y = Y.dropna()\n",
    "    X = X[X.index.isin(Y.index)].copy()\n",
    "    Y = Y[Y.index.isin(X.index)].astype('category')\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X[X.columns] = scaler.fit_transform(X)\n",
    "\n",
    "    categories = Y.cat.categories\n",
    "    colors = sb.color_palette('hls', len(categories))\n",
    "    cmap = ListedColormap(colors.as_hex())\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=size)\n",
    "\n",
    "    for i, dims in enumerate([(0, 1), (0, 2), (1, 2)]):\n",
    "        a, b = dims\n",
    "        columns = [features[a], features[b]]\n",
    "        p, q = X[columns[0]], X[columns[1]]\n",
    " \n",
    "        if boundary:\n",
    "            h = .02\n",
    "            model = model_boundaries(X[columns], Y.cat.codes, model_name=MODEL_TYPE)\n",
    "            x_min = p.min() - p.std()\n",
    "            x_max = p.max() + p.std()\n",
    "            y_min = q.min() - q.std()\n",
    "            y_max = q.max() + q.std()\n",
    "            xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                                np.arange(y_min, y_max, h))\n",
    "            Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "            Z = Z.reshape(xx.shape)\n",
    "            ax[i].pcolormesh(xx, yy, Z, cmap=cmap, alpha=0.5)\n",
    "\n",
    "        ax[i].scatter(\n",
    "            p, q, c=Y.cat.codes, cmap=cmap, edgecolors='black'\n",
    "        )\n",
    "\n",
    "        legend_entries = []\n",
    "        for c, n in dict(zip(Y.cat.codes, Y)).items():\n",
    "            legend_entries.append(\n",
    "                mpatches.Patch(color=colors[c], label=n)\n",
    "            )\n",
    "        ax[1].legend(handles=legend_entries)\n",
    "        ax[i].set_xlabel(columns[0])\n",
    "        ax[i].set_ylabel(columns[1])\n",
    "        ax[i].grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mafaulda['X_td']\n",
    "Y = mafaulda['Y']['target']\n",
    "features = find_best_subset(X, Y, 'rank')\n",
    "scatter_features_3d(X, Y, list(features), boundary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mafaulda['X_fd']\n",
    "Y = mafaulda['Y']['target']\n",
    "features = find_best_subset(X, Y, 'rank')\n",
    "scatter_features_3d(X, Y, list(features), boundary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3d plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_features_3d_plot(X, Y, features: list, size=(8, 8), boundary=False):\n",
    "    Y = Y.dropna()\n",
    "    X = X[X.index.isin(Y.index)].copy()\n",
    "    Y = Y[Y.index.isin(X.index)].astype('category')\n",
    "\n",
    "    X = X.reset_index(drop=True)\n",
    "    Y = Y.reset_index(drop=True)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = X.copy()\n",
    "    X_scaled[X_scaled.columns] = scaler.fit_transform(X_scaled)\n",
    "\n",
    "    categories = Y.astype('category').cat.categories\n",
    "    colors = sb.color_palette('hls', len(categories))\n",
    "    cmap = ListedColormap(colors.as_hex())\n",
    "\n",
    "    fig = plt.figure(figsize=size)\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    columns = [features[0], features[1], features[2]]\n",
    "\n",
    "    model = model_boundaries(X_scaled[columns], Y, model_name=MODEL_TYPE)\n",
    "    Y_predict = Y.to_frame('true')\n",
    "    Y_predict['predict'] = pd.Series(model.predict(X_scaled[columns]))\n",
    "    \n",
    "    Y_good = Y_predict.loc[Y_predict['true'] == Y_predict['predict']]\n",
    "    X_good = X[X.index.isin(Y_good.index)]\n",
    "    xs, ys, zs = X_good[columns[0]], X_good[columns[1]], X_good[columns[2]]\n",
    "    ax.scatter(xs, ys, zs, c=Y_good['true'].cat.codes, cmap=cmap, s=5)\n",
    "\n",
    "    Y_bad = Y_predict.loc[Y_predict['true'] != Y_predict['predict']]\n",
    "    X_bad = X[X.index.isin(Y_bad.index)]\n",
    "    xs, ys, zs = X_bad[columns[0]], X_bad[columns[1]], X_bad[columns[2]]\n",
    "    ax.scatter(xs, ys, zs, c=Y_bad['true'].cat.codes, marker='X', cmap=cmap, linewidths=1, edgecolors='black')\n",
    "\n",
    "    legend_entries = []\n",
    "    for c, n in dict(zip(Y.cat.codes, Y)).items():\n",
    "        legend_entries.append(\n",
    "            mpatches.Patch(color=colors[c], label=n)\n",
    "        )\n",
    "    ax.legend(handles=legend_entries)\n",
    "    ax.set_xlabel(columns[0], labelpad=10)\n",
    "    ax.set_ylabel(columns[1], labelpad=10)\n",
    "    ax.set_zlabel(columns[2], labelpad=10)\n",
    "    ax.grid(True)\n",
    "    ax.view_init(elev=20, azim=-45)\n",
    "    ax.set_box_aspect(None, zoom=0.85)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mafaulda['X_td']\n",
    "Y = mafaulda['Y']['target']\n",
    "features = find_best_subset(X, Y, 'rank')\n",
    "scatter_features_3d_plot(X, Y, list(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mafaulda['X_fd']\n",
    "Y = mafaulda['Y']['target']\n",
    "features = find_best_subset(X, Y, 'rank')\n",
    "scatter_features_3d_plot(X, Y, list(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pump['X_td']\n",
    "Y = pump['Y']['label_machine']\n",
    "features = find_best_subset(X, Y, 'rank')\n",
    "scatter_features_3d_plot(X, Y, list(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pump['X_td']\n",
    "Y = pump['Y']['label_position']\n",
    "features = find_best_subset(X, Y, 'rank')\n",
    "scatter_features_3d_plot(X, Y, list(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pump['X_td']\n",
    "Y = pump['Y']['label_binary']\n",
    "features = find_best_subset(X, Y, 'rank')\n",
    "scatter_features_3d_plot(X, Y, list(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pump['X_fd']\n",
    "Y = pump['Y']['label_machine']\n",
    "features = find_best_subset(X, Y, 'rank')\n",
    "scatter_features_3d_plot(X, Y, list(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pump['X_fd']\n",
    "Y = pump['Y']['label_position']\n",
    "features = find_best_subset(X, Y, 'rank')\n",
    "scatter_features_3d_plot(X, Y, list(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pump['X_fd']\n",
    "Y = pump['Y']['label_binary']\n",
    "features = find_best_subset(X, Y, 'rank')\n",
    "scatter_features_3d_plot(X, Y, list(features))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

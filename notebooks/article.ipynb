{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures for IIT SRC article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks, butter, lfilter, windows, welch\n",
    "from typing import Tuple\n",
    "import re\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def spectral_transform(dataset: pd.DataFrame, axis: str, window: int, fs: int) -> Tuple[np.array, np.array]:\n",
    "    overlap = 0.5\n",
    "    step = int(window * overlap)\n",
    "\n",
    "    v = dataset[axis].to_numpy()\n",
    "    f, pxx = welch(\n",
    "        v,\n",
    "        fs=fs,\n",
    "        window='hann',\n",
    "        nperseg=window,\n",
    "        noverlap=step,\n",
    "        scaling='spectrum',\n",
    "        average='mean',\n",
    "        detrend='constant',\n",
    "        return_onesided=True\n",
    "    )\n",
    "    return f, pxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mafaulda_columns = ['ax', 'ay', 'az', 'bx', 'by', 'bz']\n",
    "mafaulda_all_columns = ['tachometer', 'ax', 'ay', 'az', 'bx', 'by', 'bz', 'mic']\n",
    "mafaulda_fs_hz = 50000\n",
    "\n",
    "\n",
    "def rpm_calc(tachometer: pd.Series) -> float:\n",
    "    t = tachometer.index.to_numpy()\n",
    "    y = tachometer.to_numpy()\n",
    "    peaks, _ = find_peaks(y, prominence=3, width=50)\n",
    "    interval = np.diff(t[peaks]).mean()\n",
    "    return 60 / interval\n",
    "\n",
    "def mafaulda_lowpass_filter(\n",
    "        data: pd.Series,\n",
    "        cutoff: int = mafaulda_fs_hz // 5,\n",
    "        fs: int = mafaulda_fs_hz,\n",
    "        order: int = 5) -> pd.Series:\n",
    "    \n",
    "    b, a = butter(order, cutoff, fs=fs, btype='lowpass')\n",
    "    y = lfilter(b, a, data.to_numpy())\n",
    "    return pd.Series(data=y, index=data.index)\n",
    "\n",
    "def mafaulda_csv_import(dataset: ZipFile, filename: str) -> pd.DataFrame:\n",
    "    columns = mafaulda_all_columns\n",
    "    ts = pd.read_csv(dataset.open(filename), names=columns)\n",
    "    T = 1 / mafaulda_fs_hz\n",
    "    ts = (\n",
    "        ts\n",
    "        .assign(t = lambda x: x.index * T)\n",
    "        .reset_index()\n",
    "        .assign(t = lambda x: x.index * T)\n",
    "        .set_index('t')\n",
    "        .assign(rpm = lambda x: rpm_calc(x.tachometer))\n",
    "    )\n",
    "    # Detrending\n",
    "    ts[columns] = ts[columns].apply(lambda x: x - x.mean())\n",
    "    # Low pass filter\n",
    "    ts[columns] = ts[columns].apply(mafaulda_lowpass_filter)\n",
    "    return ts.assign(key=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluidpump_columns = ['x', 'y', 'z']\n",
    "fluidpump_all_columns = ['t', 'x', 'y', 'z']\n",
    "fluidpump_fs_hz = 26866\n",
    "\n",
    "def fluidpump_csv_import(dataset: ZipFile, filename: str) -> pd.DataFrame:\n",
    "    ts = pd.read_csv(\n",
    "        dataset.open(filename),\n",
    "        delimiter='\\t',\n",
    "        index_col=False,\n",
    "        header=0,\n",
    "        names=fluidpump_all_columns\n",
    "    ) \n",
    "    g = 9.80665\n",
    "    columns = fluidpump_columns\n",
    "    ts[columns] = ts[columns].apply(lambda x: g * (x / 1000))\n",
    "\n",
    "    T = 1 / fluidpump_fs_hz\n",
    "    ts = ts.assign(t = lambda x: x.index * T)\n",
    "    ts.set_index('t', inplace=True)\n",
    "    time = 10\n",
    "    time_diff = 5\n",
    "    ts = ts.loc[time:time + time_diff]\n",
    "    # Detrending\n",
    "    ts[columns] = ts[columns].apply(lambda x: x - x.mean())\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Signal analysis\n",
    "- 1ks plot (6x subplots) Mafaulda welch from each fault (1s, 2**14 window, hann window)  - largest severity - 2500 rpm\n",
    "- 1ks plot (6x subplots) Custom dataset - each place in one day spectrum (5s segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maufaulda - worst severity at 2500 rpm\n",
    "def plot_psd(ts, axname, fs, name, ax, window=2**14, xlim=2, ylim=0.1):\n",
    "    freqs, pxx = spectral_transform(ts, axname, window, fs)\n",
    "    freqs /= 1000\n",
    "\n",
    "    ax[i].plot(freqs, pxx, color='darkblue')\n",
    "    ax[i].fill_between(freqs, pxx, color='lightblue', alpha=0.3)\n",
    "    ax[i].grid(True)\n",
    "    ax[i].set_xlabel('Frequency [kHz]')\n",
    "    ax[i].set_ylabel('Amplitude [m/s\\u00B2]')\n",
    "    ax[i].set_xlim(0, xlim)\n",
    "    ax[i].set_ylim(0, ylim)\n",
    "    ax[i].set_title(name)\n",
    "\n",
    "\n",
    "axname = 'ay'\n",
    "dataset = ZipFile('../datasets/MAFAULDA.zip')\n",
    "filenames = [\n",
    "    'normal/43.6224.csv',\n",
    "    'horizontal-misalignment/2.0mm/42.5984.csv',\n",
    "    'imbalance/35g/43.6224.csv',\n",
    "    'underhang/cage_fault/35g/43.4176.csv',\n",
    "    'underhang/ball_fault/35g/41.1648.csv',\n",
    "    'underhang/outer_race/35g/43.4176.csv'\n",
    "]\n",
    "fig, ax = plt.subplots(len(filenames), 1, figsize=(10, 10))\n",
    "for i, name in enumerate(filenames):\n",
    "    ts = mafaulda_csv_import(dataset, name)\n",
    "    plot_psd(ts, axname, mafaulda_fs_hz, name, ax, xlim=2, ylim=0.1)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machines - in the same day\n",
    "axname = 'z'\n",
    "dataset = ZipFile('../datasets/FluidPump.zip')\n",
    "filenames = [\n",
    "    'compressor/2024-02-20/K3/001/1.tsv',\n",
    "    'compressor/2024-02-20/K3/002/1.tsv',\n",
    "    'pump/2024-02-27/KSB-1/MTR001/1.tsv',\n",
    "    'pump/2024-02-27/KSB-1/MTR002/1.tsv',\n",
    "    'pump/2024-02-27/KSB-1/PMP003/1.tsv',\n",
    "    'pump/2024-02-27/KSB-1/PMP004/1.tsv',\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(len(filenames), 1, figsize=(10, 10))\n",
    "for i, name in enumerate(filenames):\n",
    "    ts = fluidpump_csv_import(dataset, name)\n",
    "    # change name\n",
    "    plot_psd(ts, axname, fluidpump_fs_hz, name, ax, xlim=5, ylim=0.5)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axname = 'z'\n",
    "dataset = ZipFile('../datasets/FluidPump.zip')\n",
    "filenames = [\n",
    "    'compressor/2024-02-20/K5/001/1.tsv',\n",
    "    'compressor/2024-02-20/K5/002/1.tsv',\n",
    "    'pump/2024-02-27/KSB-7/MTR001/1.tsv',\n",
    "    'pump/2024-02-27/KSB-7/MTR002/1.tsv',\n",
    "    'pump/2024-02-27/KSB-7/PMP003/1.tsv',\n",
    "    'pump/2024-02-27/KSB-7/PMP004/1.tsv'\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(len(filenames), 1, figsize=(10, 10))\n",
    "for i, name in enumerate(filenames):\n",
    "    ts = fluidpump_csv_import(dataset, name)\n",
    "    # change name\n",
    "    plot_psd(ts, axname, fluidpump_fs_hz, name, ax, xlim=5, ylim=0.5)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature analysis:\n",
    "Mafaulda (3) a Custom (4) \n",
    "- 1 ks table (how many faults have how many recordings)\n",
    "- 1 ks plot (2 lines TD, FD) - number of PC vs. explained variance\n",
    "- 1 ks plot (2x subplots TD, FD) - loading plot (PC2)\n",
    "- 1 ks (4 subplots) custom: all machines, pumps, compressors, motors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Explained varinace by PCA components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_PATH = '../datasets/features'\n",
    "TD_FEATURES = os.path.join(FEATURES_PATH, 'mafaulda_temporal.csv')\n",
    "FD_FEATURES = os.path.join(FEATURES_PATH, 'mafaulda_spectral.csv')\n",
    "\n",
    "\n",
    "placements = {\n",
    "    'A': ['ax', 'ay', 'az'],\n",
    "    'B': ['bx', 'by', 'bz']\n",
    "}\n",
    "\n",
    "def get_features_list(domains):\n",
    "    features = []\n",
    "    for dname, dataset in domains.items():\n",
    "        names = pd.read_csv(dataset)\n",
    "        names = names.columns.str.extract(r'([a-z]{2})_([a-z\\_\\-]+)')[1].unique()\n",
    "        features.extend([f'{dname}_{col.strip(\"_\")}' for col in names if not pd.isnull(col)])\n",
    "\n",
    "    return features\n",
    "\n",
    "def load_whole_dataset(dataset: str, domain: str):\n",
    "    features = pd.read_csv(dataset)\n",
    "\n",
    "    axis = placements['A']\n",
    "    columns = features.columns.str.startswith(tuple(axis))\n",
    "    X = features[features.columns[columns]]\n",
    "\n",
    "    # Calculate feature magnitudes from 3D vector\n",
    "    feature_names = get_features_list({domain: dataset})\n",
    "    result = pd.DataFrame()\n",
    "    for name in feature_names:              \n",
    "        # Remove prefix: temporal, spectral\n",
    "        name = re.search(r'[a-z]+_([\\w\\_]+)', name).group(1)\n",
    "        vector_dims = [f'{dim}_{name}' for dim in axis]\n",
    "        result[name] = X[vector_dims].apply(np.linalg.norm, axis=1)\n",
    "    return result\n",
    "\n",
    "\n",
    "def explained_variance(X):\n",
    "    x_scaled = pd.DataFrame()\n",
    "    x_scaled[X.columns] = MinMaxScaler().fit_transform(X)\n",
    "    pca= PCA(n_components=10)\n",
    "    X_pca = pca.fit_transform(x_scaled)\n",
    "    return pca.explained_variance_ratio_\n",
    "\n",
    "\n",
    "def plot_cumulative_explained_variance(td_variance, fd_variance):\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    ax.plot(np.arange(1, len(td_variance) + 1), 100 * np.cumsum(td_variance), marker='s', label='Temporal features')\n",
    "    ax.plot(np.arange(1, len(fd_variance) + 1), 100 * np.cumsum(fd_variance), marker='s', label='Spectral features')\n",
    "    ax.set_xlabel('Number of principal components')\n",
    "    ax.set_ylabel('Explained variance [%]')\n",
    "    ax.grid()\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Mafaulda\n",
    "td_variance = explained_variance(load_whole_dataset(TD_FEATURES, 'temporal'))\n",
    "fd_variance = explained_variance(load_whole_dataset(FD_FEATURES, 'spectral'))\n",
    "plot_cumulative_explained_variance(td_variance, fd_variance)\n",
    "\n",
    "# TODO: pump dataset (all devices, each type - pump, motor, compressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification accuracy (choices of k. and feat. count, 5-fold cross validation)\n",
    "\n",
    "For mafaulda and custom (which classes - all or just one machine)\n",
    "- 1 ks All features (2x subplots TD, FD)\n",
    "\t- Each subplot boxplot (k = 3,5,7)\n",
    "\n",
    "All models (exhausive) - draw rank, corr, f-stat, mi as horizontal line\n",
    "\t- 3 ks plots (2, 3, 4 features)\n",
    "\t\t- Each plot 2 boxplot subplots (TD, FD) - k-neigh. vs. accuracy of all models\n",
    "\n",
    "\n",
    "Compare accuracies of best models in each categories for given number of features and k:\n",
    "- 1 ks plot - bar chart - color rainbow - one x (td), second x (fd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

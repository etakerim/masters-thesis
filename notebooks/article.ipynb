{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures for IIT SRC article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks, butter, lfilter, windows, welch\n",
    "from typing import Tuple\n",
    "import re\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from adjustText import adjust_text\n",
    "\n",
    "\n",
    "def spectral_transform(dataset: pd.DataFrame, axis: str, window: int, fs: int) -> Tuple[np.array, np.array]:\n",
    "    overlap = 0.5\n",
    "    step = int(window * overlap)\n",
    "\n",
    "    v = dataset[axis].to_numpy()\n",
    "    f, pxx = welch(\n",
    "        v,\n",
    "        fs=fs,\n",
    "        window='hann',\n",
    "        nperseg=window,\n",
    "        noverlap=step,\n",
    "        scaling='spectrum',\n",
    "        average='mean',\n",
    "        detrend='constant',\n",
    "        return_onesided=True\n",
    "    )\n",
    "    return f, pxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mafaulda_columns = ['ax', 'ay', 'az', 'bx', 'by', 'bz']\n",
    "mafaulda_all_columns = ['tachometer', 'ax', 'ay', 'az', 'bx', 'by', 'bz', 'mic']\n",
    "mafaulda_fs_hz = 50000\n",
    "\n",
    "\n",
    "def rpm_calc(tachometer: pd.Series) -> float:\n",
    "    t = tachometer.index.to_numpy()\n",
    "    y = tachometer.to_numpy()\n",
    "    peaks, _ = find_peaks(y, prominence=3, width=50)\n",
    "    interval = np.diff(t[peaks]).mean()\n",
    "    return 60 / interval\n",
    "\n",
    "def mafaulda_lowpass_filter(\n",
    "        data: pd.Series,\n",
    "        cutoff: int = mafaulda_fs_hz // 5,\n",
    "        fs: int = mafaulda_fs_hz,\n",
    "        order: int = 5) -> pd.Series:\n",
    "    \n",
    "    b, a = butter(order, cutoff, fs=fs, btype='lowpass')\n",
    "    y = lfilter(b, a, data.to_numpy())\n",
    "    return pd.Series(data=y, index=data.index)\n",
    "\n",
    "def mafaulda_csv_import(dataset: ZipFile, filename: str) -> pd.DataFrame:\n",
    "    columns = mafaulda_all_columns\n",
    "    ts = pd.read_csv(dataset.open(filename), names=columns)\n",
    "    T = 1 / mafaulda_fs_hz\n",
    "    ts = (\n",
    "        ts\n",
    "        .assign(t = lambda x: x.index * T)\n",
    "        .reset_index()\n",
    "        .assign(t = lambda x: x.index * T)\n",
    "        .set_index('t')\n",
    "        .assign(rpm = lambda x: rpm_calc(x.tachometer))\n",
    "    )\n",
    "    # Detrending\n",
    "    ts[columns] = ts[columns].apply(lambda x: x - x.mean())\n",
    "    # Low pass filter\n",
    "    ts[columns] = ts[columns].apply(mafaulda_lowpass_filter)\n",
    "    return ts.assign(key=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluidpump_columns = ['x', 'y', 'z']\n",
    "fluidpump_all_columns = ['t', 'x', 'y', 'z']\n",
    "fluidpump_fs_hz = 26866\n",
    "\n",
    "def fluidpump_csv_import(dataset: ZipFile, filename: str) -> pd.DataFrame:\n",
    "    ts = pd.read_csv(\n",
    "        dataset.open(filename),\n",
    "        delimiter='\\t',\n",
    "        index_col=False,\n",
    "        header=0,\n",
    "        names=fluidpump_all_columns\n",
    "    ) \n",
    "    g = 9.80665\n",
    "    columns = fluidpump_columns\n",
    "    ts[columns] = ts[columns].apply(lambda x: g * (x / 1000))\n",
    "\n",
    "    T = 1 / fluidpump_fs_hz\n",
    "    ts = ts.assign(t = lambda x: x.index * T)\n",
    "    ts.set_index('t', inplace=True)\n",
    "    time = 10\n",
    "    time_diff = 5\n",
    "    ts = ts.loc[time:time + time_diff]\n",
    "    # Detrending\n",
    "    ts[columns] = ts[columns].apply(lambda x: x - x.mean())\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Signal analysis\n",
    "- 1ks plot (6x subplots) Mafaulda welch from each fault (1s, 2**14 window, hann window)  - largest severity - 2500 rpm\n",
    "- 1ks plot (6x subplots) Custom dataset - each place in one day spectrum (5s segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maufaulda - worst severity at 2500 rpm\n",
    "def plot_psd(ts, axname, fs, name, ax, window=2**14, xlim=2, ylim=0.1):\n",
    "    freqs, pxx = spectral_transform(ts, axname, window, fs)\n",
    "    freqs /= 1000\n",
    "\n",
    "    ax[i].plot(freqs, pxx, color='darkblue')\n",
    "    ax[i].fill_between(freqs, pxx, color='lightblue', alpha=0.3)\n",
    "    ax[i].grid(True)\n",
    "    ax[i].set_xlabel('Frequency [kHz]')\n",
    "    ax[i].set_ylabel('Amplitude [m/s\\u00B2]')\n",
    "    ax[i].set_xlim(0, xlim)\n",
    "    ax[i].set_ylim(0, ylim)\n",
    "    ax[i].set_title(name)\n",
    "\n",
    "\n",
    "axname = 'ay'\n",
    "dataset = ZipFile('../datasets/MAFAULDA.zip')\n",
    "filenames = [\n",
    "    'normal/43.6224.csv',\n",
    "    'horizontal-misalignment/2.0mm/42.5984.csv',\n",
    "    'imbalance/35g/43.6224.csv',\n",
    "    'underhang/cage_fault/35g/43.4176.csv',\n",
    "    'underhang/ball_fault/35g/41.1648.csv',\n",
    "    'underhang/outer_race/35g/43.4176.csv'\n",
    "]\n",
    "fig, ax = plt.subplots(len(filenames), 1, figsize=(10, 10))\n",
    "for i, name in enumerate(filenames):\n",
    "    ts = mafaulda_csv_import(dataset, name)\n",
    "    plot_psd(ts, axname, mafaulda_fs_hz, name, ax, xlim=2, ylim=0.1)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machines - in the same day\n",
    "axname = 'z'\n",
    "dataset = ZipFile('../datasets/FluidPump.zip')\n",
    "filenames = [\n",
    "    'compressor/2024-02-20/K3/001/1.tsv',\n",
    "    'compressor/2024-02-20/K3/002/1.tsv',\n",
    "    'pump/2024-02-27/KSB-1/MTR001/1.tsv',\n",
    "    'pump/2024-02-27/KSB-1/MTR002/1.tsv',\n",
    "    'pump/2024-02-27/KSB-1/PMP003/1.tsv',\n",
    "    'pump/2024-02-27/KSB-1/PMP004/1.tsv',\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(len(filenames), 1, figsize=(10, 10))\n",
    "for i, name in enumerate(filenames):\n",
    "    ts = fluidpump_csv_import(dataset, name)\n",
    "    # change name\n",
    "    plot_psd(ts, axname, fluidpump_fs_hz, name, ax, xlim=5, ylim=0.5)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axname = 'z'\n",
    "dataset = ZipFile('../datasets/FluidPump.zip')\n",
    "filenames = [\n",
    "    'compressor/2024-02-20/K5/001/1.tsv',\n",
    "    'compressor/2024-02-20/K5/002/1.tsv',\n",
    "    'pump/2024-02-27/KSB-7/MTR001/1.tsv',\n",
    "    'pump/2024-02-27/KSB-7/MTR002/1.tsv',\n",
    "    'pump/2024-02-27/KSB-7/PMP003/1.tsv',\n",
    "    'pump/2024-02-27/KSB-7/PMP004/1.tsv'\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(len(filenames), 1, figsize=(10, 10))\n",
    "for i, name in enumerate(filenames):\n",
    "    ts = fluidpump_csv_import(dataset, name)\n",
    "    # change name\n",
    "    plot_psd(ts, axname, fluidpump_fs_hz, name, ax, xlim=5, ylim=0.5)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature analysis:\n",
    "Mafaulda (3) a Custom (4) \n",
    "- 1 ks table (how many faults have how many recordings)\n",
    "- 1 ks plot (2 lines TD, FD) - number of PC vs. explained variance\n",
    "- 1 ks plot (2x subplots TD, FD) - loading plot (PC2)\n",
    "- 1 ks (4 subplots) custom: all machines, pumps, compressors, motors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Explained varinace by PCA components and loading plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_list(domains):\n",
    "    features = []\n",
    "    for dname, dataset in domains.items():\n",
    "        names = pd.read_csv(dataset)\n",
    "        names = names.columns.str.extract(r'([a-z]+)_([a-z\\_\\-]+)')[1].unique()\n",
    "        features.extend([f'{dname}_{col.strip(\"_\")}' for col in names if not pd.isnull(col)])\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def load_whole_dataset(dataset: str, domain: str, axis: tuple, label_cols: list = None):\n",
    "    features = pd.read_csv(dataset)\n",
    "\n",
    "    columns = features.columns.str.startswith(axis)\n",
    "    X = features[features.columns[columns]]\n",
    "    if label_cols is not None:\n",
    "        Y = features[label_cols]\n",
    "    else:\n",
    "        Y = pd.DataFrame()\n",
    "    feature_names = get_features_list({domain: dataset})\n",
    "\n",
    "    result = pd.DataFrame()\n",
    "    for name in feature_names:              \n",
    "        name = re.search(r'[a-z]+_([\\w\\_]+)', name).group(1)\n",
    "        vector_dims = [f'{dim}_{name}' for dim in axis]\n",
    "        result[name] = X[vector_dims].apply(np.linalg.norm, axis=1)\n",
    "    X = result\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def explained_variance(X):\n",
    "    x_scaled = pd.DataFrame()\n",
    "    x_scaled[X.columns] = MinMaxScaler().fit_transform(X)\n",
    "    pca= PCA(n_components=10)\n",
    "    X_pca = pca.fit_transform(x_scaled)\n",
    "    return pca.explained_variance_ratio_\n",
    "\n",
    "\n",
    "def get_principal_components(X):\n",
    "    x_scaled = pd.DataFrame()\n",
    "    x_scaled[X.columns] = MinMaxScaler().fit_transform(X)\n",
    "    pca= PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(x_scaled)\n",
    "    return pca.components_\n",
    "\n",
    "\n",
    "def plot_cumulative_explained_variance(td_variance, fd_variance):\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    ax.plot(\n",
    "        np.arange(1, len(td_variance) + 1),\n",
    "        100 * np.cumsum(td_variance), \n",
    "        marker='s', label='Temporal features'\n",
    "    )\n",
    "    ax.plot(\n",
    "        np.arange(1, len(fd_variance) + 1), \n",
    "        100 * np.cumsum(fd_variance),\n",
    "        marker='s', label='Spectral features'\n",
    "    )\n",
    "    ax.set_xlabel('Number of principal components')\n",
    "    ax.set_ylabel('Explained variance [%]')\n",
    "    ax.grid()\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def loading_plot(loadings, feature_names, bottom, top):\n",
    "    xs = loadings[0]\n",
    "    ys = loadings[1]\n",
    "\n",
    "    texts = []\n",
    "    # Plot the loadings on a scatterplot\n",
    "    for i, varnames in enumerate(feature_names):\n",
    "        plt.arrow(\n",
    "            0, 0,   # coordinates of arrow base\n",
    "            xs[i],  # length of the arrow along x\n",
    "            ys[i],  # length of the arrow along y\n",
    "            color='r', \n",
    "            head_width=0.01\n",
    "        )\n",
    "        texts.append(plt.text(xs[i], ys[i], varnames))\n",
    "\n",
    "    # Define the axis\n",
    "    adjust_text(texts, only_move={'points':'y', 'texts':'y'})\n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')\n",
    "    plt.xlim(bottom, top)\n",
    "    plt.ylim(bottom, top)\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MaFaulDa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_PATH = '../datasets/features'\n",
    "dataset = {\n",
    "    'td_features': os.path.join(FEATURES_PATH, 'mafaulda_temporal.csv'),\n",
    "    'fd_features': os.path.join(FEATURES_PATH, 'mafaulda_spectral.csv'),\n",
    "    'axis': ('ax', 'ay', 'az'),\n",
    "    'labels': ['fault', 'severity']\n",
    "}\n",
    "dataset['X_td'], dataset['Y_td'] = (\n",
    "    load_whole_dataset(dataset['td_features'], 'temporal', dataset['axis'], dataset['labels'])\n",
    ")\n",
    "dataset['X_fd'], dataset['Y_fd'] = (\n",
    "    load_whole_dataset(dataset['fd_features'], 'spectral', dataset['axis'], dataset['labels'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explained variance\n",
    "td_variance = explained_variance(dataset['X_td'])\n",
    "fd_variance = explained_variance(dataset['X_fd'])\n",
    "plot_cumulative_explained_variance(td_variance, fd_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading plots\n",
    "td_pc = get_principal_components(dataset['X_td'])\n",
    "fd_pc = get_principal_components(dataset['X_fd'])\n",
    "loading_plot(td_pc, dataset['X_td'].columns, -0.5, 1)\n",
    "loading_plot(fd_pc, dataset['X_fd'].columns, -0.5, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fluid pumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pump dataset (all devices, each type - pump, motor, compressor)\n",
    "FEATURES_PATH = '../datasets/features'\n",
    "dataset = {\n",
    "    'td_features': os.path.join(FEATURES_PATH, 'fluidpump_temporal.csv'),\n",
    "    'fd_features': os.path.join(FEATURES_PATH, 'fluidpump_spectral.csv'),\n",
    "    'axis': ('x', 'y', 'z'),\n",
    "    'labels': ['device', 'position']\n",
    "}\n",
    "dataset['X_td'], dataset['Y_td'] = (\n",
    "    load_whole_dataset(dataset['td_features'], 'temporal', dataset['axis'], dataset['labels'])\n",
    ")\n",
    "dataset['X_fd'], dataset['Y_fd'] = (\n",
    "    load_whole_dataset(dataset['fd_features'], 'spectral', dataset['axis'], dataset['labels'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_variance = explained_variance(dataset['X_td'])\n",
    "fd_variance = explained_variance(dataset['X_fd'])\n",
    "plot_cumulative_explained_variance(td_variance, fd_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading plots\n",
    "td_pc = get_principal_components(dataset['X_td'])\n",
    "fd_pc = get_principal_components(dataset['X_fd'])\n",
    "loading_plot(td_pc, dataset['X_td'].columns, -0.5, 1)\n",
    "loading_plot(fd_pc, dataset['X_fd'].columns, -0.5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split by machine\n",
    "compressor = Y[Y['device'].isin(['K3', 'K5'])].index\n",
    "pump = Y[\n",
    "    Y['device'].isin(['KSB-1', 'KSB-7']) & \n",
    "    Y['position'].isin(['PMP003', 'PMP004'])\n",
    "].index\n",
    "motor = Y[\n",
    "    Y['device'].isin(['KSB-1', 'KSB-7']) & \n",
    "    Y['position'].isin(['MTR001', 'MTR002'])\n",
    "].index\n",
    "\n",
    "td_variance = explained_variance(dataset['X_td'].loc[compressor])\n",
    "fd_variance = explained_variance(dataset['X_fd'].loc[compressor])\n",
    "plot_cumulative_explained_variance(td_variance, fd_variance)\n",
    "\n",
    "td_pc = get_principal_components(dataset['X_td'].loc[compressor])\n",
    "fd_pc = get_principal_components(dataset['X_fd'].loc[compressor])\n",
    "loading_plot(td_pc, dataset['X_td'].columns, -0.5, 1)\n",
    "loading_plot(fd_pc, dataset['X_fd'].columns, -0.5, 1)\n",
    "\n",
    "# -----\n",
    "td_variance = explained_variance(X_td.loc[pump])\n",
    "fd_variance = explained_variance(X_fd.loc[pump])\n",
    "plot_cumulative_explained_variance(td_variance, fd_variance)\n",
    "\n",
    "td_pc = get_principal_components(dataset['X_td'].loc[pump])\n",
    "fd_pc = get_principal_components(dataset['X_fd'].loc[pump])\n",
    "loading_plot(td_pc, dataset['X_td'].columns, -0.5, 1)\n",
    "loading_plot(fd_pc, dataset['X_fd'].columns, -0.5, 1)\n",
    "\n",
    "# -----\n",
    "td_variance = explained_variance(X_td.loc[motor])\n",
    "fd_variance = explained_variance(X_fd.loc[motor])\n",
    "plot_cumulative_explained_variance(td_variance, fd_variance)\n",
    "\n",
    "td_pc = get_principal_components(dataset['X_td'].loc[motor])\n",
    "fd_pc = get_principal_components(dataset['X_fd'].loc[motor])\n",
    "loading_plot(td_pc, dataset['X_td'].columns, -0.5, 1)\n",
    "loading_plot(fd_pc, dataset['X_fd'].columns, -0.5, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1A. Class labels count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Scatter plots of labels\n",
    "- 1 ks (5 subplots) scatter: mafaulda, all machines, pumps, compressors, motors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification accuracy (choices of k. and feat. count, 5-fold cross validation)\n",
    "\n",
    "For mafaulda and custom (which classes - all or just one machine)\n",
    "- 1 ks All features (2x subplots TD, FD)\n",
    "\t- Each subplot boxplot (k = 3,5,7)\n",
    "\n",
    "All models (exhausive) - draw rank, corr, f-stat, mi as horizontal line\n",
    "\t- 3 ks plots (2, 3, 4 features)\n",
    "\t\t- Each plot 2 boxplot subplots (TD, FD) - k-neigh. vs. accuracy of all models\n",
    "\n",
    "\n",
    "Compare accuracies of best models in each categories for given number of features and k:\n",
    "- 1 ks plot - bar chart - color rainbow - one x (td), second x (fd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

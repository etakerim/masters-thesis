{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN streaming data\n",
    "- temporal\n",
    "- spectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DOMAIN = 'temporal' \n",
    "DOMAIN = 'spectral'\n",
    "\n",
    "from river import preprocessing\n",
    "from river import neighbors, utils, evaluate, stream\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from vibrodiagnostics import selection, models, discovery\n",
    "from vibrodiagnostics.selection import METADATA_COLUMNS_ALL\n",
    "from vibrodiagnostics.models import (\n",
    "    fault_labeling, filter_out_metadata_columns, project_classifier_map_plot\n",
    ")\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "import random\n",
    "import functools\n",
    "from collections import defaultdict\n",
    "from sklearn import metrics as skmetrics\n",
    "from tqdm.notebook import tqdm\n",
    "from river import metrics\n",
    "\n",
    "\n",
    "FEATURES_PATH =  '../../datasets/features_data/'\n",
    "FAULT_CLASSES = {\n",
    "    'A': {\n",
    "        'normal': 'normal',\n",
    "        'imbalance': 'imbalance',\n",
    "        'horizontal-misalignment': 'misalignment',\n",
    "        'vertical-misalignment': 'misalignment',\n",
    "        'underhang-outer_race': 'outer race fault',\n",
    "        'underhang-cage_fault': 'cage fault',\n",
    "        'underhang-ball_fault': 'ball fault'\n",
    "    },\n",
    "    'B': {\n",
    "        'normal': 'normal',\n",
    "        'imbalance': 'imbalance',\n",
    "        'horizontal-misalignment': 'misalignment',\n",
    "        'vertical-misalignment': 'misalignment',\n",
    "        'overhang-cage_fault': 'cage fault',\n",
    "        'overhang-ball_fault': 'ball fault',\n",
    "        'overhang-outer_race': 'outer race fault'\n",
    "    }\n",
    "}\n",
    "\n",
    "TD_FEATURES = os.path.join(FEATURES_PATH, selection.TIME_FEATURES_PATH)\n",
    "FD_FEATURES = os.path.join(FEATURES_PATH, selection.FREQ_FEATURES_PATH)\n",
    "TD_FD_FEATURES = os.path.join(FEATURES_PATH, selection.TIME_AND_FREQ_FEATURES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def knn_online_learn(X, Y, label='fault', window_len=1, learn_skip=0, clusters=False):\n",
    "    # Buffer true samples for learning for later: simulate delayed annotation\n",
    "    learning_window = []\n",
    "\n",
    "    # Model consists of scaler to give approximately same weight to all features and kNN\n",
    "    scaler = preprocessing.MinMaxScaler() \n",
    "    knn = neighbors.KNNClassifier(n_neighbors=5)\n",
    "\n",
    "    scores = []                 # List of tuples with accuracy, precision and recall score on each iteration\n",
    "    v_true = []                 # Append y true sample on each iteration\n",
    "    v_predict = []              # Append y predicted sample on each iteration\n",
    "\n",
    "    skipping = 0\n",
    "    started = False\n",
    "    order_saved = []\n",
    "    X['fault'] = Y\n",
    "\n",
    "    for idx, row in tqdm(X.iterrows()):\n",
    "        x = {k: v for k, v in dict(row).items() if k not in METADATA_COLUMNS_ALL}\n",
    "\n",
    "        x_scaled = scaler.learn_one(x).transform_one(x)\n",
    "        y_true = row['fault']\n",
    "        learning_window.append((x_scaled, y_true))\n",
    "\n",
    "        if started:\n",
    "            # Predict sample after at least one example has been learned\n",
    "            y_predict = knn.predict_one(x_scaled)\n",
    "            v_true.append(y_true)\n",
    "            v_predict.append(y_predict)\n",
    "            order_saved.append(idx)\n",
    "\n",
    "            scores.append([\n",
    "                idx,\n",
    "                skmetrics.accuracy_score(v_true, v_predict),\n",
    "                skmetrics.precision_score(v_true, v_predict, average='micro'),\n",
    "                skmetrics.recall_score(v_true, v_predict, average='micro')\n",
    "            ])\n",
    "\n",
    "        # Provide labels after window length has passed\n",
    "        if len(learning_window) == window_len:\n",
    "            for x, y in learning_window:\n",
    "                # Learn first sample at start of window\n",
    "                if skipping == learn_skip:\n",
    "                    started = True\n",
    "                    knn.learn_one(x, y)\n",
    "                    skipping = 0\n",
    "                else:\n",
    "                    skipping += 1\n",
    "            learning_window = []\n",
    "\n",
    "    if clusters:\n",
    "        return pd.Series(v_predict, index=order_saved)\n",
    "        \n",
    "    return pd.DataFrame(scores, columns=['step', 'accuracy', 'precision', 'recall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: refactor\n",
    "def get_features_list(domains):\n",
    "    features = []\n",
    "    for dname, dataset in domains.items():\n",
    "        names = pd.read_csv(dataset)\n",
    "        names = names.columns.str.extract(r'([a-z]{2})_([a-z\\_\\-]+)')[1].unique()\n",
    "        features.extend([f'{dname}_{col.strip(\"_\")}' for col in names if not pd.isnull(col)])\n",
    "\n",
    "    return features\n",
    "\n",
    "def load_source(dataset: str, domain: str, row: dict):\n",
    "    faults = {\n",
    "        'A': {\n",
    "            'normal': 'normal',\n",
    "            'imbalance': 'imbalance',\n",
    "            'horizontal-misalignment': 'misalignment',\n",
    "            'vertical-misalignment': 'misalignment',\n",
    "            'underhang-outer_race': 'outer race fault',\n",
    "            'underhang-cage_fault': 'cage fault',\n",
    "            'underhang-ball_fault': 'ball fault'\n",
    "        },\n",
    "        'B': {\n",
    "            'normal': 'normal',\n",
    "            'imbalance': 'imbalance',\n",
    "            'horizontal-misalignment': 'misalignment',\n",
    "            'vertical-misalignment': 'misalignment',\n",
    "            'overhang-cage_fault': 'cage fault',\n",
    "            'overhang-ball_fault': 'ball fault',\n",
    "            'overhang-outer_race': 'outer race fault'\n",
    "        }\n",
    "    }\n",
    "    placements = {\n",
    "        'A': ['ax', 'ay', 'az'],\n",
    "        'B': ['bx', 'by', 'bz']\n",
    "    }\n",
    "\n",
    "    RPM = 2500\n",
    "    RPM_RANGE = 500\n",
    "    features = pd.read_csv(dataset).fillna(0)\n",
    "\n",
    "    # Choosing rpm range\n",
    "    if row['rpm_limit']:\n",
    "        features = features[features['rpm'].between(RPM - RPM_RANGE, RPM + RPM_RANGE, inclusive='both')]\n",
    "\n",
    "    # Labeling anomaly severity levels\n",
    "    target = re.search(r'([a-z]+)_?(\\d+)?', row['target'])\n",
    "    anomaly_severity = target.group(2) or '60'\n",
    "    anomaly_severity = float(anomaly_severity) / 100\n",
    "\n",
    "    # Choose measurement placement: A or B\n",
    "    place = row['placement']\n",
    "    axis = placements[place]\n",
    "    features = features[features['fault'].isin(tuple(faults[place]))]\n",
    "    features = models.fault_labeling(features, faults[place], anomaly_severity)\n",
    "\n",
    "    columns = features.columns.str.startswith(tuple(axis))\n",
    "    X = features[features.columns[columns]]\n",
    "\n",
    "    # Select predicted variable column\n",
    "    label = target.group(1)\n",
    "    Y = features[label].astype('category')\n",
    "\n",
    "    # Filter columns in feature domain with window size 2**14\n",
    "    if domain == 'spectral':\n",
    "        window_size = 2**14\n",
    "        X = X.loc[:,X.columns.str.endswith(f'_{window_size}')]\n",
    "        X.columns = X.columns.str.extract(r'(\\w+)_\\w+$')[0]\n",
    "\n",
    "    # Calculate feature magnitudes from 3D vector\n",
    "    feature_names = get_features_list({domain: dataset})\n",
    "    result = pd.DataFrame()\n",
    "    for name in feature_names:              \n",
    "        # Remove prefix: temporal, spectral\n",
    "        name = re.search(r'[a-z]+_([\\w\\_]+)', name).group(1)\n",
    "        vector_dims = [f'{dim}_{name}' for dim in axis]\n",
    "        result[name] = X[vector_dims].apply(np.linalg.norm, axis=1)\n",
    "    X = result\n",
    "\n",
    "    # Batch / Online hold-out (balance and event sequencing)\n",
    "    train_size = 0.8\n",
    "\n",
    "    # Shuffle order within severity level and order event with increasing severity\n",
    "    groups = [\n",
    "        df.sample(frac=1, random_state=10)\n",
    "        for i, df in (\n",
    "            features.sort_values(by='severity_level').groupby('severity_level')\n",
    "        )\n",
    "    ]\n",
    "    rows = list(pd.concat(groups).index)\n",
    "    \n",
    "    X = X.loc[rows].reset_index(drop=True)\n",
    "    Y = Y.loc[rows].reset_index(drop=True)\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, train_size=train_size, random_state=10\n",
    "    )  \n",
    "    X_train, X_test, Y_train, Y_test = (\n",
    "        X_train.sort_index(), X_test.sort_index(),\n",
    "        Y_train.sort_index(), Y_test.sort_index()\n",
    "    )\n",
    "\n",
    "    serevity_groups = pd.concat(groups)['severity_level'].reset_index(drop=True).sort_index()\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.plot(np.arange(0, len(X_train)), serevity_groups.loc[X_train.index], color='red')\n",
    "    ax.set_xlabel('Observations')\n",
    "    ax.set_ylabel('Severity level')\n",
    "    ax.grid()\n",
    "    plt.show()\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test   # WARNING: order matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {'temporal': TD_FEATURES, 'spectral': FD_FEATURES}\n",
    "config = {'rpm_limit': False, 'placement': 'A', 'domain': DOMAIN, 'target': 'fault'}\n",
    "XStream_fault, YStream_fault, _, YF1 = load_source(dataset[DOMAIN], config['domain'], config)\n",
    "config = {'rpm_limit': False, 'placement': 'A', 'domain': DOMAIN, 'target': 'anomaly'}\n",
    "XStream_anomaly, YStream_anomaly, _, YA1 = load_source(dataset[DOMAIN], config['domain'], config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evolution of faults and anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = discovery.plot_label_occurences(YStream_fault)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = discovery.plot_label_occurences(YStream_anomaly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discovery.plot_label_occurences(YF1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discovery.plot_label_occurences(YA1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradual learning\n",
    "- 6 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = knn_online_learn(XStream_fault, YStream_fault, label='fault', window_len=1)\n",
    "ax = results[['accuracy']].plot(\n",
    "    grid=True, legend=False, figsize=(8, 4),\n",
    "    xlabel='Sample', ylabel='Accuracy', title='Fault classes: 6, Window size: 1'\n",
    ")\n",
    "best = results.tail(1)\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradual learning\n",
    "- Binary classifier - anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = knn_online_learn(XStream_anomaly, YStream_anomaly, label='anomaly_90', window_len=1)\n",
    "ax = results[['accuracy']].plot(\n",
    "    grid=True, legend=False, figsize=(8, 4),\n",
    "    xlabel='Sample', ylabel='Accuracy', title='Fault classes: 1, Window size: 1'\n",
    ")\n",
    "best = results.tail(1)\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Window learning\n",
    "- Compare classification accuracies for window sizes in one graph: (1, 10, 50, 100, 250)\n",
    "- Scenarios: fault, anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_window_lengths = (1, 10, 50, 100, 250)\n",
    "\n",
    "fault_evolution = pd.DataFrame()\n",
    "for n in tqdm(learning_window_lengths):\n",
    "    results = knn_online_learn(XStream_fault, YStream_fault, label='fault', window_len=n)\n",
    "    accuracy = results['accuracy']\n",
    "    accuracy.index += n             # Starts learning after at least one window has been filled\n",
    "    fault_evolution[str(n)] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = fault_evolution.fillna(0).plot(\n",
    "    grid=True, legend=True, figsize=(8, 4),\n",
    "    xlabel='Sample', ylabel='Accuracy', title='Faults: Label with delay'\n",
    ")\n",
    "fault_evolution.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_evolution = pd.DataFrame()\n",
    "for n in tqdm(learning_window_lengths):\n",
    "    results = knn_online_learn(XStream_anomaly, YStream_anomaly, label='anomaly_90', window_len=n)\n",
    "    accuracy = results['accuracy']\n",
    "    accuracy.index += n             # Starts learning after at least one window has been filled\n",
    "    anomaly_evolution[str(n)] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = anomaly_evolution.fillna(0).plot(\n",
    "    grid=True, legend=True, figsize=(8, 4),\n",
    "    xlabel='Sample', ylabel='Accuracy', title='Anomaly: Label with delay'\n",
    ")\n",
    "anomaly_evolution.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing labels - Faults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_len = 10\n",
    "labels_skips = (0, 5, 15, 25, 50, 100)\n",
    "\n",
    "fault_skip_evolution = pd.DataFrame()\n",
    "for s in tqdm(labels_skips):\n",
    "    results = knn_online_learn(XStream_fault, YStream_fault, label='fault', window_len=window_len, learn_skip=s)\n",
    "    accuracy = results['accuracy']\n",
    "    accuracy.index += len(XStream_fault) - len(accuracy)\n",
    "    fault_skip_evolution[str(s)] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = fault_skip_evolution.fillna(0).plot(\n",
    "    grid=True, legend=True, figsize=(8, 4),\n",
    "    xlabel='Sample', ylabel='Accuracy', title=f'Faults (4 classes): Skip labels (out of {len(XStream_fault)} total), Window: {window_len}'\n",
    ")\n",
    "fault_skip_evolution.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing labels - Anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_skip_evolution = pd.DataFrame()\n",
    "for s in tqdm(labels_skips):\n",
    "    results = knn_online_learn(XStream_anomaly, YStream_anomaly, label='anomaly_90', window_len=window_len, learn_skip=s)\n",
    "    accuracy = results['accuracy']\n",
    "    accuracy.index += len(XStream_anomaly) - len(accuracy)\n",
    "    anomaly_skip_evolution[str(s)] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = anomaly_skip_evolution.fillna(0).plot(\n",
    "    grid=True, legend=True, figsize=(8, 4),\n",
    "    xlabel='Sample', ylabel='Accuracy', title=f'Anomaly: Skip labels (out of {len(XStream_anomaly)} total), Window: {window_len}'\n",
    ")\n",
    "anomaly_skip_evolution.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatter plot - True labels vs. Predicted labels\n",
    "- Faults\n",
    "- Anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_classifier_map_plot(\n",
    "    filter_out_metadata_columns(XStream_fault.reset_index(drop=True)),\n",
    "    YStream_fault.reset_index(drop=True),\n",
    "    knn_online_learn(XStream_fault.reset_index(drop=True), YStream_fault.reset_index(drop=True), label='fault', window_len=1, learn_skip=0, clusters=True)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def knn_model_setup(n):\n",
    "    engine = neighbors.SWINN(\n",
    "        dist_func=functools.partial(utils.math.minkowski_distance, p=2),\n",
    "        seed=10\n",
    "    )\n",
    "    model = (\n",
    "        preprocessing.MinMaxScaler() |\n",
    "        neighbors.KNNClassifier(n_neighbors=n, engine=engine)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def knn_accuracy_with_delays(X, y, delays):\n",
    "    knn = knn_model_setup(5)\n",
    "\n",
    "    evolution = defaultdict(dict)\n",
    "    for delay in delays:\n",
    "        steps = evaluate.iter_progressive_val_score(\n",
    "            model=knn,\n",
    "            dataset=stream.iter_pandas(X, y),\n",
    "            metric=metrics.Accuracy(),\n",
    "            step=100,\n",
    "            delay=delay\n",
    "        )\n",
    "        for step in steps:\n",
    "            step_num = step['Step']\n",
    "            evolution[step_num]['Observation'] = step_num\n",
    "            evolution[step_num][delay] = step['Accuracy'].get()\n",
    "\n",
    "    evolution = (\n",
    "        pd.DataFrame\n",
    "        .from_records(list(evolution.values()))\n",
    "        .set_index('Observation')\n",
    "    )\n",
    "    evolution.plot(\n",
    "        grid=True, figsize=(15, 4), \n",
    "        marker='.', ylabel='Accuracy', \n",
    "        title='Accuracy with different delays'\n",
    "    )\n",
    "    return evolution\n",
    "\n",
    "\n",
    "def knn_conf_matrix_plot(X, y):\n",
    "    knn = knn_model_setup(5)\n",
    "    #confmatrix = metrics.ConfusionMatrix()\n",
    "    y_predictions = []\n",
    "\n",
    "    for x, y_true in stream.iter_pandas(X, y):\n",
    "        y_predict = knn.predict_one(x) or 0\n",
    "        knn.learn_one(x, y_true)\n",
    "        y_predictions.append(y_predict)\n",
    "        # confmatrix.update(y_true, y_predict)\n",
    "\n",
    "    cm = skmetrics.confusion_matrix(y, y_predictions)\n",
    "    ax = sb.heatmap(cm, cbar=True, cmap='BuGn', annot=True, fmt='d')\n",
    "    ax.set(xlabel='Prediction', ylabel='Truth')\n",
    "\n",
    "\n",
    "def knn_visualize_classes(X, y):\n",
    "    knn = knn_model_setup(5)\n",
    "\n",
    "    y_predictions = []\n",
    "    for xs, ys in stream.iter_pandas(X, y):\n",
    "        y_predict = knn.predict_one(xs)\n",
    "        knn.learn_one(xs, ys)\n",
    "        y_predictions.append(y_predict)\n",
    "\n",
    "    y_predictions = pd.Series(y_predictions)\n",
    "    mismatch = models.project_classifier_map_plot(X, y, y_predictions)\n",
    "    print(f'Error rate: {100 * (len(mismatch) / len(y)):.2f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN classifier (Faults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = XStream_fault.loc[:,XStream_fault.columns != 'fault'], YStream_fault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evolution = knn_accuracy_with_delays(X, y, (1, 50, 100, 250))\n",
    "plt.show()\n",
    "evolution.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evolution[evolution[2] > 0.5] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification report (Faults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate.progressive_val_score(\n",
    "    model=knn_model_setup(5),\n",
    "    dataset=stream.iter_pandas(X, y),\n",
    "    metric=metrics.ClassificationReport()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix (Faults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_conf_matrix_plot(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize clusters of nearest neighbors (Faults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaled = X.reset_index(drop=True)\n",
    "y_scaled = y.reset_index(drop=True)\n",
    "x_scaled[x_scaled.columns] = MinMaxScaler().fit_transform(x_scaled)\n",
    "knn_visualize_classes(x_scaled, y_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN classifier (Anomaly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = XStream_anomaly.loc[:,XStream_fault.columns != 'fault'], YStream_anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_accuracy_with_delays(X, y, (1, 50, 100, 250))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification report (Anomaly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate.progressive_val_score(\n",
    "    model=knn_model_setup(5),\n",
    "    dataset=stream.iter_pandas(X, y),\n",
    "    metric=metrics.ClassificationReport()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix (Anomaly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_conf_matrix_plot(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize clusters of nearest neighbors (Anomaly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaled = X.reset_index(drop=True)\n",
    "y_scaled = y.reset_index(drop=True)\n",
    "x_scaled[x_scaled.columns] = MinMaxScaler().fit_transform(x_scaled)\n",
    "knn_visualize_classes(x_scaled, y_scaled)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

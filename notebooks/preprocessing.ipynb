{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from zipfile import ZipFile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "import mafaulda\n",
    "import extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRACT = False\n",
    "PATH = '../datasets'\n",
    "FEATURES_PATH = os.path.join(PATH, 'features')\n",
    "DATASET_PATH = os.path.join(PATH, 'MAFAULDA.zip')\n",
    "LABELED_DATASET_PATH = os.path.join(FEATURES_PATH, 'MAFAULDA_LABEL.csv')\n",
    "FEATURES = {\n",
    "    'TD': os.path.join(FEATURES_PATH, 'MAFAULDA_TD.csv'),\n",
    "    'FD': os.path.join(FEATURES_PATH, 'MAFAULDA_FD.csv'),\n",
    "}\n",
    "PARTS = 1\n",
    "FFT_WINDOW = 2**15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_time_domain(dataset: ZipFile, filename: str, parts: int = PARTS) -> pd.DataFrame:\n",
    "    return mafaulda.features_by_domain(extraction.time_features_calc, dataset, filename, parts=parts)\n",
    "\n",
    "\n",
    "def features_frequency_domain(dataset: ZipFile, filename: str, parts: int = PARTS) -> pd.DataFrame:\n",
    "    return mafaulda.features_by_domain(extraction.frequency_features_calc, dataset, filename, window=FFT_WINDOW, parts=parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXTRACT is True:\n",
    "    features = extraction.load_files_split(ZipFile(DATASET_PATH), features_time_domain)\n",
    "    features.to_csv(FEATURES['TD'], index=False)\n",
    "else:\n",
    "    features = pd.read_csv(FEATURES['TD'])\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXTRACT is True:\n",
    "    features = extraction.load_files_split(ZipFile(DATASET_PATH), features_frequency_domain)\n",
    "    features.to_csv(FEATURES['FD'], index=False)\n",
    "else:\n",
    "    features = pd.read_csv(FEATURES['FD'])\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display example severities\n",
    "df = extraction.load_features(FEATURES['TD'], mafaulda.BEARING_A_COLUMNS, mafaulda.LABEL_COLUMNS) \n",
    "df = mafaulda.label_severity(df, 'A', 0.5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate different feature sets\n",
    "datasets = []\n",
    "domains = ('TD', 'FD')\n",
    "dimensions = (1, 3)\n",
    "columns = {\n",
    "    'A': {\n",
    "        1: ['ay'],\n",
    "        3: mafaulda.BEARING_A_COLUMNS\n",
    "    },\n",
    "    'B': {\n",
    "        1: ['by'],\n",
    "        3: mafaulda.BEARING_B_COLUMNS\n",
    "    }\n",
    "}\n",
    "\n",
    "for domain in domains:\n",
    "    for dim in dimensions:\n",
    "        a = extraction.load_features(FEATURES[domain], columns['A'][dim], mafaulda.LABEL_COLUMNS) \n",
    "        a = mafaulda.assign_labels(a, 'A')\n",
    "        datasets.append({'domain': domain, 'dim': dim, 'bearing': 'A', 'severity': False, 'data': a})\n",
    "\n",
    "        b = extraction.load_features(FEATURES[domain], columns['B'][dim], mafaulda.LABEL_COLUMNS) \n",
    "        b = mafaulda.assign_labels(b, 'B')\n",
    "        datasets.append({'domain': domain, 'dim': dim, 'bearing': 'B', 'severity': False, 'data': b})\n",
    "\n",
    "        ab = pd.concat([a, b]).reset_index(drop=True)\n",
    "        datasets.append({'domain': domain, 'dim': dim, 'bearing': 'A+B', 'severity': False, 'data': ab})\n",
    "\n",
    "        a = extraction.load_features(FEATURES[domain], columns['A'][dim], mafaulda.LABEL_COLUMNS) \n",
    "        a = mafaulda.label_severity(a, 'A', 0.5)\n",
    "        datasets.append({'domain': domain, 'dim': dim, 'bearing': 'A', 'severity': True, 'data': a})\n",
    "\n",
    "        b = extraction.load_features(FEATURES[domain], columns['B'][dim], mafaulda.LABEL_COLUMNS) \n",
    "        b = mafaulda.label_severity(b, 'B', 0.5)\n",
    "        datasets.append({'domain': domain, 'dim': dim, 'bearing': 'B', 'severity': True, 'data': b})\n",
    "\n",
    "        ab = pd.concat([a, b]).reset_index(drop=True)\n",
    "        datasets.append({'domain': domain, 'dim': dim, 'bearing': 'A+B', 'severity': True, 'data': ab})\n",
    "\n",
    "\n",
    "datasets_domains = pd.DataFrame.from_records(datasets)\n",
    "\n",
    "# Join columns of features in time and frequency domain\n",
    "for name, group in datasets_domains.groupby(by=['dim', 'bearing', 'severity']):\n",
    "    dim, bearing, severity = name\n",
    "    frames_by_domain = [\n",
    "        df.drop(columns=['label']).reset_index(drop=True)\n",
    "        for df in group['data'].values\n",
    "    ]\n",
    "    df = pd.concat(frames_by_domain, axis=1)\n",
    "    df['label'] = group['data'].values[0]['label']\n",
    "    datasets.append({'domain': 'TD+FD', 'dim': dim, 'bearing': bearing, 'severity': severity, 'data': df})\n",
    "\n",
    "\n",
    "datasets = pd.DataFrame.from_records(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zisti počty jednotlivých tried - ovplyvnené cez severity a bearing\n",
    "# domain ovplyvnuje počet stĺpcov, dim - iba z koľkých pôvodných stĺpcov\n",
    "# Riadok - bearings, severity\n",
    "# Stĺpce - počet z každej class\n",
    "label_counts = []\n",
    "for name, group in datasets_domains.groupby(by=['severity', 'bearing']):\n",
    "    severity, bearing = name\n",
    "    df = group['data'].values[0]\n",
    "    scenario = {'bearing': bearing, 'severity': severity}\n",
    "    counts = df['label'].value_counts().to_dict()\n",
    "    counts['sum'] = sum(counts.values())\n",
    "    scenario.update(counts)\n",
    "    label_counts.append(scenario)\n",
    "\n",
    "pd.DataFrame.from_records(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range of values in features\n",
    "for name, group in datasets_domains.groupby(by=['domain', 'dim', 'bearing']):\n",
    "    df = group['data'].values[0].drop(columns=['label'])\n",
    "\n",
    "    fig, ax = plt.subplots(1, len(df.columns), figsize=(20, 4))\n",
    "    print(name)\n",
    "    for i, col in enumerate(df):\n",
    "        df.boxplot([col], ax=ax[i])\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range of values in features - Power transform\n",
    "for name, group in datasets_domains.groupby(by=['domain', 'dim', 'bearing']):\n",
    "    df = group['data'].values[0].drop(columns=['label'])\n",
    "\n",
    "    pt = PowerTransformer(method='yeo-johnson', standardize=True)\n",
    "    df[df.columns] = pt.fit_transform(df)\n",
    "\n",
    "    fig, ax = plt.subplots(1, len(df.columns), figsize=(20, 4))\n",
    "    print(name)\n",
    "    for i, col in enumerate(df):\n",
    "        df.boxplot([col], ax=ax[i])\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# Features EDA - corr to rpm, \n",
    "\n",
    "# EDA of signals later - prepare functions\n",
    "\n",
    "# PCA EDA of features\n",
    "\n",
    "# Apply power transform (next column of data column)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

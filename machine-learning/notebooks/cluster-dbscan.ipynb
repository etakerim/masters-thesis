{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from tqdm.notebook import tqdm\n",
    "from kneed import KneeLocator\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from vibrodiagnostics import mafaulda, visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot distances among points\n",
    "- https://stats.stackexchange.com/questions/88872/a-routine-to-choose-eps-and-minpts-for-dbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_points_distances(df: pd.DataFrame, n_neighbors: int) -> list: \n",
    "    neighbors = NearestNeighbors(n_neighbors=n_neighbors)\n",
    "    neighbors.fit(df)\n",
    "    distances, indices = neighbors.kneighbors(df)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    distance_desc = sorted(distances[:, 1], reverse=True)\n",
    "    ax.plot(list(range(1, len(distance_desc) + 1)), distance_desc)\n",
    "    ax.set_xlabel('Number of points')\n",
    "    ax.set_ylabel('Distance')\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return distance_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Range of values is MinMaxScaled in range (0, 1) - eps must be smaller than 1\n",
    "- Noisy samples are given the label -1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time domain features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {'placement': 'A', 'online': False}\n",
    "X_train, X_test, y_train, y_test = mafaulda.load_source('TD', CONFIG)\n",
    "\n",
    "distance_desc = plot_points_distances(X_train, 6)\n",
    "kneedle = KneeLocator(range(1, len(distance_desc) + 1), distance_desc,\n",
    "                      S=1.0, curve='convex', direction='decreasing')\n",
    "kneedle.plot_knee_normalized()\n",
    "print(kneedle.elbow, kneedle.knee_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsel = ['shape', 'rms', 'clearance']\n",
    "X_train = X_train[fsel]\n",
    "X_test = X_test[fsel]\n",
    "\n",
    "visualize.cross_cuts_3d_cluster(X_train, y_train, 'Ground truth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = DBSCAN(eps=kneedle.knee_y, min_samples=5, metric='l2')\n",
    "clustering.fit(X_train)\n",
    "y_train_labels = clustering.labels_\n",
    "y_predict = clustering.fit_predict(X_test)\n",
    "\n",
    "visualize.cross_cuts_3d_cluster(X_train, y_train_labels, 'Clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clustering(X_train, y_train_labels, X_test, y_predict):\n",
    "    # The Silhouette Coefficient is calculated using the mean intra-cluster distance (a) and the mean nearest-cluster distance (b) for each sample.\n",
    "    # The best value is 1 and the worst value is -1. Values near 0 indicate overlapping clusters\n",
    "    print('Silhouette score:')\n",
    "    print('Train:', silhouette_score(X_train, y_train_labels, metric='euclidean'))\n",
    "    print('Test:', silhouette_score(X_test, y_predict, metric='euclidean'))\n",
    "\n",
    "    # Daviesâ€“Bouldin index: The minimum score is zero, with lower values indicating better clustering.\n",
    "    print('Davies-Bouldin index')\n",
    "    print('Train:', davies_bouldin_score(X_train, y_train_labels))\n",
    "    print('Test:', davies_bouldin_score(X_test, y_predict))\n",
    "\n",
    "    occurences = pd.DataFrame(\n",
    "        data=contingency_matrix(y_train, y_train_labels),\n",
    "        index=np.unique(y_train),\n",
    "        columns=np.unique(y_train_labels)\n",
    "    )\n",
    "    ax = sb.heatmap(occurences, cbar=True, cmap='BuGn', annot=True, fmt='d')\n",
    "\n",
    "\n",
    "evaluate_clustering(X_train, y_train_labels, X_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequency domain features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {'placement': 'A', 'online': False}\n",
    "X_train, X_test, y_train, y_test = mafaulda.load_source('FD', CONFIG)\n",
    "\n",
    "distance_desc = plot_points_distances(X_train, 6)\n",
    "kneedle = KneeLocator(range(1, len(distance_desc) + 1), distance_desc,\n",
    "                      S=1.0, curve='convex', direction='decreasing')\n",
    "kneedle.plot_knee_normalized()\n",
    "print(kneedle.elbow, kneedle.knee_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = DBSCAN(eps=kneedle.knee_y, min_samples=15, metric='l2')\n",
    "clustering.fit(X_train)\n",
    "y_train_labels = clustering.labels_\n",
    "y_predict = clustering.fit_predict(X_test)\n",
    "\n",
    "visualize.cross_cuts_3d_cluster(X_train, y_train_labels, 'Clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_clustering(X_train, y_train_labels, X_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find best parameters for DBSCAN in supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_clustering_score(X, y, num_of_features, eps, min_samples):\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "\n",
    "    crossvalid = StratifiedKFold(n_splits=5)\n",
    "\n",
    "    for train_index, test_index in crossvalid.split(X, y):\n",
    "        X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "        X_test, y_test = X.iloc[test_index], y.iloc[test_index]\n",
    "\n",
    "        clustering = DBSCAN(eps=eps, min_samples=int(min_samples), metric='l2')\n",
    "        clustering.fit(X_train)\n",
    "        y_train_labels = clustering.labels_\n",
    "        y_predict = clustering.fit_predict(X_test)\n",
    "\n",
    "        num_of_clusters_train = len(np.unique(y_train_labels))\n",
    "        num_of_clusters_test = len(np.unique(y_predict))\n",
    "        if num_of_clusters_train > 1 and num_of_clusters_test > 1:\n",
    "            train_scores.append(silhouette_score(X_train, y_train_labels, metric='euclidean'))\n",
    "            test_scores.append(silhouette_score(X_test, y_predict, metric='euclidean'))\n",
    "\n",
    "    train_scores = np.array(train_scores)\n",
    "    test_scores = np.array(test_scores)\n",
    "\n",
    "    train_score_mean = np.mean(train_scores)\n",
    "    train_score_std = np.std(train_scores)\n",
    "    test_score_mean = np.mean(test_scores)\n",
    "    test_score_std = np.std(test_scores)\n",
    "\n",
    "    return train_score_mean, train_score_std, test_score_mean, test_score_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {'placement': 'A', 'online': False}\n",
    "X, _, y, _  = mafaulda.load_source('TD', CONFIG)\n",
    "\n",
    "num_of_features = np.arange(1, len(X.columns) + 1)\n",
    "eps = np.linspace(0.05, 0.8, 8)\n",
    "min_samples = np.linspace(3, 8, 2)\n",
    "grid = np.array(np.meshgrid(num_of_features, eps, min_samples)).T.reshape(-1, 3)\n",
    "\n",
    "rows = []\n",
    "for f, e, s in tqdm(grid):\n",
    "    row = [f, e, s]\n",
    "    row.extend(cross_validate_clustering_score(X, y, f, e, s))\n",
    "    rows.append(row)\n",
    "\n",
    "\n",
    "results = pd.DataFrame(rows, columns=[\n",
    "    'eps', 'min_samples', 'clusters', \n",
    "    'train_score_mean', 'train_score_std',\n",
    "    'test_score_mean', 'test_score_std'\n",
    "]).dropna()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 best scored parameters with silhouette score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[results['clusters'] > 1].sort_values(by='train_score_mean', ascending=False).head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

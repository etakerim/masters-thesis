{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from vibrodiagnostics import (\n",
    "    mafaulda, \n",
    "    extraction,\n",
    "    visualize,\n",
    "    models\n",
    ")\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARTS = 1\n",
    "FFT_WINDOW = 2**15\n",
    "EXTRACT = False\n",
    "GENERATE = False\n",
    "POWER_TRANSFORM = False\n",
    "MODEL_TYPE = 'knn'\n",
    "\n",
    "K_NEIGHBORS_OPTIONS = (3, 5, 11)\n",
    "NUM_FEATURES_OPTIONS = (2, 3, 4)\n",
    "\n",
    "PATH = '../datasets'\n",
    "FEATURES_PATH = os.path.join(PATH, 'features')\n",
    "RESULTS_PATH = os.path.join(FEATURES_PATH, 'results.json')\n",
    "BEST_FEATURES_PATH = os.path.join(FEATURES_PATH, 'best_features_accuracy.csv')\n",
    "DATASET_PATH = os.path.join(PATH, 'MAFAULDA.zip')\n",
    "LABELED_DATASET_PATH = os.path.join(FEATURES_PATH, 'MAFAULDA_LABEL.csv')\n",
    "KNN_BRUTE_FORCE_PATH = os.path.join(PATH, 'knn_brute_force_features')\n",
    "FEATURES = {\n",
    "    'TD': os.path.join(FEATURES_PATH, 'MAFAULDA_TD.csv'),\n",
    "    'FD': os.path.join(FEATURES_PATH, 'MAFAULDA_FD.csv'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_time_domain(dataset: ZipFile, filename: str, parts: int = PARTS) -> pd.DataFrame:\n",
    "    return mafaulda.features_by_domain(extraction.time_features_calc, dataset, filename, parts=parts)\n",
    "\n",
    "\n",
    "def features_frequency_domain(dataset: ZipFile, filename: str, parts: int = PARTS) -> pd.DataFrame:\n",
    "    return mafaulda.features_by_domain(extraction.frequency_features_calc, dataset, filename, window=FFT_WINDOW, parts=parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXTRACT is True:\n",
    "    features = extraction.load_files_split(ZipFile(DATASET_PATH), features_time_domain)\n",
    "    features.to_csv(FEATURES['TD'], index=False)\n",
    "else:\n",
    "    features = pd.read_csv(FEATURES['TD'])\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXTRACT is True:\n",
    "    features = extraction.load_files_split(ZipFile(DATASET_PATH), features_frequency_domain)\n",
    "    features.to_csv(FEATURES['FD'], index=False)\n",
    "else:\n",
    "    features = pd.read_csv(FEATURES['FD'])\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display example severities\n",
    "df = extraction.load_features(FEATURES['TD'], mafaulda.BEARING_A_COLUMNS, mafaulda.LABEL_COLUMNS) \n",
    "df = mafaulda.label_severity(df, 'A', 0.5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate different feature sets\n",
    "datasets = []\n",
    "domains = ('TD', 'FD')\n",
    "dimensions = (1, 3)\n",
    "columns = {\n",
    "    'A': {\n",
    "        1: ['ay'],\n",
    "        3: mafaulda.BEARING_A_COLUMNS\n",
    "    },\n",
    "    'B': {\n",
    "        1: ['by'],\n",
    "        3: mafaulda.BEARING_B_COLUMNS\n",
    "    }\n",
    "}\n",
    "\n",
    "for domain in domains:\n",
    "    for dim in dimensions:\n",
    "        a = extraction.load_features(FEATURES[domain], columns['A'][dim], mafaulda.LABEL_COLUMNS) \n",
    "        a = mafaulda.assign_labels(a, 'A')\n",
    "        datasets.append({'domain': domain, 'dim': dim, 'bearing': 'A', 'severity': False, 'data': a})\n",
    "\n",
    "        b = extraction.load_features(FEATURES[domain], columns['B'][dim], mafaulda.LABEL_COLUMNS) \n",
    "        b = mafaulda.assign_labels(b, 'B')\n",
    "        datasets.append({'domain': domain, 'dim': dim, 'bearing': 'B', 'severity': False, 'data': b})\n",
    "\n",
    "        ab = pd.concat([a, b]).reset_index(drop=True)\n",
    "        datasets.append({'domain': domain, 'dim': dim, 'bearing': 'A+B', 'severity': False, 'data': ab})\n",
    "\n",
    "        a = extraction.load_features(FEATURES[domain], columns['A'][dim], mafaulda.LABEL_COLUMNS) \n",
    "        a = mafaulda.label_severity(a, 'A', 0.5)\n",
    "        datasets.append({'domain': domain, 'dim': dim, 'bearing': 'A', 'severity': True, 'data': a})\n",
    "\n",
    "        b = extraction.load_features(FEATURES[domain], columns['B'][dim], mafaulda.LABEL_COLUMNS) \n",
    "        b = mafaulda.label_severity(b, 'B', 0.5)\n",
    "        datasets.append({'domain': domain, 'dim': dim, 'bearing': 'B', 'severity': True, 'data': b})\n",
    "\n",
    "        ab = pd.concat([a, b]).reset_index(drop=True)\n",
    "        datasets.append({'domain': domain, 'dim': dim, 'bearing': 'A+B', 'severity': True, 'data': ab})\n",
    "\n",
    "\n",
    "datasets_domains = pd.DataFrame.from_records(datasets)\n",
    "\n",
    "# Join columns of features in time and frequency domain\n",
    "for name, group in datasets_domains.groupby(by=['dim', 'bearing', 'severity']):\n",
    "    dim, bearing, severity = name\n",
    "    frames_by_domain = [\n",
    "        df.drop(columns=['label']).reset_index(drop=True).add_prefix(f'{domain}-')\n",
    "        for domain, df in zip(group['domain'].to_list(), group['data'].values)\n",
    "    ]\n",
    "    df = pd.concat(frames_by_domain, axis=1)\n",
    "    df['label'] = group['data'].values[0]['label']\n",
    "    datasets.append({'domain': 'TD+FD', 'dim': dim, 'bearing': bearing, 'severity': severity, 'data': df})\n",
    "\n",
    "\n",
    "datasets = pd.DataFrame.from_records(datasets)\n",
    "\n",
    "# TODO: temp\n",
    "# datasets = datasets.iloc[25:]\n",
    "datasets = datasets[datasets['domain'].isin(['TD', 'FD'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zisti počty jednotlivých tried - ovplyvnené cez severity a bearing\n",
    "# domain ovplyvnuje počet stĺpcov, dim - iba z koľkých pôvodných stĺpcov\n",
    "# Riadok - bearings, severity\n",
    "# Stĺpce - počet z každej class\n",
    "label_counts = []\n",
    "for name, group in datasets_domains.groupby(by=['severity', 'bearing']):\n",
    "    severity, bearing = name\n",
    "    df = group['data'].values[0]\n",
    "    scenario = {'bearing': bearing, 'severity': severity}\n",
    "    counts = df['label'].value_counts().to_dict()\n",
    "    counts['sum'] = sum(counts.values())\n",
    "    scenario.update(counts)\n",
    "    label_counts.append(scenario)\n",
    "\n",
    "pd.DataFrame.from_records(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range of values in features\n",
    "for name, group in datasets_domains.groupby(by=['domain', 'dim', 'bearing']):\n",
    "    df = group['data'].values[0].drop(columns=['label'])\n",
    "\n",
    "    fig, ax = plt.subplots(1, len(df.columns), figsize=(20, 4))\n",
    "    print(name)\n",
    "    for i, col in enumerate(df):\n",
    "        df.boxplot([col], ax=ax[i])\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range of values in features - Power transform\n",
    "for name, group in datasets_domains.groupby(by=['domain', 'dim', 'bearing']):\n",
    "    df = group['data'].values[0].drop(columns=['label'])\n",
    "\n",
    "    pt = PowerTransformer(method='yeo-johnson', standardize=True)\n",
    "    df[df.columns] = pt.fit_transform(df)\n",
    "\n",
    "    fig, ax = plt.subplots(1, len(df.columns), figsize=(20, 4))\n",
    "    print(name)\n",
    "    for i, col in enumerate(df):\n",
    "        df.boxplot([col], ax=ax[i])\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All features on each scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "if GENERATE is True:\n",
    "    for index, row in tqdm(datasets.iterrows()):\n",
    "        source = row['data']\n",
    "        y = source['label']\n",
    "        x = source.drop(columns=['label'])\n",
    "        r = models.all_features(\n",
    "            x, y, power_transform=POWER_TRANSFORM\n",
    "        )\n",
    "        r.update({\n",
    "            'domain': row['domain'],\n",
    "            'dim': row['dim'],\n",
    "            'bearing': row['bearing'],\n",
    "            'severity': row['severity']\n",
    "        })\n",
    "        results.append(r)\n",
    "    json.dump(results, open(RESULTS_PATH, 'w'))\n",
    "\n",
    "results = json.load(open(RESULTS_PATH, 'r'))\n",
    "results[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = json.load(open(RESULTS_PATH, 'r'))\n",
    "for row in results:\n",
    "    print(row['domain'], row['dim'], row['bearing'], row['severity'])\n",
    "    visualize.plot_all_knn_simple(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enumerate feature combinations on each scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_filename(row: dict, separator: str = '#'):\n",
    "    parts = [\n",
    "        row['domain'],\n",
    "        row['dim'],\n",
    "        row['bearing'],\n",
    "        row['severity'],\n",
    "        POWER_TRANSFORM\n",
    "    ]\n",
    "    filename = separator.join([str(p) for p in parts])\n",
    "    return filename\n",
    "\n",
    "results = []\n",
    "Path(KNN_BRUTE_FORCE_PATH).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if GENERATE is True:\n",
    "    for index, row in tqdm(datasets.iterrows()):\n",
    "        source = row['data']\n",
    "        y = source['label']\n",
    "        x = source.drop(columns=['label'])\n",
    "\n",
    "        result = models.enumerate_models(\n",
    "            x, y, row['domain'],\n",
    "            power_transform=POWER_TRANSFORM,\n",
    "            k_neighbors=K_NEIGHBORS_OPTIONS,\n",
    "            num_of_features=NUM_FEATURES_OPTIONS\n",
    "        )\n",
    "        filename = make_filename(row)\n",
    "        filename = os.path.join(KNN_BRUTE_FORCE_PATH, filename)\n",
    "        result.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(KNN_BRUTE_FORCE_PATH):\n",
    "    if not os.path.isfile(os.path.join(KNN_BRUTE_FORCE_PATH, filename)):\n",
    "        continue\n",
    "    models_summary = pd.read_csv(os.path.join(KNN_BRUTE_FORCE_PATH, filename))\n",
    "    print(filename)\n",
    "    visualize.boxplot_enumerate_models_accuracy(models_summary, 'test', 'f', 'k')\n",
    "    visualize.boxplot_enumerate_models_accuracy(models_summary, 'test', 'k', 'f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bar chart for specfic number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE is True:\n",
    "    results = []\n",
    "    for index, row in tqdm(datasets.iterrows()):\n",
    "        source = row['data']\n",
    "        y = source['label']\n",
    "        x = source.drop(columns=['label'])\n",
    "        filename = make_filename(row)\n",
    "        models_summary = pd.read_csv(os.path.join(KNN_BRUTE_FORCE_PATH, filename))\n",
    "\n",
    "        for fnum in NUM_FEATURES_OPTIONS:\n",
    "            for k in K_NEIGHBORS_OPTIONS:\n",
    "                result = models.feature_selection_accuracies(\n",
    "                    x, y, \n",
    "                    row['domain'],\n",
    "                    models_summary,\n",
    "                    k_neighbors=k,\n",
    "                    number_of_features=fnum, \n",
    "                    power_transform=POWER_TRANSFORM\n",
    "                )\n",
    "                for r in result:\n",
    "                    r.update({\n",
    "                        'dim': row['dim'],\n",
    "                        'bearing': row['bearing'],\n",
    "                        'severity': row['severity'],\n",
    "                        'k': k,\n",
    "                        'f': fnum\n",
    "                    })\n",
    "                results.extend(result)\n",
    "    \n",
    "    results = pd.DataFrame.from_records(results)\n",
    "    results.to_csv(BEST_FEATURES_PATH, index=False)\n",
    "else:\n",
    "    results = pd.read_csv(BEST_FEATURES_PATH)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in results.groupby(by=['dim', 'bearing', 'severity', 'domain', 'k', 'f']):\n",
    "    print(name)\n",
    "    visualize.plot_models_performance_bar(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy and percentile of feature selection methods to number of features\n",
    "- The best features don't have always 100 percentile. The best subset is taken after sorting training set and distribution of accuracies is from validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in results.groupby(by=['dim', 'bearing', 'severity', 'domain', 'k']):\n",
    "    print(name)\n",
    "    (group[['f', 'set', 'test_accuracy']]\n",
    "     .pivot(index='f', columns='set', values='test_accuracy')\n",
    "     .plot(figsize=(8, 5), marker='o', grid=True, xlabel='Number of features', ylabel='Accuracy'))\n",
    "    plt.xticks(NUM_FEATURES_OPTIONS)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in results.groupby(by=['dim', 'bearing', 'severity', 'domain', 'k']):\n",
    "    print(name)\n",
    "    (group[['f', 'set', 'test_percentile']]\n",
    "     .pivot(index='f', columns='set', values='test_percentile')\n",
    "     .plot(figsize=(8, 5), marker='o', grid=True, xlabel='Number of features', ylabel='Percentile'))\n",
    "    plt.xticks(NUM_FEATURES_OPTIONS)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy and percentile of feature selection methods to number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in results.groupby(by=['dim', 'bearing', 'severity', 'domain', 'f']):\n",
    "    print(name)\n",
    "    (group[['k', 'set', 'test_accuracy']]\n",
    "     .pivot(index='k', columns='set', values='test_accuracy')\n",
    "     .plot(figsize=(8, 6), marker='o', grid=True, xlabel='k-Neighbors', ylabel='Accuracy'))\n",
    "    plt.xticks(K_NEIGHBORS_OPTIONS)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in results.groupby(by=['dim', 'bearing', 'severity', 'domain', 'f']):\n",
    "    print(name)\n",
    "    (group[['k', 'set', 'test_percentile']]\n",
    "     .pivot(index='k', columns='set', values='test_percentile')\n",
    "     .plot(figsize=(8, 6), marker='o', grid=True, label='k-Neighbors', ylabel='Percentile'))\n",
    "    plt.xticks(K_NEIGHBORS_OPTIONS)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In how many cases is rank product best among all the selection methods?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_wins_of_methods(datasets, results, methods):\n",
    "    columns = list(set(datasets.columns) - {'data'}) + ['k', 'f']\n",
    "    counts = dict(zip(methods + ['total'], np.zeros(len(methods)+1)))\n",
    "    percentiles = dict(zip(methods, [[] for _ in range(len(methods))]))\n",
    "    \n",
    "    for name, group in results.groupby(by=columns):\n",
    "        counts['total'] += 1\n",
    "        row = (\n",
    "            group[group['set'].isin(methods)]\n",
    "            .sort_values(by='test_percentile', ascending=False)\n",
    "            .head(1)\n",
    "        )\n",
    "        key = row.head(1)['set'].values[0]\n",
    "        percentile = row.head(1)['test_percentile'].values[0]\n",
    "\n",
    "        percentiles[key].append(percentile)\n",
    "        counts[key] += 1\n",
    "        \n",
    "    percentiles = {k: np.mean(v or [0]) for k, v in percentiles.items()}\n",
    "    percentiles = pd.DataFrame.from_dict(percentiles, orient='index', columns=['score'])\n",
    "        \n",
    "    counts = pd.DataFrame.from_dict(counts, orient='index', columns=['count'])\n",
    "    counts['percentage'] = 100 * (counts['count'] / counts[counts.index == 'total'].values[0])\n",
    "    counts = counts.join(percentiles)\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = list(set(results['set'].unique()) - {'PCA PC', 'All features', 'Best features'})\n",
    "count_wins_of_methods(datasets, results, methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = list(set(results['set'].unique()) - {'All features', 'Best features'})\n",
    "count_wins_of_methods(datasets, results, methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = list(set(results['set'].unique()) - {'Best features'})\n",
    "count_wins_of_methods(datasets, results, methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram of model accuracy distribution and vertical line for individual feature selection methods\n",
    "- dim=3, bearing=A, severity=False, k=5, f=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cycler import cycler\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(15, 8))\n",
    "for i, domain in enumerate(FEATURES):\n",
    "    row = {\n",
    "        'domain': domain,\n",
    "        'dim': 3,\n",
    "        'bearing': 'A',\n",
    "        'severity': False\n",
    "    }\n",
    "    filename = make_filename(row)\n",
    "    distribution = pd.read_csv(os.path.join(KNN_BRUTE_FORCE_PATH, filename))\n",
    "    mselection = results[\n",
    "        (results['domain'] == row['domain']) &\n",
    "        (results['dim'] == row['dim']) &\n",
    "        (results['bearing'] == row['bearing']) &\n",
    "        (results['severity'] == row['severity']) &\n",
    "        (results['k'] == 5) &\n",
    "        (results['f'] == 3)\n",
    "    ]\n",
    "    params = dict(\n",
    "        grid=True,\n",
    "        bins=50,\n",
    "        edgecolor='black',\n",
    "        linewidth=0.5,\n",
    "        color='gray',\n",
    "        range=(0.5, 1)\n",
    "    )\n",
    "    colors = ['r', 'g', 'b', 'c', 'm', 'y', 'k']\n",
    "\n",
    "    params['ax'] = ax[0][i]\n",
    "    params['ax'].set_xlabel('Accuracy')\n",
    "    params['ax'].set_ylabel('Number of k-NN models')\n",
    "    params['ax'].set_title(visualize.DOMAIN_TITLES[domain] + ', Training set')\n",
    "    distribution['train'].hist(**params)\n",
    "\n",
    "    sel = mselection.set_index('set').to_dict()['train_accuracy']\n",
    "    color_cycle = cycler(color=colors)\n",
    "    for c, (k, v) in zip(color_cycle, sel.items()):\n",
    "        params['ax'].axvline(v, linestyle='--', lw=2, label=k, **c) \n",
    "    params['ax'].legend()\n",
    "\n",
    "    params['ax'] = ax[1][i]\n",
    "    params['ax'].set_xlabel('Accuracy')\n",
    "    params['ax'].set_ylabel('Number of k-NN models')\n",
    "    params['ax'].set_title(visualize.DOMAIN_TITLES[domain] + ', Testing set')\n",
    "    distribution['test'].hist(**params)\n",
    "\n",
    "    sel = mselection.set_index('set').to_dict()['test_accuracy']\n",
    "    color_cycle = cycler(color=colors)\n",
    "    for c, (k, v) in zip(color_cycle, sel.items()):\n",
    "        params['ax'].axvline(v, linestyle='--', lw=2, label=k, **c) \n",
    "    params['ax'].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: same experiments for online models (4 experiments) - Po\n",
    "# TODO: check if fsel is done on train set - best set is broken!\n",
    "\n",
    "# TODO: Features EDA - corr to rpm, histograms per machine, time waveform, frequency spectra, time-frequency waveform, features in feature space\n",
    "# TODO: EDA of compressors\n",
    "\n",
    "# .................... Writing - St"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

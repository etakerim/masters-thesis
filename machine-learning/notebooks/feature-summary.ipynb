{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "from typing import List, Set, Tuple, Dict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gmean\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from enum import Enum, auto\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from vibrodiagnostics import mafaulda, visualize, ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments(conditions: List[dict], exp_output: ranking.ExperimentOutput, pc=3) -> pd.DataFrame:\n",
    "    experiments = []\n",
    "    domains = ('TD', 'FD')\n",
    "\n",
    "    for row in tqdm(conditions):\n",
    "        experiment = row.copy()\n",
    "\n",
    "        for domain_label in domains:\n",
    "            X_train, X_test, Y_train, Y_test = mafaulda.load_source(domain_label, row)\n",
    "\n",
    "            if exp_output == ranking.ExperimentOutput.COUNTS:\n",
    "                experiment.update({'n_train': len(X_train), 'n_test': len(X_test), 'sum': len(X)})\n",
    "                break\n",
    "\n",
    "            elif exp_output == ranking.ExperimentOutput.PCA:\n",
    "                experiment = row.copy()\n",
    "                experiment.update({'domain': domain_label})\n",
    "                experiment.update(ranking.pca_explained_variances(X_train, pc))\n",
    "                experiments.append(experiment)\n",
    "                continue\n",
    "\n",
    "            elif exp_output == ranking.ExperimentOutput.SILHOUETTE:\n",
    "                synonyms = ranking.compute_correlations(X_train, corr_above=0.95)\n",
    "                if row['online']:\n",
    "                    ranks = ranking.online_feature_ranking(X_train, Y_train)\n",
    "                else:\n",
    "                    ranks = ranking.batch_feature_ranking(X_train, Y_train)\n",
    "    \n",
    "                best_features = ranking.best_columns(ranks, synonyms, n=3)\n",
    "                scores = ranking.silhouette_scores(X_train, X_test, Y_train, Y_test, best_features, pc)\n",
    "                experiment = row.copy()\n",
    "                experiment.update({'domain': domain_label})\n",
    "                experiment.update(scores)\n",
    "                experiments.append(experiment)\n",
    "                continue\n",
    "\n",
    "            elif exp_output == ranking.ExperimentOutput.BEST_SET:\n",
    "                if row['online']:\n",
    "                    ranks = ranking.online_feature_ranking(X_train, Y_train)\n",
    "                else:\n",
    "                    ranks = ranking.batch_feature_ranking(X_train, Y_train)\n",
    "                synonyms = ranking.compute_correlations(X_train, corr_above=0.95)\n",
    "                subset = ranking.best_subset(ranks, synonyms, n=3)\n",
    "                output = subset\n",
    "\n",
    "            elif exp_output == ranking.ExperimentOutput.BEST_CORR:\n",
    "                if row['online']:\n",
    "                    ranks = ranking.online_feature_ranking(X_train, Y_train, 'corr')\n",
    "                else:\n",
    "                    ranks = ranking.batch_feature_ranking(X_train, Y_train, 'corr')\n",
    "                synonyms = ranking.compute_correlations(X_train, corr_above=0.95)\n",
    "                subset = ranking.best_subset(ranks, synonyms, n=3)\n",
    "                output = subset\n",
    "\n",
    "            elif exp_output == ranking.ExperimentOutput.BEST_F_STAT:\n",
    "                if row['online']:\n",
    "                    ranks = ranking.online_feature_ranking(X_train, Y_train, 'f_stat')\n",
    "                else:\n",
    "                    ranks = ranking.batch_feature_ranking(X_train, Y_train,'f_stat')\n",
    "                synonyms = ranking.compute_correlations(X_train, corr_above=0.95)\n",
    "                subset = ranking.best_subset(ranks, synonyms, n=3)\n",
    "                output = subset\n",
    "\n",
    "            elif exp_output == ranking.ExperimentOutput.BEST_MI:\n",
    "                if row['online']:\n",
    "                    ranks = ranking.online_feature_ranking(X_train, Y_train, 'mi')\n",
    "                else:\n",
    "                    ranks = ranking.batch_feature_ranking(X_train, Y_train, 'mi')\n",
    "                synonyms = ranking.compute_correlations(X_train, corr_above=0.95)\n",
    "                subset = ranking.best_subset(ranks, synonyms, n=3)\n",
    "                output = subset\n",
    "    \n",
    "            elif exp_output == ranking.ExperimentOutput.RANKS:\n",
    "                if row['online']:\n",
    "                    ranks = ranking.online_feature_ranking(X_train, Y_train)\n",
    "                else:\n",
    "                    ranks = ranking.batch_feature_ranking(X_train, Y_train)\n",
    "                output = ranks\n",
    "\n",
    "            output.reset_index(inplace=True)\n",
    "            output['feature'] = output['feature'].apply(lambda s: f'{domain_label}_{s}')\n",
    "            output = dict(zip(list(output['feature']), list(output['rank'])))\n",
    "            experiment.update(output)\n",
    "\n",
    "        if exp_output not in (ranking.ExperimentOutput.PCA, ranking.ExperimentOutput.SILHOUETTE):\n",
    "            experiments.append(experiment)\n",
    "\n",
    "    return pd.DataFrame.from_records(experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['placement', 'online']\n",
    "initial_conditions = [\n",
    "    dict(zip(column_names, row)) \n",
    "    for row in itertools.product(['A', 'B'], [False, True])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Majority voting: feature in subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 member sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "membership = run_experiments(initial_conditions, ranking.ExperimentOutput.BEST_SET)\n",
    "membership.to_csv('best_set/rank_product.csv', index=False)\n",
    "membership = run_experiments(initial_conditions, ranking.ExperimentOutput.BEST_CORR)\n",
    "membership.to_csv('best_set/corr.csv', index=False)\n",
    "membership = run_experiments(initial_conditions, ranking.ExperimentOutput.BEST_F_STAT)\n",
    "membership.to_csv('best_set/fstat.csv', index=False)\n",
    "membership = run_experiments(initial_conditions, ranking.ExperimentOutput.BEST_MI)\n",
    "membership.to_csv('best_set/mi.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globally best features (batch and online)\n",
    "def globally_best_batch_features(filename):\n",
    "    best_set_membership = pd.read_csv(filename)\n",
    "\n",
    "    for i, domain in enumerate(['TD', 'FD']):\n",
    "        fig, ax = plt.subplots(figsize=(12, 5))\n",
    "        cols = [col for col in best_set_membership if col.startswith(domain)]\n",
    "        graph = (\n",
    "            best_set_membership[cols][best_set_membership == True]\n",
    "            .count(axis=0)\n",
    "            .sort_values(ascending=False)\n",
    "        )\n",
    "        plt.grid()\n",
    "        ax.bar([re.search('[\\w]+_(\\w+)', s).group(1) for s in graph.index], graph)\n",
    "        ax.set_xlabel('Feature')\n",
    "        ax.set_ylabel('Count of best subset memberships')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globally_best_batch_features('best_set/rank_product.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globally_best_batch_features('best_set/corr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globally_best_batch_features('best_set/fstat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globally_best_batch_features('best_set/mi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_set_membership = pd.read_csv('best_set/rank_product.csv')\n",
    "temporal_columns = [col for col in best_set_membership if col.startswith('TD')]\n",
    "spectral_columns = [col for col in best_set_membership if col.startswith('FD')]\n",
    "agg = pd.DataFrame()\n",
    "for key, group in best_set_membership.groupby(by=['online']):\n",
    "    t_situation = group[temporal_columns][group == True].count(axis=0).sort_values(ascending=False).head(3)\n",
    "    f_situation = group[spectral_columns][group == True].count(axis=0).sort_values(ascending=False).head(3)\n",
    "    agg[key] = pd.concat([t_situation, f_situation]).index\n",
    "agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rank product: feature ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_set_ranks = run_experiments(initial_conditions, ranking.ExperimentOutput.RANKS)\n",
    "best_set_ranks.to_csv('best_set/ranks.csv', index=False)\n",
    "best_set_ranks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_set_ranks = pd.read_csv('best_set/ranks.csv')\n",
    "# Globally best features (lower rank is better)\n",
    "\n",
    "group = best_set_ranks[best_set_ranks['online'] == False]\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 4))\n",
    "for i, col in enumerate([temporal_columns, spectral_columns]):\n",
    "    graph = group[col].apply(gmean, axis=0).sort_values(ascending=True)\n",
    "    print(graph)\n",
    "    ax[i].grid()\n",
    "    ax[i].bar([re.search('\\w+_(\\w+)', s).group(1) for s in graph.index], graph)\n",
    "plt.show()\n",
    "\n",
    "# Online\n",
    "group = best_set_ranks[best_set_ranks['online'] == True]\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 4))\n",
    "for i, col in enumerate([temporal_columns, spectral_columns]):\n",
    "    graph = group[col].apply(gmean, axis=0).sort_values(ascending=True)\n",
    "    print(graph)\n",
    "    ax[i].grid()\n",
    "    ax[i].bar([re.search('\\w+_(\\w+)', s).group(1) for s in graph.index], graph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary (absolute counts) - RPM limited/unlimted and machinery element\n",
    "best_set_ranks = pd.read_csv('best_set/ranks.csv')\n",
    "all_columns = temporal_columns + spectral_columns\n",
    "agg = pd.DataFrame()\n",
    "for key, group in best_set_ranks.groupby(by=['online']):\n",
    "    agg[key] = group[all_columns].apply(gmean, axis=0)\n",
    "agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_set_ranks = pd.read_csv('best_set/ranks.csv')\n",
    "agg = pd.DataFrame()\n",
    "for key, group in best_set_ranks.groupby(by=['online']):\n",
    "    t_situation = group[temporal_columns].apply(gmean, axis=0).sort_values(ascending=True).head(3)\n",
    "    f_situation = group[spectral_columns].apply(gmean, axis=0).sort_values(ascending=True).head(3)\n",
    "    agg[key] = pd.concat([t_situation, f_situation]).index\n",
    "agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary (absolute counts) - RPM limited/unlimted and machinery element\n",
    "best_set_ranks = pd.read_csv('best_set/ranks.csv')\n",
    "agg = pd.DataFrame()\n",
    "for key, group in best_set_ranks.groupby(by=['online']):\n",
    "    agg[key] = group[all_columns].apply(gmean, axis=0)\n",
    "agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_set_ranks = pd.read_csv('best_set/ranks.csv')\n",
    "agg = pd.DataFrame()\n",
    "for key, group in best_set_ranks.groupby(by=['online']):\n",
    "    t_situation = group[temporal_columns].apply(gmean, axis=0).sort_values(ascending=False).head(3)\n",
    "    f_situation = group[spectral_columns].apply(gmean, axis=0).sort_values(ascending=False).head(3)\n",
    "    agg[key] = pd.concat([t_situation, f_situation]).index\n",
    "agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best features by experiment\n",
    "- Majority voting\n",
    "- Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature_names(feature_set):\n",
    "    return [re.search('\\w+_(\\w+)', s).group(1) for s in feature_set.index]\n",
    "\n",
    "def best_feature_set_methods(filename):\n",
    "    best_set_membership = pd.read_csv(filename)\n",
    "    feature_sets = []\n",
    "    indexer = ['placement', 'online']\n",
    "    for key, group in best_set_membership.groupby(by=indexer):\n",
    "        t_situation = group[temporal_columns][group == True].count(axis=0).sort_values(ascending=False).head(3)\n",
    "        f_situation = group[spectral_columns][group == True].count(axis=0).sort_values(ascending=False).head(3)\n",
    "\n",
    "        # Extract feature names\n",
    "        temporal = list(sorted(extract_feature_names(t_situation)))\n",
    "        spectral = list(sorted(extract_feature_names(f_situation)))\n",
    "\n",
    "        fset = {'placement': key[0], 'online': key[1], 'TD': temporal , 'FD': spectral}\n",
    "        feature_sets.append(fset)\n",
    "\n",
    "    return pd.DataFrame.from_records(feature_sets).set_index(indexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_feature_set_methods('best_set/rank_product.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_feature_set_methods('best_set/corr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_feature_set_methods('best_set/fstat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_feature_set_methods('best_set/mi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_feature_set_methods('best_set/ranks.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA explained variance (batch only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['placement', 'online']\n",
    "batch_initial_conditions = [\n",
    "    dict(zip(column_names, row)) \n",
    "    for row in itertools.product(['A', 'B'], [False, True])\n",
    "]\n",
    "pca_vars = run_experiments(batch_initial_conditions, ranking.ExperimentOutput.PCA)\n",
    "pca_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stacked(df: pd.DataFrame, selected_columns: List[str], ylabel: str):\n",
    "    domains = ('TD', 'FD')\n",
    "    placements = ('A', 'B')\n",
    "    fig, ax = plt.subplots(len(domains), len(placements), figsize=(8, 8))\n",
    "\n",
    "    for r, domain in enumerate(domains):\n",
    "        for c, place in enumerate(placements):\n",
    "            g = df[\n",
    "                (df['placement'] == place) & \n",
    "                (df['domain'] == domain)\n",
    "            ][selected_columns]\n",
    "            g.plot.bar(\n",
    "                stacked=True,\n",
    "                grid=True,\n",
    "                ax=ax[r][c],\n",
    "                title=f'{domain} features, Placement: {place}',\n",
    "                xlabel='',\n",
    "                ylabel=ylabel\n",
    "            )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_stacked(\n",
    "    pca_vars[pca_vars['online'] == False],\n",
    "    ['PC1', 'PC2', 'PC3'],\n",
    "    'Explained variance'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Silhouette scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = run_experiments(batch_initial_conditions, ranking.ExperimentOutput.SILHOUETTE)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stacked(scores[scores['online'] == False], ['train', 'test'], 'Silhouette score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stacked(scores[scores['online'] == False], ['train_pca', 'test_pca'], 'Silhouette score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature distribution in different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_features(conditions: List[dict]):\n",
    "    for row in tqdm(conditions):\n",
    "        experiment = row.copy()\n",
    "        print(row)\n",
    "        domains = ('TD', 'FD')\n",
    "\n",
    "        for domain_label in domains:\n",
    "            X_train, X_test, Y_train, Y_test = mafaulda.load_source(domain_label, row)\n",
    "            X_train_scaled = X_train\n",
    "\n",
    "            # Diagonal of covariance matrix to see explained variance cov(A, A) = var(A)\n",
    "            # Variance threshold\n",
    "            train_cov = X_train_scaled.cov()\n",
    "            diagonal_cov = pd.Series(np.diag(train_cov), index=[train_cov.index, train_cov.columns])\n",
    "            diagonal_cov = diagonal_cov / diagonal_cov.sum()\n",
    "            diagonal_cov = diagonal_cov.sort_values(ascending=False)\n",
    "            print(row)\n",
    "            print(diagonal_cov)\n",
    "\n",
    "            X_train_scaled['target'] = Y_train\n",
    "            # Show boxplots split by predicted variable\n",
    "            X_train_scaled.boxplot(figsize=(15, 5))\n",
    "            plt.show()\n",
    "            X_train_scaled.boxplot(figsize=(20, 5), layout=(2, 6), by='target', sharey=False)\n",
    "            plt.show()\n",
    "\n",
    "column_names = ['placement', 'online']\n",
    "batch_initial_conditions = [\n",
    "    dict(zip(column_names, row)) \n",
    "    for row in itertools.product(['A', 'B'], [False, True])\n",
    "]\n",
    "boxplot_features(batch_initial_conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxprops = dict(linewidth=1, color='k')\n",
    "medianprops = dict(linewidth=2, color='k')\n",
    "X, _, Y, _ = mafaulda.load_source('TD', {'placement': 'A', 'online': False})\n",
    "X.plot(\n",
    "    kind='box', \n",
    "    subplots=True, \n",
    "    sharey=False, \n",
    "    figsize=(20, 5),\n",
    "    grid=True,\n",
    "    boxprops=boxprops,\n",
    "    medianprops=medianprops,\n",
    "    whiskerprops=boxprops,\n",
    "    capprops=boxprops\n",
    "    \n",
    ")\n",
    "\n",
    "x_scaled = pd.DataFrame()\n",
    "x_scaled[X.columns] = MinMaxScaler().fit_transform(X)\n",
    "vars = {}\n",
    "\n",
    "X_td = X.copy()\n",
    "pca_td = PCA(n_components=10)\n",
    "X_pca = pca_td.fit_transform(x_scaled)\n",
    "print(pca_td.explained_variance_ratio_)\n",
    "print(np.cumsum(pca_td.explained_variance_ratio_))\n",
    "\n",
    "for col in x_scaled.columns:\n",
    "    vars[col] = np.var(x_scaled[col])\n",
    "vars = pd.DataFrame.from_records([vars]).T\n",
    "\n",
    "\n",
    "(100 * (vars / vars.sum())).sort_values(by=0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, _, Y, _ = mafaulda.load_source('FD', {'placement': 'A', 'online': False})\n",
    "X.plot(\n",
    "    kind='box', \n",
    "    subplots=True, \n",
    "    sharey=False, \n",
    "    figsize=(20, 5),\n",
    "    grid=True,\n",
    "    boxprops=boxprops,\n",
    "    medianprops=medianprops,\n",
    "    whiskerprops=boxprops,\n",
    "    capprops=boxprops\n",
    "    \n",
    ")\n",
    "\n",
    "x_scaled = pd.DataFrame()\n",
    "x_scaled[X.columns] = MinMaxScaler().fit_transform(X)\n",
    "vars = {}\n",
    "\n",
    "X_fd = X.copy()\n",
    "pca_fd = PCA(n_components=10)\n",
    "X_pca = pca_fd.fit_transform(x_scaled)\n",
    "print(pca_fd.explained_variance_ratio_)\n",
    "print(np.cumsum(pca_fd.explained_variance_ratio_))\n",
    "\n",
    "for col in x_scaled.columns:\n",
    "    vars[col] = np.var(x_scaled[col])\n",
    "vars = pd.DataFrame.from_records([vars]).T\n",
    "\n",
    "# Explained variances\n",
    "(100 * (vars / vars.sum())).sort_values(by=0, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explained varinace by PCA components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.plot(np.arange(1, 11), 100 * np.cumsum(pca_td.explained_variance_ratio_), marker='s', label='Temporal features')\n",
    "ax.plot(np.arange(1, 11), 100 * np.cumsum(pca_fd.explained_variance_ratio_), marker='s', label='Spectral features')\n",
    "ax.set_xlabel('Number of principal components')\n",
    "ax.set_ylabel('Percentage of explained variance')\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loadings plot\n",
    "- https://www.jcchouinard.com/python-pca-biplots-machine-learning/\n",
    "- https://support.minitab.com/en-us/minitab/21/help-and-how-to/statistical-modeling/multivariate/how-to/principal-components/interpret-the-results/key-results/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings = pca_td.components_\n",
    "n_features = pca_td.n_features_in_\n",
    "feature_names = X_td.columns\n",
    "pc_list = [f'PC{i}' for i in list(range(1, n_features + 1))]\n",
    "\n",
    "# Match PC names to loadings\n",
    "pc_loadings = dict(zip(pc_list, loadings))\n",
    "\n",
    "# Matrix of corr coefs between feature names and PCs\n",
    "loadings_df = pd.DataFrame.from_dict(pc_loadings)\n",
    "loadings_df['feature_names'] = feature_names\n",
    "loadings_df = loadings_df.set_index('feature_names')\n",
    "loadings_df[['PC1', 'PC2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.loading_plot(pca_td.components_, X_td.columns, -0.5, 1)\n",
    "visualize.loading_plot(pca_fd.components_, X_fd.columns, -0.5, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

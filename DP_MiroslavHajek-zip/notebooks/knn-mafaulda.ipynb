{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from zipfile import ZipFile\n",
    "import itertools\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from cycler import cycler\n",
    "import seaborn as sb\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from vibrodiagnostics import (\n",
    "    mafaulda, \n",
    "    extraction,\n",
    "    visualize,\n",
    "    models\n",
    ")\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARTS = 1\n",
    "FFT_WINDOW = 2**15\n",
    "EXTRACT = False\n",
    "GENERATE = False\n",
    "POWER_TRANSFORM = False\n",
    "MODEL_TYPE = 'knn'\n",
    "\n",
    "K_NEIGHBORS_OPTIONS = (3, 5, 11)\n",
    "NUM_FEATURES_OPTIONS = (2, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../datasets'\n",
    "FEATURES_PATH = os.path.join(PATH, 'features')\n",
    "RESULTS_PATH = os.path.join(FEATURES_PATH, f'results#{POWER_TRANSFORM}.json')\n",
    "BEST_FEATURES_PATH = os.path.join(FEATURES_PATH, 'best_features_accuracy.csv')\n",
    "DATASET_PATH = os.path.join(PATH, 'MAFAULDA.zip')\n",
    "LABELED_DATASET_PATH = os.path.join(FEATURES_PATH, 'MAFAULDA_LABEL.csv')\n",
    "KNN_BRUTE_FORCE_PATH = os.path.join(PATH, 'knn-accuracy-distribution')\n",
    "ONLINE_GRADUAL_PATH = os.path.join(PATH, 'knn-incremental-accuracy')\n",
    "\n",
    "FEATURES = {\n",
    "    'TD': os.path.join(FEATURES_PATH, 'MAFAULDA_TD.csv'),\n",
    "    'FD': os.path.join(FEATURES_PATH, 'MAFAULDA_FD.csv'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_filename(row: dict, separator: str = '#'):\n",
    "    parts = [\n",
    "        row['domain'],\n",
    "        row['dim'],\n",
    "        row['bearing'],\n",
    "        row['severity'],\n",
    "        POWER_TRANSFORM\n",
    "    ]\n",
    "    filename = separator.join([str(p) for p in parts])\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display example severities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = extraction.load_features(FEATURES['TD'], mafaulda.BEARING_A_COLUMNS, mafaulda.LABEL_COLUMNS) \n",
    "df = mafaulda.label_severity(df, 'A', 0.5, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate different feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "domains = ('TD', 'FD')\n",
    "dimensions = (1, 3)\n",
    "columns = {\n",
    "    'A': {\n",
    "        1: ['ay'],\n",
    "        3: mafaulda.BEARING_A_COLUMNS\n",
    "    },\n",
    "    'B': {\n",
    "        1: ['by'],\n",
    "        3: mafaulda.BEARING_B_COLUMNS\n",
    "    }\n",
    "}\n",
    "\n",
    "for domain in domains:\n",
    "    for dim in dimensions:\n",
    "        a = extraction.load_features(FEATURES[domain], columns['A'][dim], mafaulda.LABEL_COLUMNS) \n",
    "        a = mafaulda.mark_severity(a, 'A')\n",
    "        datasets.append({'domain': domain, 'dim': dim, 'bearing': 'A', 'severity': False, 'data': a})\n",
    "\n",
    "        b = extraction.load_features(FEATURES[domain], columns['B'][dim], mafaulda.LABEL_COLUMNS) \n",
    "        b = mafaulda.mark_severity(b, 'B')\n",
    "        datasets.append({'domain': domain, 'dim': dim, 'bearing': 'B', 'severity': False, 'data': b})\n",
    "\n",
    "        ab = pd.concat([a, b]).reset_index(drop=True)\n",
    "        datasets.append({'domain': domain, 'dim': dim, 'bearing': 'A+B', 'severity': False, 'data': ab})\n",
    "\n",
    "        a = extraction.load_features(FEATURES[domain], columns['A'][dim], mafaulda.LABEL_COLUMNS) \n",
    "        a = mafaulda.label_severity(a, 'A', 0.5, keep=True)\n",
    "        datasets.append({'domain': domain, 'dim': dim, 'bearing': 'A', 'severity': True, 'data': a})\n",
    "\n",
    "        b = extraction.load_features(FEATURES[domain], columns['B'][dim], mafaulda.LABEL_COLUMNS) \n",
    "        b = mafaulda.label_severity(b, 'B', 0.5, keep=True)\n",
    "        datasets.append({'domain': domain, 'dim': dim, 'bearing': 'B', 'severity': True, 'data': b})\n",
    "\n",
    "        ab = pd.concat([a, b]).reset_index(drop=True)\n",
    "        datasets.append({'domain': domain, 'dim': dim, 'bearing': 'A+B', 'severity': True, 'data': ab})\n",
    "\n",
    "\n",
    "datasets_raw_dict = [d.copy() for d in datasets]\n",
    "datasets_raw = pd.DataFrame.from_records(datasets_raw_dict)\n",
    "datasets_raw['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_online = [d.copy() for d in datasets_raw_dict]\n",
    "for row in datasets_online:\n",
    "    df = row['data']\n",
    "    groups = [\n",
    "        frame.sample(frac=1, random_state=10)\n",
    "        for i, frame in (\n",
    "            df.sort_values(by='severity_level')\n",
    "              .groupby('severity_level')\n",
    "        )\n",
    "    ]\n",
    "    rows = list(pd.concat(groups).index)\n",
    "    df = df.loc[rows].reset_index(drop=True).sort_index()\n",
    "    if row['severity'] is True:\n",
    "        df.loc[df['severity_level'] < 0.5, 'label'] = 'normal'\n",
    "    visualize.evolution_of_severity_levels(df)\n",
    "    row['data'] = mafaulda.clean_columns(df)\n",
    "\n",
    "datasets_online = pd.DataFrame.from_records(datasets_online)\n",
    "datasets_online['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = datasets_online[\n",
    "    (datasets_online['bearing'] == 'A') &\n",
    "    (datasets_online['severity'] == False)\n",
    "].head(1)\n",
    "x = visualize.plot_label_occurences(df['data'].values[0]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = datasets_online[\n",
    "    (datasets_online['bearing'] == 'A') &\n",
    "    (datasets_online['severity'] == True)\n",
    "].head(1)\n",
    "x = visualize.plot_label_occurences(df['data'].values[0]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in datasets:\n",
    "    df = row['data']\n",
    "    if row['severity'] is True:\n",
    "        df.loc[df['severity_level'] < 0.5, 'label'] = 'normal'\n",
    "    row['data'] = mafaulda.clean_columns(df)\n",
    "    \n",
    "datasets = pd.DataFrame.from_records(datasets)\n",
    "datasets = datasets[datasets['domain'].isin(['TD', 'FD'])]\n",
    "datasets['data'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of members in each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = []\n",
    "for name, group in datasets.groupby(by=['severity', 'bearing']):\n",
    "    severity, bearing = name\n",
    "    df = group['data'].values[0]\n",
    "    scenario = {'bearing': bearing, 'severity': severity}\n",
    "    counts = df['label'].value_counts().to_dict()\n",
    "    counts['sum'] = sum(counts.values())\n",
    "    scenario.update(counts)\n",
    "    label_counts.append(scenario)\n",
    "\n",
    "pd.DataFrame.from_records(label_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Range of values in features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in datasets.groupby(by=['domain', 'dim', 'bearing']):\n",
    "    df = group['data'].values[0].drop(columns=['label'])\n",
    "\n",
    "    fig, ax = plt.subplots(1, len(df.columns), figsize=(20, 4))\n",
    "    print(name)\n",
    "    for i, col in enumerate(df):\n",
    "        df.boxplot([col], ax=ax[i], color='black')\n",
    "    print(df.describe())\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Range of values in features - Power transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in datasets.groupby(by=['domain', 'dim', 'bearing']):\n",
    "    df = group['data'].values[0].drop(columns=['label'])\n",
    "\n",
    "    pt = PowerTransformer(method='yeo-johnson', standardize=True)\n",
    "    df[df.columns] = pt.fit_transform(df)\n",
    "\n",
    "    fig, ax = plt.subplots(1, len(df.columns), figsize=(20, 4))\n",
    "    print(name)\n",
    "    for i, col in enumerate(df):\n",
    "        df.boxplot([col], ax=ax[i], color='black')\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation of features to RPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_columns = datasets[datasets['domain'] == 'TD']['data'].head(1).values[0].drop(columns=['label']).columns.to_list()\n",
    "fd_columns = datasets[datasets['domain'] == 'FD']['data'].head(1).values[0].drop(columns=['label']).columns.to_list()\n",
    "\n",
    "datasets_corr = []\n",
    "for row in datasets_raw_dict.copy():\n",
    "    row = row.copy()\n",
    "    df = row.pop('data')\n",
    "    domain = row['domain']\n",
    "    columns = td_columns if domain == 'TD' else fd_columns\n",
    "    for col in df[columns]:\n",
    "        row[f'{domain}-{col}'] = np.corrcoef(df[col], df['rpm'])[0, 1]\n",
    "    \n",
    "    datasets_corr.append(row)\n",
    "\n",
    "datasets_corr_domains = []\n",
    "datasets_corr_domains.append(pd.DataFrame.from_records([d for d in datasets_corr if d['domain'] == 'TD']).drop(columns=['domain']))\n",
    "datasets_corr_domains.append(pd.DataFrame.from_records([d for d in datasets_corr if d['domain'] == 'FD']).drop(columns=['domain']))\n",
    "datasets_corr_domains = pd.concat(datasets_corr_domains, axis=1)\n",
    "datasets_corr_domains.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_corr_domains.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = datasets_corr_domains[\n",
    "    datasets_corr_domains.columns[\n",
    "        ~datasets_corr_domains.columns.isin(('dim', 'bearing', 'severity'))\n",
    "    ]\n",
    "]\n",
    "# Sort features by mean\n",
    "df = df.T.assign(m=df.T.mean(axis=1)).sort_values('m', ascending=False).drop('m', axis=1).T\n",
    "df.boxplot(figsize=(10, 5), color='black', notch=True)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Correlation')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation of features among themselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = LinearSegmentedColormap.from_list('', ['black', 'white', 'black'])\n",
    "\n",
    "for name, group in datasets.groupby(by=['domain', 'dim', 'bearing']):\n",
    "    df = group['data'].values[0].drop(columns=['label'])\n",
    "    print(name)\n",
    "    columns = list(df.columns)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "    sb.heatmap(df[columns].corr(), cmap=cmap, vmin=-1, vmax=1, annot=True, ax=ax, fmt='.0%')\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neighbourhood of same class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighborhood_of_same_class(severity: bool, bearing: str):\n",
    "    frame = {}\n",
    "    for domain in domains: \n",
    "        df = datasets[\n",
    "            (datasets['dim'] == 3) & \n",
    "            (datasets['domain'] == domain) & \n",
    "            (datasets['bearing'] == bearing) & \n",
    "            (datasets['severity'] == severity)]['data'].values[0]\n",
    "\n",
    "        dx = df.drop(columns='label')\n",
    "        rows = {}\n",
    "\n",
    "        for k in range(2, 100, 2):\n",
    "            neigh = NearestNeighbors(n_neighbors=k).fit(dx)\n",
    "            distances, indices = neigh.kneighbors(dx)\n",
    "            count = 0\n",
    "            for idx, nearby in enumerate(indices):\n",
    "                my_label = df.iloc[idx]['label']\n",
    "                majority_label = df.iloc[nearby]['label'].value_counts().sort_values(ascending=False).index.values[0]\n",
    "                # majority label is same as mine\n",
    "                if my_label == majority_label:\n",
    "                    count += 1\n",
    "            rows[k - 1] = ((count / len(dx)) * 100)\n",
    "\n",
    "        frame[domain] = rows\n",
    "\n",
    "    return pd.DataFrame.from_records(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = neighborhood_of_same_class(False, 'A')\n",
    "df.plot(grid=True, xlabel='Majority of neighbours with same label', ylabel='Fraction of dataset [%]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = neighborhood_of_same_class(True, 'A')\n",
    "df.plot(grid=True, xlabel='Majority of neighbours with same label', ylabel='Fraction of dataset [%]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All features on each scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "if GENERATE is True:\n",
    "    for index, row in tqdm(datasets.iterrows()):\n",
    "        source = row['data']\n",
    "        y = source['label']\n",
    "        x = source.drop(columns=['label'])\n",
    "        r = models.all_features(\n",
    "            x, y, power_transform=POWER_TRANSFORM\n",
    "        )\n",
    "        r.update({\n",
    "            'domain': row['domain'],\n",
    "            'dim': row['dim'],\n",
    "            'bearing': row['bearing'],\n",
    "            'severity': row['severity']\n",
    "        })\n",
    "        results.append(r)\n",
    "    json.dump(results, open(RESULTS_PATH, 'w'))\n",
    "\n",
    "results = json.load(open(RESULTS_PATH, 'r'))\n",
    "results[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = json.load(open(RESULTS_PATH, 'r'))\n",
    "y = []\n",
    "for x in results:\n",
    "    d = dict(zip(x['k'], x['test']))\n",
    "    for key in ('k', 'train', 'test'):\n",
    "        x.pop(key)\n",
    "    x.update(d)\n",
    "    y.append(x)\n",
    "\n",
    "k_all_features_test = pd.DataFrame.from_records(y)\n",
    "k_all_features_test = k_all_features_test[k_all_features_test['domain'].isin(('TD', 'FD'))]\n",
    "k_all_features_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_all_features_k_accuracies(results: pd.DataFrame, domain: str, severity: bool):\n",
    "    df = results.drop(columns=['severity'])\n",
    "    df = df.set_index(['domain', 'dim', 'bearing']).T\n",
    "    ax = df.plot(figsize=(12, 6), marker='v')\n",
    "\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_xlabel('K-neighbors')\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "for (domain, severity), group in k_all_features_test.groupby(by=['domain', 'severity']):\n",
    "    print(domain, severity)\n",
    "    compare_all_features_k_accuracies(group, domain, severity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enumerate feature combinations on each scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "Path(KNN_BRUTE_FORCE_PATH).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if GENERATE is True:\n",
    "    for index, row in tqdm(datasets.iterrows()):\n",
    "        source = row['data']\n",
    "        y = source['label']\n",
    "        x = source.drop(columns=['label'])\n",
    "\n",
    "        result = models.enumerate_models(\n",
    "            x, y, row['domain'],\n",
    "            power_transform=POWER_TRANSFORM,\n",
    "            k_neighbors=K_NEIGHBORS_OPTIONS,\n",
    "            num_of_features=NUM_FEATURES_OPTIONS\n",
    "        )\n",
    "        filename = make_filename(row)\n",
    "        filename = os.path.join(KNN_BRUTE_FORCE_PATH, filename)\n",
    "        result.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(KNN_BRUTE_FORCE_PATH):\n",
    "    if not os.path.isfile(os.path.join(KNN_BRUTE_FORCE_PATH, filename)):\n",
    "        continue\n",
    "    models_summary = pd.read_csv(os.path.join(KNN_BRUTE_FORCE_PATH, filename))\n",
    "    print(filename)\n",
    "    visualize.boxplot_enumerate_models_accuracy(models_summary, 'test', 'f', 'k')\n",
    "    visualize.boxplot_enumerate_models_accuracy(models_summary, 'test', 'k', 'f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bar chart for specfic number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE is True:\n",
    "    results = []\n",
    "    for index, row in tqdm(datasets.iterrows()):\n",
    "        source = row['data']\n",
    "        y = source['label']\n",
    "        x = source.drop(columns=['label'])\n",
    "        filename = make_filename(row)\n",
    "        models_summary = pd.read_csv(os.path.join(KNN_BRUTE_FORCE_PATH, filename))\n",
    "\n",
    "        for fnum in NUM_FEATURES_OPTIONS:\n",
    "            for k in K_NEIGHBORS_OPTIONS:\n",
    "                result = models.feature_selection_accuracies(\n",
    "                    x, y, \n",
    "                    row['domain'],\n",
    "                    models_summary,\n",
    "                    k_neighbors=k,\n",
    "                    number_of_features=fnum, \n",
    "                    power_transform=POWER_TRANSFORM\n",
    "                )\n",
    "                for r in result:\n",
    "                    r.update({\n",
    "                        'dim': row['dim'],\n",
    "                        'bearing': row['bearing'],\n",
    "                        'severity': row['severity'],\n",
    "                        'k': k,\n",
    "                        'f': fnum\n",
    "                    })\n",
    "                results.extend(result)\n",
    "    \n",
    "    results = pd.DataFrame.from_records(results)\n",
    "    results.to_csv(BEST_FEATURES_PATH, index=False)\n",
    "else:\n",
    "    results = pd.read_csv(BEST_FEATURES_PATH)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = results[\n",
    "    (results['f'] == 3) &\n",
    "    (results['k'] == 5)\n",
    "]\n",
    "frame.to_csv('../datasets/mafaulda_knn_feature_selection.csv', index=False)\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in results.groupby(by=['dim', 'bearing', 'severity', 'domain', 'k', 'f']):\n",
    "    print(name)\n",
    "    visualize.plot_models_performance_bar(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy and percentile of feature selection methods to number of features\n",
    "- The best features don't have always 100 percentile. The best subset is taken after sorting training set and distribution of accuracies is from validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in results.groupby(by=['dim', 'bearing', 'severity', 'domain', 'k']):\n",
    "    print(name)\n",
    "    (group[['f', 'set', 'test_accuracy']]\n",
    "     .pivot(index='f', columns='set', values='test_accuracy')\n",
    "     .plot(figsize=(8, 5), marker='o', grid=True, xlabel='Number of features', ylabel='Accuracy'))\n",
    "    plt.xticks(NUM_FEATURES_OPTIONS)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in results.groupby(by=['dim', 'bearing', 'severity', 'domain', 'k']):\n",
    "    print(name)\n",
    "    (group[['f', 'set', 'test_percentile']]\n",
    "     .pivot(index='f', columns='set', values='test_percentile')\n",
    "     .plot(figsize=(8, 5), marker='o', grid=True, xlabel='Number of features', ylabel='Percentile'))\n",
    "    plt.xticks(NUM_FEATURES_OPTIONS)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy and percentile of feature selection methods to number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in results.groupby(by=['dim', 'bearing', 'severity', 'domain', 'f']):\n",
    "    print(name)\n",
    "    (group[['k', 'set', 'test_accuracy']]\n",
    "     .pivot(index='k', columns='set', values='test_accuracy')\n",
    "     .plot(figsize=(8, 6), marker='o', grid=True, xlabel='k-Neighbors', ylabel='Accuracy'))\n",
    "    plt.xticks(K_NEIGHBORS_OPTIONS)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in results.groupby(by=['dim', 'bearing', 'severity', 'domain', 'f']):\n",
    "    print(name)\n",
    "    (group[['k', 'set', 'test_percentile']]\n",
    "     .pivot(index='k', columns='set', values='test_percentile')\n",
    "     .plot(figsize=(8, 6), marker='o', grid=True, label='k-Neighbors', ylabel='Percentile'))\n",
    "    plt.xticks(K_NEIGHBORS_OPTIONS)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of percentiles reached by feature selection methods in various subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(\n",
    "    grid=True,\n",
    "    bins=20,\n",
    "    edgecolor='black',\n",
    "    linewidth=0.5,\n",
    "    alpha=0.5\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 5))\n",
    "for method in ('Rank product', 'Mutual information', 'F statistic', 'Correlation'):\n",
    "    df = results[results['set'] == method]\n",
    "    print(method, df['test_percentile'].median())\n",
    "    sb.kdeplot(data=df, x='test_percentile', bw_adjust=0.2, label=method, ax=ax)\n",
    "    ax.set_xlabel('Percentile')\n",
    "    ax.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(\n",
    "    grid=True,\n",
    "    bins=20,\n",
    "    edgecolor='black',\n",
    "    linewidth=0.5,\n",
    "    alpha=0.5\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 5))\n",
    "for method in ('Rank product', 'Mutual information', 'F statistic', 'Correlation'):\n",
    "    df = results[results['set'] == method]\n",
    "    print(method, df['test_accuracy'].median())\n",
    "    sb.kdeplot(data=df, x='test_accuracy', bw_adjust=0.8, label=method, ax=ax)\n",
    "    ax.set_xlabel('Accuracy')\n",
    "    ax.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In how many cases is rank product best among all the selection methods?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_wins_of_methods(datasets, results, methods):\n",
    "    columns = list(set(datasets.columns) - {'data'}) + ['k', 'f']\n",
    "    counts = dict(zip(methods + ['total'], np.zeros(len(methods)+1)))\n",
    "    percentiles = dict(zip(methods, [[] for _ in range(len(methods))]))\n",
    "    \n",
    "    for name, group in results.groupby(by=columns):\n",
    "        counts['total'] += 1\n",
    "        row = (\n",
    "            group[group['set'].isin(methods)]\n",
    "            .sort_values(by='test_percentile', ascending=False)\n",
    "            .head(1)\n",
    "        )\n",
    "        key = row.head(1)['set'].values[0]\n",
    "        percentile = row.head(1)['test_percentile'].values[0]\n",
    "\n",
    "        percentiles[key].append(percentile)\n",
    "        counts[key] += 1\n",
    "        \n",
    "    percentiles = {k: np.mean(v or [0]) for k, v in percentiles.items()}\n",
    "    percentiles = pd.DataFrame.from_dict(percentiles, orient='index', columns=['score'])\n",
    "        \n",
    "    counts = pd.DataFrame.from_dict(counts, orient='index', columns=['count'])\n",
    "    counts['percentage'] = 100 * (counts['count'] / counts[counts.index == 'total'].values[0])\n",
    "    counts = counts.join(percentiles)\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = list(set(results['set'].unique()) - {'PCA PC', 'All features', 'Best features'})\n",
    "count_wins_of_methods(datasets, results, methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = list(set(results['set'].unique()) - {'All features', 'Best features'})\n",
    "count_wins_of_methods(datasets, results, methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = list(set(results['set'].unique()) - {'Best features'})\n",
    "count_wins_of_methods(datasets, results, methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram of model accuracy distribution and vertical line for individual feature selection methods\n",
    "- dim=3, bearing=A, severity=False, k=5, f=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(16, 9))\n",
    "for i, domain in enumerate(FEATURES):\n",
    "    row = {\n",
    "        'domain': domain,\n",
    "        'dim': 3,\n",
    "        'bearing': 'A',\n",
    "        'severity': False,\n",
    "        'k': 5,\n",
    "        'f': 3\n",
    "    }\n",
    "    filename = make_filename(row)\n",
    "    print(filename)\n",
    "    distribution = pd.read_csv(os.path.join(KNN_BRUTE_FORCE_PATH, filename))\n",
    "    distribution = distribution[\n",
    "        (distribution['k'] == row['k']) &\n",
    "        (distribution['f'] == row['f'])\n",
    "    ]\n",
    "\n",
    "    mselection = results[\n",
    "        (results['domain'] == row['domain']) &\n",
    "        (results['dim'] == row['dim']) &\n",
    "        (results['bearing'] == row['bearing']) &\n",
    "        (results['severity'] == row['severity']) &\n",
    "        (results['k'] == row['k']) &\n",
    "        (results['f'] == row['f'])\n",
    "    ]\n",
    "    params = dict(\n",
    "        grid=True,\n",
    "        bins=30,\n",
    "        edgecolor='black',\n",
    "        linewidth=0.5,\n",
    "        color='gray',\n",
    "        range=(0.6, 1)\n",
    "    )\n",
    "    colors = ['r', 'g', 'b', 'orange', 'm', 'y', 'k']\n",
    "\n",
    "    params['ax'] = ax[0][i]\n",
    "    params['ax'].set_xlabel('Accuracy')\n",
    "    params['ax'].set_ylabel('Number of k-NN models')\n",
    "    params['ax'].set_title(visualize.DOMAIN_TITLES[domain] + ', Training set')\n",
    "    distribution['train'].hist(**params)\n",
    "\n",
    "    sel = mselection.set_index('set').to_dict()['train_accuracy']\n",
    "    color_cycle = cycler(color=colors)\n",
    "    for c, (k, v) in zip(color_cycle, sel.items()):\n",
    "        params['ax'].axvline(v, linestyle='-', lw=2, label=f'{k} ({v*100:.1f})', alpha=0.8, **c) \n",
    "    params['ax'].legend()\n",
    "\n",
    "    params['ax'] = ax[1][i]\n",
    "    params['ax'].set_xlabel('Accuracy')\n",
    "    params['ax'].set_ylabel('Number of k-NN models')\n",
    "    params['ax'].set_title(visualize.DOMAIN_TITLES[domain] + ', Testing set')\n",
    "    distribution['test'].hist(**params)\n",
    "\n",
    "    sel = mselection.set_index('set').to_dict()['test_accuracy']\n",
    "    color_cycle = cycler(color=colors)\n",
    "    for c, (k, v) in zip(color_cycle, sel.items()):\n",
    "        params['ax'].axvline(v, linestyle='-', lw=2, label=f'{k} ({v*100:.1f})', alpha=0.8, **c) \n",
    "    params['ax'].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_online"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Online gradual learning with step 1\n",
    "k = 5, f = 3\n",
    "(90 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_filename_incremental(domain: str, severity: bool, window_len: int, learn_skip: int):\n",
    "    return f'{domain}#{severity}#{window_len}#{learn_skip}.csv'\n",
    "\n",
    "\n",
    "def parse_filename_incremental(filename: str) -> tuple:\n",
    "    return filename.rstrip('.csv').split('#')\n",
    "\n",
    "\n",
    "def incremental_learning(num_of_features: int, folder: str, window_len: int, learn_skip: int):\n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for (domain, severity), group in tqdm(datasets_online.groupby(by=['domain', 'severity'])):\n",
    "        print(domain, severity)\n",
    "        online_scenarios = group[\n",
    "            (group['bearing'] == 'A') &\n",
    "            (group['dim'] == 3)\n",
    "        ]\n",
    "\n",
    "        stream = online_scenarios['data'].values[0]\n",
    "        columns = stream.drop(columns=['label']).columns\n",
    "        # print(stream[stream['label'] == 'normal'].tail(1).index, len(stream))\n",
    "\n",
    "        results = []\n",
    "        for features in list(itertools.combinations(columns, r=num_of_features)):\n",
    "            x = stream[list(features)].copy()\n",
    "            y = stream['label'].copy()\n",
    "            r = models.knn_online_learn(x, y, window_len=window_len, learn_skip=learn_skip)\n",
    "            r = {v['step']: v['accuracy'] for v in r.to_dict('records')}\n",
    "            results.append(r)\n",
    "\n",
    "        m = pd.DataFrame.from_records(results)\n",
    "        m.to_csv(os.path.join(folder, make_filename_incremental(domain, severity, window_len, learn_skip)), index=False)\n",
    "\n",
    "\n",
    "def load_incremental_distributions(win_desired: List[int], skip: List[int]):\n",
    "    graphs = []\n",
    "    for filename in os.listdir(ONLINE_GRADUAL_PATH):\n",
    "        path = os.path.join(ONLINE_GRADUAL_PATH, filename)\n",
    "        domain, severity, win, skip = parse_filename_incremental(filename)\n",
    "\n",
    "        if not os.path.isfile(path):\n",
    "            continue\n",
    "        if not (int(win) in win_desired and int(skip) in skip_desired):\n",
    "            continue\n",
    "\n",
    "        m = pd.read_csv(path)\n",
    "        steps = m.T.index.astype(int).to_numpy()\n",
    "        graphs.append({\n",
    "            'domain': domain,\n",
    "            'severity': severity,\n",
    "            'win': win,\n",
    "            'skip': skip,\n",
    "            'steps': steps,\n",
    "            'lower_boundary': m.min().to_numpy(),\n",
    "            'upper_boundary': m.max().to_numpy(),\n",
    "            'middle_line': m.median().to_numpy()\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame.from_records(graphs)\n",
    "\n",
    "\n",
    "def plot_model_evolution(d: dict, ax, color='gray', line_color='darkgreen', alpha=0.5, label=None):\n",
    "    print(\n",
    "        d['steps'][-1],\n",
    "        d['lower_boundary'][-1],\n",
    "        d['middle_line'][-1],\n",
    "        d['upper_boundary'][-1]\n",
    "    )\n",
    "    ax.fill_between(\n",
    "        d['steps'], \n",
    "        d['lower_boundary'],\n",
    "        d['upper_boundary'],\n",
    "        color='#ccc',\n",
    "        alpha=alpha\n",
    "    )\n",
    "    ax.plot(\n",
    "        d['steps'],\n",
    "        d['lower_boundary'],\n",
    "        linestyle='--',\n",
    "        color=color\n",
    "    )\n",
    "    ax.plot(\n",
    "        d['steps'],\n",
    "        d['upper_boundary'],\n",
    "        linestyle='-.',\n",
    "        color=color\n",
    "    )\n",
    "    ax.plot(\n",
    "        d['steps'],\n",
    "        d['middle_line'],\n",
    "        color=line_color,\n",
    "        label=label\n",
    "    )\n",
    "    ax.set_xlabel('Observations')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.grid(True)\n",
    "\n",
    "\n",
    "def graph_evolution_comparison(models: pd.DataFrame, hyperparam: str):\n",
    "    colors = ['#ffbe0b', '#3a86ff', '#3a5a40']\n",
    "    color_cycle = cycler(color=colors)\n",
    "    x = None\n",
    "    for (domain, severity), group in models.groupby(by=['domain', 'severity']):\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "        print(domain, severity)\n",
    "        for color, row in zip(color_cycle, group.sort_values(by=hyperparam).to_dict('records')):\n",
    "            plot_model_evolution(row, ax, color=color['color'], line_color=color['color'], alpha=0.1, label=row[hyperparam])\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_features = 3\n",
    "learning_window_lengths = (1, 10, 100)\n",
    "labels_skips = (0, 10, 50)\n",
    "\n",
    "if GENERATE is True:\n",
    "    skip = labels_skips[0]\n",
    "    for win in learning_window_lengths:\n",
    "        incremental_learning(number_of_features, ONLINE_GRADUAL_PATH, win, skip)\n",
    "\n",
    "    win = learning_window_lengths[1]\n",
    "    for skip in labels_skips[1:]:\n",
    "        incremental_learning(number_of_features, ONLINE_GRADUAL_PATH, win, skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_desired = [1]\n",
    "skip_desired = [0]\n",
    "models = load_incremental_distributions(win_desired, skip_desired)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (domain, severity), group in models.groupby(by=['domain', 'severity']):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "    print(domain, severity)\n",
    "    plot_model_evolution(group.to_dict('records')[0], ax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different lengths of tumbling windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_desired = learning_window_lengths\n",
    "skip_desired = [0]\n",
    "models = load_incremental_distributions(win_desired, skip_desired)\n",
    "graph_evolution_comparison(models, 'win')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different amount of skipping true labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_desired = [10]\n",
    "skip_desired = labels_skips\n",
    "models = load_incremental_distributions(win_desired, skip_desired)\n",
    "graph_evolution_comparison(models, 'skip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN streaming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOMAINS = ['TD', 'FD']\n",
    "DOMAIN = DOMAINS[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import functools\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn import metrics as skmetrics\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from river import metrics\n",
    "from river import preprocessing\n",
    "from river import neighbors, utils, evaluate, stream\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from vibrodiagnostics import (\n",
    "    mafaulda, \n",
    "    extraction,\n",
    "    visualize,\n",
    "    models\n",
    ")\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_source(domain: str, row: dict):\n",
    "    PATH = '../datasets/'\n",
    "    FEATURES_PATH = os.path.join(PATH, 'features')\n",
    "    MAFAULDA_TEMPORAL = os.path.join(FEATURES_PATH, 'MAFAULDA_TD.csv')\n",
    "    MAFAULDA_SPECTRAL = os.path.join(FEATURES_PATH, 'MAFAULDA_FD.csv')\n",
    "\n",
    "    dataset = {\n",
    "        'TD': MAFAULDA_TEMPORAL,\n",
    "        'FD': MAFAULDA_SPECTRAL,\n",
    "        'axis': {\n",
    "            'A': ['ax', 'ay', 'az'],\n",
    "            'B': ['bx', 'by', 'bz']\n",
    "        },\n",
    "        'labels': ['fault', 'severity', 'rpm']\n",
    "    }\n",
    "\n",
    "    placement = row['placement']\n",
    "    df = extraction.load_features(\n",
    "        dataset[domain],\n",
    "        dataset['axis'][placement],\n",
    "        dataset['labels']\n",
    "    )\n",
    "    frame = mafaulda.assign_labels(df, placement)\n",
    "    Y = frame['label']\n",
    "    X = frame.drop(columns=['label'])\n",
    "\n",
    "    # Shuffle order within severity level and order event with increasing severity\n",
    "    features = mafaulda.label_severity(df, placement, 0.5, keep=True)\n",
    "    # Shuffle order within severity level and order event with increasing severity\n",
    "    groups = [\n",
    "        frame.sample(frac=1, random_state=10)\n",
    "        for i, frame in (\n",
    "            features\n",
    "            .sort_values(by='severity_level')\n",
    "            .groupby('severity_level')\n",
    "        )\n",
    "    ]\n",
    "    rows = list(pd.concat(groups).index)\n",
    "    \n",
    "    features = features.loc[rows].reset_index(drop=True)\n",
    "    X = X.loc[rows].reset_index(drop=True)\n",
    "    Y = Y.loc[rows].reset_index(drop=True)\n",
    "    X['severity_level'] = features['severity_level']\n",
    "\n",
    "    X, Y, features = X.sort_index(), Y.sort_index(), features.sort_index()\n",
    "    \n",
    "    visualize.evolution_of_severity_levels(X)\n",
    "    X = X.drop(columns=['severity_level'])\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = load_source(DOMAIN, {'placement': 'A', 'domain': DOMAIN})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evolution of faults "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = visualize.plot_label_occurences(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradual learning\n",
    "- 6 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = models.knn_online_learn(X, Y, window_len=1)\n",
    "ax = results[['accuracy']].plot(\n",
    "    grid=True, legend=False, figsize=(10, 5),\n",
    "    xlabel='Observations', ylabel='Accuracy' # title='Fault classes: 6, Window size: 1'\n",
    ")\n",
    "best = results.tail(1)\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Window learning\n",
    "- Compare classification accuracies for window sizes in one graph: (1, 10, 50, 100, 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_window_lengths = (1, 10, 100)\n",
    "\n",
    "fault_evolution = pd.DataFrame()\n",
    "for n in tqdm(learning_window_lengths):\n",
    "    results = models.knn_online_learn(X, Y, window_len=n)\n",
    "    accuracy = results['accuracy']\n",
    "    accuracy.index += n             # Starts learning after at least one window has been filled\n",
    "    fault_evolution[str(n)] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = fault_evolution.fillna(0).plot(\n",
    "    grid=True, legend=True, figsize=(10, 5), #ylim=(0.8, 1.01),\n",
    "    xlabel='Sample', ylabel='Accuracy' #, title='Faults: Label with delay'\n",
    ")\n",
    "fault_evolution.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing labels - Faults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_len = 10\n",
    "labels_skips = (0, 2, 10, 50)\n",
    "\n",
    "fault_skip_evolution = pd.DataFrame()\n",
    "for s in tqdm(labels_skips):\n",
    "    results = models.knn_online_learn(X, Y, window_len=window_len, learn_skip=s)\n",
    "    accuracy = results['accuracy']\n",
    "    accuracy.index += len(X) - len(accuracy)\n",
    "    fault_skip_evolution[str(s)] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = fault_skip_evolution.fillna(0).plot(\n",
    "    grid=True, legend=True, figsize=(10, 5), # ylim=(0, 1.01),\n",
    "    xlabel='Sample', ylabel='Accuracy' # , title=f'Faults (4 classes): Skip labels (out of {len(XStream_fault)} total), Window: {window_len}'\n",
    ")\n",
    "fault_skip_evolution.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy at same observation point with different label skips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line - generation (), Y-axis: accuracy, X-axis: skip amount\n",
    "evolution = fault_skip_evolution[200:len(fault_skip_evolution)-1:400]\n",
    "evolution = evolution.T.reset_index()\n",
    "evolution['index'] = evolution['index'].astype(int)\n",
    "evolution['index'] = 100 / evolution['index']\n",
    "evolution.replace([np.inf], 100, inplace=True)\n",
    "evolution =  evolution.set_index('index')\n",
    "evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = evolution.plot(marker='o', grid=True, figsize=(8, 6))\n",
    "ax.set_xlabel('Fraction of original labels [%]')\n",
    "ax.set_ylabel('Accuracy [%]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatter plot - True labels vs. Predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.project_classifier_map_plot(\n",
    "    X.drop(columns=['label']).reset_index(drop=True),\n",
    "    Y.reset_index(drop=True),\n",
    "    models.knn_online_learn(X.reset_index(drop=True), Y.reset_index(drop=True), window_len=1, learn_skip=0, clusters=True)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_model_setup(n):\n",
    "    engine = neighbors.SWINN(\n",
    "        dist_func=functools.partial(utils.math.minkowski_distance, p=2),\n",
    "        seed=10\n",
    "    )\n",
    "    model = (\n",
    "        preprocessing.MinMaxScaler() |\n",
    "        neighbors.KNNClassifier(n_neighbors=n, engine=engine)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def knn_accuracy_with_delays(X, y, delays):\n",
    "    knn = knn_model_setup(5)\n",
    "\n",
    "    evolution = defaultdict(dict)\n",
    "    for delay in delays:\n",
    "        steps = evaluate.iter_progressive_val_score(\n",
    "            model=knn,\n",
    "            dataset=stream.iter_pandas(X, y),\n",
    "            metric=metrics.Accuracy(),\n",
    "            step=100,\n",
    "            delay=delay\n",
    "        )\n",
    "        for step in steps:\n",
    "            step_num = step['Step']\n",
    "            evolution[step_num]['Observation'] = step_num\n",
    "            evolution[step_num][delay] = step['Accuracy'].get()\n",
    "\n",
    "    evolution = (\n",
    "        pd.DataFrame\n",
    "        .from_records(list(evolution.values()))\n",
    "        .set_index('Observation')\n",
    "    )\n",
    "    evolution.plot(\n",
    "        grid=True, figsize=(8, 4), \n",
    "        ylabel='Accuracy'\n",
    "       # title='Accuracy with different delays'\n",
    "    )\n",
    "    return evolution\n",
    "\n",
    "\n",
    "def knn_conf_matrix_plot(X, y):\n",
    "    knn = knn_model_setup(5)\n",
    "    #confmatrix = metrics.ConfusionMatrix()\n",
    "    y_predictions = []\n",
    "\n",
    "    for x, y_true in stream.iter_pandas(X, y):\n",
    "        y_predict = knn.predict_one(x) or 0\n",
    "        knn.learn_one(x, y_true)\n",
    "        y_predictions.append(y_predict)\n",
    "        # confmatrix.update(y_true, y_predict)\n",
    "\n",
    "    cm = skmetrics.confusion_matrix(y, y_predictions)\n",
    "    ax = sb.heatmap(cm, cbar=True, cmap='BuGn', annot=True, fmt='d')\n",
    "    ax.set(xlabel='Prediction', ylabel='Truth')\n",
    "\n",
    "\n",
    "def knn_visualize_classes(X, y):\n",
    "    knn = knn_model_setup(5)\n",
    "\n",
    "    y_predictions = []\n",
    "    for xs, ys in stream.iter_pandas(X, y):\n",
    "        y_predict = knn.predict_one(xs)\n",
    "        knn.learn_one(xs, ys)\n",
    "        y_predictions.append(y_predict)\n",
    "\n",
    "    y_predictions = pd.Series(y_predictions)\n",
    "    mismatch = visualize.project_classifier_map_plot(X, y, y_predictions)\n",
    "    print(f'Error rate: {100 * (len(mismatch) / len(y)):.2f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN classifier (Faults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = X.drop(columns=['label']), Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evolution = knn_accuracy_with_delays(X, y, (1, 50, 100, 250))\n",
    "plt.show()\n",
    "evolution.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification report (Faults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate.progressive_val_score(\n",
    "    model=knn_model_setup(5),\n",
    "    dataset=stream.iter_pandas(X, y),\n",
    "    metric=metrics.ClassificationReport()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix (Faults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_conf_matrix_plot(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
